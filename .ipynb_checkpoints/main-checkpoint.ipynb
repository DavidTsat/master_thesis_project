{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from matrix_factorization.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter \n",
    "import matrix_factorization\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 5778k    0 17401    0     0  30262      0  0:03:15 --:--:--  0:03:15 30262\n",
      " 12 5778k   12  719k    0     0   478k      0  0:00:12  0:00:01  0:00:11  478k\n",
      " 42 5778k   42 2480k    0     0   990k      0  0:00:05  0:00:02  0:00:03  990k\n",
      " 69 5778k   69 4033k    0     0  1093k      0  0:00:05  0:00:03  0:00:02 1093k\n",
      " 83 5778k   83 4816k    0     0  1052k      0  0:00:05  0:00:04  0:00:01 1052k\n",
      " 97 5778k   97 5645k    0     0  1024k      0  0:00:05  0:00:05 --:--:-- 1140k\n",
      "100 5778k  100 5778k    0     0  1019k      0  0:00:05  0:00:05 --:--:-- 1215k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-1m.zip\n",
      "  inflating: ml-1m/movies.dat        \n",
      "  inflating: ml-1m/ratings.dat       \n",
      "  inflating: ml-1m/README            \n",
      "  inflating: ml-1m/users.dat         \n"
     ]
    }
   ],
   "source": [
    "# Downloading Movielens-1m\n",
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip ml-1m.zip\n",
    "!cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_list = [i.strip().split(\"::\") for i in open('./ml-1m/ratings.dat', 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open('./ml-1m/users.dat', 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open('./ml-1m/movies.dat', 'r').readlines()]\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1 10 100 1000 1002 1003 1004 1005 1006 1007  ... 99 990 991 992 993  \\\n",
       "UserID                                                ...                      \n",
       "1        5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "10       5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "100      0  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1000     5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1001     4  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "\n",
       "MovieID 994 996 997 998 999  \n",
       "UserID                       \n",
       "1         0   0   0   0   0  \n",
       "10        0   0   0   0   0  \n",
       "100       0   0   0   0   0  \n",
       "1000      0   0   0   0   0  \n",
       "1001      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "R_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(R_df.values, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users = df.user_id.unique().shape[0]\n",
    "# n_items = df.item_id.unique().shape[0]\n",
    "# ratings = np.zeros((n_users, n_items))\n",
    "# for row in df.itertuples():\n",
    "#     ratings[row[1]-1, row[2]-1] = row[3]\n",
    "# ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(R_df.values, dtype=int)\n",
    "n_users = ratings.shape[0]\n",
    "n_items = ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    print (str(n_users) + ' users')\n",
    "    print (str(n_items) + ' items')\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n",
      "Sparsity: 4.47%\n"
     ]
    }
   ],
   "source": [
    "print ('Sparsity: {:4.2f}%'.format(get_sparsity(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int (ratings[0, :].nonzero()[0].shape[0]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=int(ratings[user, :].nonzero()[0].shape[0]/2), replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    \n",
    "#     print(test)\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2407997769859507"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2275627852453335"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.8534988095522325\n",
      "Test mse: 0.8688700762793526\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####################################### GANS ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise(batch_size):\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8286, 0.3773, 0.4484, 0.8004, 0.0810, 0.2336, 0.2669, 0.5789, 0.5965,\n",
       "         0.6433, 0.5064, 0.4319, 0.1509, 0.9770, 0.9012, 0.1474, 0.5231, 0.7965,\n",
       "         0.0676, 0.3197, 0.4385, 0.8900, 0.0823, 0.8286, 0.0739, 0.5791, 0.1959,\n",
       "         0.7163, 0.3008, 0.5834, 0.8412, 0.6135, 0.4347, 0.9300, 0.1680, 0.4885,\n",
       "         0.4412, 0.4802, 0.9546, 0.3943, 0.9071, 0.5518, 0.5416, 0.3762, 0.4665,\n",
       "         0.0193, 0.2582, 0.6052, 0.6872, 0.3026, 0.1753, 0.3926, 0.4272, 0.9563,\n",
       "         0.2090, 0.4256, 0.4575, 0.2309, 0.1390, 0.2013, 0.3276, 0.5335, 0.9201,\n",
       "         0.5601, 0.2012, 0.3879, 0.2943, 0.3919, 0.9447, 0.6145, 0.4194, 0.4409,\n",
       "         0.6741, 0.1153, 0.8877, 0.2219, 0.1126, 0.3821, 0.5854, 0.5212, 0.5162,\n",
       "         0.6840, 0.0252, 0.2265, 0.9295, 0.5536, 0.4964, 0.7735, 0.9520, 0.5243,\n",
       "         0.9713, 0.8994, 0.8473, 0.2071, 0.8766, 0.9776, 0.7205, 0.0112, 0.1247,\n",
       "         0.5554],\n",
       "        [0.1887, 0.0115, 0.5134, 0.0923, 0.8085, 0.7471, 0.3456, 0.7753, 0.0050,\n",
       "         0.9096, 0.0854, 0.3445, 0.4967, 0.2185, 0.1525, 0.5924, 0.2435, 0.5042,\n",
       "         0.2291, 0.7816, 0.2857, 0.5672, 0.1419, 0.2595, 0.2495, 0.2214, 0.7062,\n",
       "         0.3936, 0.9276, 0.4842, 0.0687, 0.1195, 0.9182, 0.5944, 0.7027, 0.1607,\n",
       "         0.5115, 0.6232, 0.9309, 0.6765, 0.6063, 0.7697, 0.7519, 0.3417, 0.8708,\n",
       "         0.7988, 0.5536, 0.8389, 0.9645, 0.7666, 0.5390, 0.3395, 0.3545, 0.7686,\n",
       "         0.7583, 0.5884, 0.7617, 0.8696, 0.0449, 0.8800, 0.9456, 0.3628, 0.9574,\n",
       "         0.7005, 0.6213, 0.5618, 0.6213, 0.5643, 0.1183, 0.1919, 0.5793, 0.0275,\n",
       "         0.5741, 0.9845, 0.1737, 0.8532, 0.4085, 0.4268, 0.7972, 0.6093, 0.8225,\n",
       "         0.1637, 0.1684, 0.2893, 0.7434, 0.9509, 0.4262, 0.3290, 0.7347, 0.7501,\n",
       "         0.3678, 0.7433, 0.6772, 0.5393, 0.3872, 0.6066, 0.0168, 0.1233, 0.9374,\n",
       "         0.1664],\n",
       "        [0.4374, 0.6197, 0.7526, 0.3271, 0.9421, 0.6456, 0.1807, 0.8225, 0.4720,\n",
       "         0.2436, 0.6590, 0.4931, 0.6705, 0.0613, 0.6672, 0.3387, 0.1448, 0.9961,\n",
       "         0.3130, 0.6540, 0.0432, 0.6590, 0.1394, 0.7187, 0.3397, 0.0611, 0.7182,\n",
       "         0.1024, 0.4607, 0.3355, 0.5820, 0.7991, 0.8982, 0.4940, 0.0091, 0.4577,\n",
       "         0.6145, 0.7351, 0.2216, 0.7647, 0.0817, 0.0172, 0.2268, 0.7246, 0.4518,\n",
       "         0.8120, 0.1861, 0.7580, 0.2506, 0.9881, 0.1883, 0.5402, 0.3819, 0.4654,\n",
       "         0.6774, 0.9674, 0.7337, 0.4238, 0.0869, 0.8384, 0.7597, 0.2848, 0.3126,\n",
       "         0.6836, 0.2313, 0.6111, 0.9366, 0.8728, 0.3947, 0.3570, 0.3541, 0.4032,\n",
       "         0.4221, 0.7517, 0.0348, 0.4349, 0.5058, 0.8814, 0.1050, 0.1882, 0.5455,\n",
       "         0.1091, 0.4492, 0.0358, 0.1595, 0.1735, 0.5438, 0.5887, 0.4638, 0.0292,\n",
       "         0.3755, 0.0752, 0.4632, 0.3732, 0.9793, 0.3105, 0.9090, 0.4285, 0.7723,\n",
       "         0.6625],\n",
       "        [0.2394, 0.1968, 0.1281, 0.6539, 0.7269, 0.2099, 0.6699, 0.1167, 0.9211,\n",
       "         0.6242, 0.7069, 0.8386, 0.6841, 0.3146, 0.0176, 0.7383, 0.5849, 0.7128,\n",
       "         0.4159, 0.2897, 0.9581, 0.4471, 0.5277, 0.0604, 0.1394, 0.3928, 0.5388,\n",
       "         0.5204, 0.7442, 0.2145, 0.1163, 0.4732, 0.4146, 0.2226, 0.1389, 0.0112,\n",
       "         0.8012, 0.1256, 0.1719, 0.2560, 0.6476, 0.5727, 0.7098, 0.1938, 0.3427,\n",
       "         0.9966, 0.8009, 0.7147, 0.3362, 0.5029, 0.1772, 0.0627, 0.8377, 0.5998,\n",
       "         0.7114, 0.6610, 0.5794, 0.0611, 0.4549, 0.4527, 0.2225, 0.6789, 0.1832,\n",
       "         0.4267, 0.5619, 0.0048, 0.3611, 0.2572, 0.1404, 0.4725, 0.9680, 0.6991,\n",
       "         0.5686, 0.6598, 0.5521, 0.0362, 0.2183, 0.0746, 0.2355, 0.1405, 0.9738,\n",
       "         0.5198, 0.7138, 0.4671, 0.8605, 0.0536, 0.1296, 0.6692, 0.7796, 0.4590,\n",
       "         0.8203, 0.9181, 0.9077, 0.5207, 0.8296, 0.1929, 0.5616, 0.7089, 0.7367,\n",
       "         0.7221],\n",
       "        [0.6460, 0.9092, 0.5424, 0.4178, 0.1581, 0.3309, 0.8857, 0.2708, 0.2698,\n",
       "         0.3490, 0.8528, 0.4220, 0.7057, 0.7777, 0.1357, 0.8442, 0.8170, 0.1126,\n",
       "         0.5874, 0.1219, 0.0308, 0.9326, 0.6589, 0.8532, 0.5548, 0.8434, 0.9379,\n",
       "         0.7025, 0.1343, 0.4270, 0.3116, 0.4068, 0.6456, 0.7584, 0.9605, 0.6172,\n",
       "         0.7559, 0.0219, 0.4203, 0.1939, 0.1748, 0.4458, 0.0202, 0.1865, 0.8497,\n",
       "         0.4234, 0.4402, 0.3659, 0.9841, 0.1140, 0.3278, 0.9613, 0.7711, 0.3839,\n",
       "         0.4883, 0.4586, 0.6856, 0.9273, 0.3968, 0.3418, 0.7499, 0.7083, 0.4034,\n",
       "         0.9169, 0.3808, 0.7546, 0.2621, 0.8904, 0.9874, 0.7804, 0.3149, 0.0371,\n",
       "         0.4762, 0.4110, 0.5083, 0.8198, 0.4339, 0.9212, 0.6285, 0.4564, 0.6009,\n",
       "         0.7730, 0.8818, 0.7991, 0.4006, 0.0342, 0.0641, 0.6769, 0.5604, 0.7159,\n",
       "         0.1985, 0.7238, 0.6829, 0.6592, 0.3323, 0.0633, 0.5064, 0.9299, 0.3158,\n",
       "         0.3928]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_some_noise(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator class\n",
    "\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(800,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining discriminator class\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(200,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(ratings.shape[1], 1)\n",
    "gen = generator(100, ratings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=3706, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=1000, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=800, out_features=3706, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps = 300\n",
    "g_steps = 300\n",
    "\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# printing_steps = 200\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]\n",
    "    \n",
    "get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g):\n",
    "    return torch.sum(torch.abs((x_r != 0).float() * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "eval_losses = []\n",
    "for epoch in range(1):\n",
    "#     print (epoch)\n",
    "\n",
    "    # training discriminator\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()\n",
    "        \n",
    "        # training discriminator on real data\n",
    "        real_rows = get_random_batch(train, batch_size)\n",
    "        discriminator_real_outputs = dis(real_rows)\n",
    "   \n",
    "        dis_real_loss = criteriond1(discriminator_real_outputs, Variable(torch.ones(batch_size,1)))\n",
    "    \n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # training discriminator on data produced by generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        #output from generator is generated        \n",
    "        fake_rows = gen(z_vector).detach()\n",
    "#         print(fake_rows[:20])\n",
    "        dis_fake_out = dis(fake_rows)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out, Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()\n",
    "        \n",
    "    # training generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()\n",
    "        \n",
    "        #generating data for input for generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        \n",
    "        fake_rows = gen(z_vector)\n",
    "#         print(fake_rows.shape, z_vector.shape)\n",
    "#         print(fake_rows[:20])\n",
    "        dis_out_gen_training = dis(fake_rows)\n",
    "        gen_loss = criteriond2(dis_out_gen_training, Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()\n",
    "\n",
    "    # evaluation\n",
    "    if epoch % 10: # todo- to change\n",
    "        gen.eval()\n",
    "        z_vector_eval = make_some_noise(128)\n",
    "        fake_rows_eval = gen(z_vector_eval)\n",
    "        real_rows_eval = get_random_batch(train, 128)\n",
    "#         print(fake_rows[0][:10]) enable to see some results\n",
    "        eval_loss = F.mse_loss(fake_rows_eval, real_rows_eval, reduction='mean')\n",
    "        eval_losses.append(eval_loss)\n",
    "#         print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "        print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real_rows_eval, fake_rows_eval)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vector = make_some_noise(16)\n",
    "fake_rows = gen(z_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4683, 2.5271, 2.3960, 2.4189, 2.3755, 2.5695, 2.4089, 2.5953, 2.4142],\n",
       "        [2.5101, 2.5172, 2.3890, 2.4423, 2.4204, 2.5056, 2.4331, 2.4869, 2.4380],\n",
       "        [2.5211, 2.6048, 2.4080, 2.4004, 2.4534, 2.4957, 2.4699, 2.5215, 2.4338],\n",
       "        [2.5403, 2.6287, 2.3578, 2.4084, 2.4141, 2.5188, 2.4241, 2.4405, 2.3813],\n",
       "        [2.5309, 2.5508, 2.3813, 2.4191, 2.3735, 2.5363, 2.4376, 2.5573, 2.4490],\n",
       "        [2.4896, 2.5440, 2.4390, 2.4170, 2.4031, 2.5628, 2.3837, 2.5894, 2.4820],\n",
       "        [2.4759, 2.4890, 2.3844, 2.4044, 2.3361, 2.5646, 2.3623, 2.5605, 2.4206],\n",
       "        [2.4745, 2.5781, 2.3986, 2.3674, 2.4108, 2.5798, 2.3924, 2.5408, 2.4513],\n",
       "        [2.5866, 2.6028, 2.4352, 2.4401, 2.3978, 2.5467, 2.4567, 2.6086, 2.3954],\n",
       "        [2.5206, 2.5999, 2.3991, 2.4608, 2.4139, 2.5368, 2.4473, 2.5239, 2.4674],\n",
       "        [2.5207, 2.5853, 2.4515, 2.4172, 2.4443, 2.5631, 2.4338, 2.5352, 2.4675],\n",
       "        [2.5980, 2.5686, 2.5051, 2.4832, 2.3769, 2.5519, 2.4021, 2.6102, 2.4638],\n",
       "        [2.5050, 2.5399, 2.4208, 2.4241, 2.3692, 2.5832, 2.4359, 2.5093, 2.4219],\n",
       "        [2.5599, 2.5562, 2.4007, 2.4309, 2.3949, 2.5358, 2.4323, 2.5285, 2.4210],\n",
       "        [2.5509, 2.5987, 2.4579, 2.4275, 2.4470, 2.5608, 2.4016, 2.5375, 2.4710],\n",
       "        [2.4517, 2.5314, 2.4394, 2.4553, 2.3991, 2.6536, 2.4243, 2.5626, 2.4446]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we see generator produces very similar vectors \n",
    "fake_rows[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os\n",
    "# from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c32e52d050>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 100\n",
    "cuda = True\n",
    "epochs = 100 #change\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "name = \"mnist-experiment\"\n",
    "# configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#     transform=transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length=6\n",
    "# batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Dropout(p=0.5)\n",
      "  )\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(features_length, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(features_length, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, features_length)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        filt = (torch.abs((real != 0).float() * fake - real))/real.shape[0]\n",
    "#         filt = torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda())\n",
    "#         filt = torch.abs((xr != 0).int() * xf - xr)\n",
    "#         filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "#         print(filt.type(), x.type())\n",
    "        x = filt * x\n",
    "\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, features_length),\n",
    "#     torch.nn.Sigmoid()*5\n",
    "#     )\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(nz,1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024,features_length),\n",
    "                                 nn.Sigmoid(),\n",
    "                                 nn.Dropout(0.5)\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]\n",
    "    \n",
    "# networks\n",
    "netD = NetD(use_cuda=False)\n",
    "netG = NetG()\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "cuda = False\n",
    "if cuda is True:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(length=6):\n",
    "     return Variable(torch.IntTensor(np.random.choice([0, 1], size=(batch_size, length))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3706])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_batch(train, batch_size=batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 5. my distance between random real and fake samples 17642.201171875\n",
      "Epoch number 11. my distance between random real and fake samples 19959.1796875\n",
      "Epoch number 17. my distance between random real and fake samples 18155.15234375\n",
      "Epoch number 23. my distance between random real and fake samples 17043.408203125\n",
      "Epoch number 29. my distance between random real and fake samples 21911.34765625\n",
      "Epoch number 35. my distance between random real and fake samples 22687.05078125\n",
      "Epoch number 41. my distance between random real and fake samples 18111.48046875\n",
      "Epoch number 47. my distance between random real and fake samples 21374.26953125\n",
      "Epoch number 52. my distance between random real and fake samples 22663.46484375\n",
      "Epoch number 58. my distance between random real and fake samples 16857.2109375\n",
      "Epoch number 64. my distance between random real and fake samples 18356.068359375\n",
      "Epoch number 70. my distance between random real and fake samples 20930.1328125\n",
      "Epoch number 76. my distance between random real and fake samples 17254.498046875\n",
      "Epoch number 82. my distance between random real and fake samples 17587.09375\n",
      "Epoch number 88. my distance between random real and fake samples 19049.50390625\n",
      "Epoch number 94. my distance between random real and fake samples 22761.90625\n",
      "Epoch number 99. my distance between random real and fake samples 21763.291015625\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "gen_iterations = 0\n",
    "eval_losses = []\n",
    "for epoch in range(epochs):\n",
    "#     data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < steps_per_epoch:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter:\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "#             X, _ = data_iter.next()\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             print(X >= 0.5)\n",
    "# #             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "#             print(real.shape, fake.shape)\n",
    "    \n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real)\n",
    "#             print('fake', fake[:,0].sum())\n",
    "            out = netD(real, fake)\n",
    "            \n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "#             print(out.shape)\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter:\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "#             print('output_D', outputD.item(), gen_iterations)\n",
    "#             print('output_G', outputG.item(), gen_iterations)\n",
    "#             print('std_D', stdD.item(), gen_iterations)\n",
    "#             print('std_G', stdG.item(), gen_iterations)\n",
    "            \n",
    "            # evaluation\n",
    "            if gen_iterations % 100 == 0: # todo- to change\n",
    "#                 gen.eval()\n",
    "#                 z_vector_eval = make_some_noise(128)\n",
    "#                 fake_rows_eval = gen(z_vector_eval)\n",
    "#                 real_rows_eval = get_random_batch(train, 128)\n",
    "        #         print(fake_rows[0][:10]) enable to see some results\n",
    "                eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "                eval_losses.append(eval_loss)\n",
    "                print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real, fake)))\n",
    "#                 print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda()).cuda().type()\n",
    "torch.abs((real != 0).float() * fake - real).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = ratings.shape[0]\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, nz)\n",
    "if cuda: \n",
    "    noise = noise.cuda()\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 tensor(1157428) 226310\n",
      "4 tensor(4330141) 348971\n",
      "3 tensor(3513882) 261197\n",
      "2 tensor(1092310) 107557\n",
      "1 tensor(212463) 56174\n",
      "0 tensor(11198321) 21384031\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == ratings.round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == ratings.round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == ratings.round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == ratings.round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == ratings.round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == ratings.round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11191494 > 21384031\n",
    "fake_ratings = fake.detach().int().numpy().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 3, ..., 3, 0, 0],\n",
       "       [0, 0, 3, ..., 2, 3, 0],\n",
       "       [4, 0, 0, ..., 2, 3, 0],\n",
       "       ...,\n",
       "       [4, 0, 3, ..., 2, 0, 0],\n",
       "       [0, 3, 3, ..., 2, 0, 3],\n",
       "       [4, 3, 0, ..., 2, 3, 0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040, 3706), (6040, 3706))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11191494 > 21384031\n",
    "fake_ratings.shape, ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.7690205251552"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(fake_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_fake = fake_ratings[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4, 0, 4, 3, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 4, 0, 4,\n",
       "       0, 0, 3, 4, 0, 4, 3, 0, 0, 4, 0, 4, 0, 0, 3, 0, 0, 0, 0, 4, 4, 0,\n",
       "       0, 4, 4, 4, 0, 0, 4, 0, 3, 3, 4, 0, 0, 4, 3, 0, 4, 0, 0, 0, 0, 0,\n",
       "       4, 0, 4, 0, 4, 4, 0, 4, 3, 4, 4, 0, 4, 4, 4, 4, 0, 0, 4, 0, 0, 0,\n",
       "       4, 0, 0, 0, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 4, 4, 4, 0, 4, 0, 4, 0,\n",
       "       0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0,\n",
       "       4, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 4, 4, 0, 0, 0, 4, 3, 4,\n",
       "       0, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 3, 4, 0, 0, 4, 3, 0, 0, 4, 4, 0,\n",
       "       0, 3, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 4, 4, 4, 0,\n",
       "       0, 4, 3, 0, 4, 0, 4, 3, 4, 4, 0, 4, 4, 0, 0, 0, 4, 3, 0, 0, 0, 0,\n",
       "       0, 4, 3, 4, 0, 4, 3, 3, 4, 0, 4, 4, 0, 3, 4, 3, 4, 3, 3, 3, 0, 4,\n",
       "       4, 0, 0, 4, 3, 4, 4, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 4, 4, 3, 4,\n",
       "       0, 3, 4, 4, 0, 0, 0, 3, 4, 0, 4, 4, 0, 0, 0, 4, 4, 0, 0, 3, 3, 0,\n",
       "       0, 3, 4, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adding_fake[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 0, 5, 0, 5, 0, 0, 0, 0, 5, 0, 5, 6, 6, 4, 0, 0, 5, 6, 0, 0,\n",
       "       6, 6, 0, 5, 5, 0, 0, 0, 7, 0, 0, 0, 6, 4, 6, 0, 5, 0, 0, 5, 5, 5,\n",
       "       6, 4, 5, 0, 5, 0, 0, 0, 4, 5, 0, 5, 5, 4, 5, 0, 5, 5, 5, 4, 5, 0,\n",
       "       0, 4, 5, 4, 5, 0, 5, 0, 0, 4, 5, 5, 0, 5, 6, 0, 6, 0, 0, 5, 5, 6,\n",
       "       0, 0, 0, 0, 0, 6, 0, 0, 0, 4, 4, 0, 5, 0, 4, 0, 0, 5, 5, 0, 0, 5,\n",
       "       0, 6, 0, 0, 5, 5, 4, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       5, 0, 0, 5, 0, 6, 0, 0, 0, 4, 0, 0, 5, 6, 0, 0, 5, 4, 0, 0, 5, 5,\n",
       "       5, 4, 4, 0, 6, 5, 4, 4, 6, 5, 0, 0, 0, 0, 6, 0, 5, 0, 6, 6, 0, 5,\n",
       "       0, 5, 5, 0, 6, 5, 5, 0, 5, 0, 6, 5, 5, 5, 0, 0, 5, 0, 0, 0, 0, 5,\n",
       "       0, 0, 0, 6, 0, 0, 5, 5, 0, 5, 4, 4, 0, 0, 0, 4, 6, 4, 0, 4, 0, 0,\n",
       "       5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0, 6, 6, 6, 5, 0, 0, 0, 5, 0, 0, 0,\n",
       "       0, 5, 0, 5, 0, 0, 0, 5, 0, 4, 4, 0, 5, 5, 0, 0, 0, 6, 0, 0, 5, 0,\n",
       "       5, 0, 5, 0, 4, 4, 0, 0, 0, 6, 6, 5, 0, 4, 5, 4, 0, 5, 0, 5, 5, 6,\n",
       "       6, 0, 4, 0, 5, 6, 0, 0, 5, 0, 6, 5, 0, 0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adding_fake[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040, 3706), (300, 3706))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape, adding_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat = np.append(ratings, adding_fake, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6340, 3706)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.612369573766473"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 3, 0, ..., 0, 3, 3],\n",
       "       [4, 3, 3, ..., 2, 0, 3],\n",
       "       [4, 0, 3, ..., 3, 0, 3]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip(new_mat, 0,5, out=new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.6598825380975267\n",
      "Test mse: 0.8647333814366519\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(new_mat, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.8534771653423189\n",
      "Test mse: 0.8688528847623804\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train.numpy(), 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1890)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake[0] < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3653"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ratings[0] < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_row(n=10):\n",
    "    elements = [0, 1, 2, 3, 4, 5]\n",
    "    probabilities = [0.5, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "    return np.random.choice(elements, 10, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_dwgan(x_r, x_g):\n",
    "    return sum(x_r != x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g):\n",
    "    return np.sum(np.abs((x_r != 0).astype(int) * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_1 = np.array([0, 0, 3, 0, 4, 0, 0, 0, 0, 0])\n",
    "\n",
    "x_r_2 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_2 = np.array([0, 5, 3, 0, 4, 4, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1, x_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_2, x_g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r = random_row(n=10)\n",
    "x_g = random_row(n=10)\n",
    "\n",
    "print('x real', x_r)\n",
    "print('x gen ', x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
