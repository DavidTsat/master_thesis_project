{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in c:\\users\\david\\anaconda3\\lib\\site-packages (0.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from matrix_factorization.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter \n",
    "import matrix_factorization\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 5778k    0 21621    0     0  22220      0  0:04:26 --:--:--  0:04:26 22220\n",
      " 18 5778k   18 1077k    0     0   509k      0  0:00:11  0:00:02  0:00:09  509k\n",
      " 46 5778k   46 2673k    0     0   911k      0  0:00:06  0:00:02  0:00:04  911k\n",
      " 80 5778k   80 4647k    0     0  1192k      0  0:00:04  0:00:03  0:00:01 1192k\n",
      "100 5778k  100 5778k    0     0  1316k      0  0:00:04  0:00:04 --:--:-- 1316k\n",
      "\"unzip\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "‘ЁбвҐ¬Ґ ­Ґ г¤ Ґвбп ­ ©вЁ гЄ § ­­л© Їгвм.\n"
     ]
    }
   ],
   "source": [
    "# Downloading Movielens-1m\n",
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip ml-1m.zip\n",
    "!cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_list = [i.strip().split(\"::\") for i in open('./ml-1m/ratings.dat', 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open('./ml-1m/users.dat', 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open('./ml-1m/movies.dat', 'r').readlines()]\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1 10 100 1000 1002 1003 1004 1005 1006 1007  ... 99 990 991 992 993  \\\n",
       "UserID                                                ...                      \n",
       "1        5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "10       5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "100      0  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1000     5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1001     4  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "\n",
       "MovieID 994 996 997 998 999  \n",
       "UserID                       \n",
       "1         0   0   0   0   0  \n",
       "10        0   0   0   0   0  \n",
       "100       0   0   0   0   0  \n",
       "1000      0   0   0   0   0  \n",
       "1001      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "R_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(R_df.values, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users = df.user_id.unique().shape[0]\n",
    "# n_items = df.item_id.unique().shape[0]\n",
    "# ratings = np.zeros((n_users, n_items))\n",
    "# for row in df.itertuples():\n",
    "#     ratings[row[1]-1, row[2]-1] = row[3]\n",
    "# ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(R_df.values, dtype=int)\n",
    "n_users = ratings.shape[0]\n",
    "n_items = ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    print (str(n_users) + ' users')\n",
    "    print (str(n_items) + ' items')\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n",
      "Sparsity: 4.47%\n"
     ]
    }
   ],
   "source": [
    "print ('Sparsity: {:4.2f}%'.format(get_sparsity(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=20, replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    \n",
    "#     print(test)\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.9286971547839014"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5396654074473827"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.8264795643096374\n",
      "Test mse: 0.9051574489352089\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####################################### GANS ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise(batch_size):\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1474, 0.4041, 0.9266, 0.8344, 0.0607, 0.2055, 0.1804, 0.0571, 0.4477,\n",
       "         0.9110, 0.6711, 0.7431, 0.1136, 0.5251, 0.9401, 0.2184, 0.7752, 0.4742,\n",
       "         0.4788, 0.6751, 0.0654, 0.4542, 0.4279, 0.1089, 0.7128, 0.4631, 0.8986,\n",
       "         0.4779, 0.2469, 0.5552, 0.6571, 0.4859, 0.2940, 0.1368, 0.3363, 0.2028,\n",
       "         0.8328, 0.9889, 0.3798, 0.6714, 0.4464, 0.2448, 0.3737, 0.3871, 0.0631,\n",
       "         0.8536, 0.3421, 0.4817, 0.3166, 0.8078, 0.4534, 0.7482, 0.3868, 0.9344,\n",
       "         0.6995, 0.4715, 0.5936, 0.1676, 0.0990, 0.9420, 0.8569, 0.9895, 0.9712,\n",
       "         0.3469, 0.5302, 0.3782, 0.8043, 0.3108, 0.5110, 0.0579, 0.7652, 0.7038,\n",
       "         0.9826, 0.5229, 0.1523, 0.5841, 0.5733, 0.7517, 0.1006, 0.2259, 0.0476,\n",
       "         0.5392, 0.3839, 0.1672, 0.2411, 0.0920, 0.9446, 0.8182, 0.8028, 0.3419,\n",
       "         0.1951, 0.9592, 0.1417, 0.7151, 0.8432, 0.9255, 0.4445, 0.8176, 0.5176,\n",
       "         0.8171],\n",
       "        [0.9218, 0.0678, 0.7880, 0.4564, 0.7748, 0.0275, 0.7941, 0.6963, 0.9955,\n",
       "         0.5948, 0.3814, 0.5588, 0.1448, 0.7751, 0.8301, 0.2677, 0.8140, 0.3889,\n",
       "         0.3443, 0.7233, 0.4649, 0.4262, 0.9822, 0.0209, 0.7131, 0.9418, 0.2149,\n",
       "         0.5334, 0.6630, 0.3185, 0.2230, 0.5042, 0.8593, 0.0288, 0.3876, 0.7659,\n",
       "         0.2721, 0.8075, 0.4833, 0.5887, 0.0621, 0.4105, 0.4461, 0.6103, 0.3768,\n",
       "         0.5193, 0.9324, 0.5867, 0.7411, 0.6914, 0.2625, 0.0129, 0.1967, 0.6396,\n",
       "         0.4566, 0.5555, 0.2042, 0.6865, 0.5263, 0.3177, 0.0340, 0.0920, 0.2988,\n",
       "         0.7571, 0.3724, 0.0829, 0.8553, 0.1836, 0.1216, 0.2835, 0.7585, 0.8662,\n",
       "         0.0182, 0.0373, 0.5089, 0.5759, 0.4925, 0.6157, 0.5206, 0.8865, 0.0840,\n",
       "         0.7209, 0.8109, 0.9364, 0.5454, 0.0735, 0.3639, 0.8822, 0.6379, 0.0168,\n",
       "         0.1272, 0.8697, 0.9438, 0.4180, 0.2830, 0.0075, 0.4266, 0.9641, 0.6695,\n",
       "         0.4516],\n",
       "        [0.8927, 0.3349, 0.1524, 0.3513, 0.5880, 0.3446, 0.0975, 0.1965, 0.2214,\n",
       "         0.0924, 0.0221, 0.7201, 0.3687, 0.9060, 0.1803, 0.6998, 0.1316, 0.3383,\n",
       "         0.6833, 0.8137, 0.4331, 0.8839, 0.4711, 0.5688, 0.6902, 0.3322, 0.6057,\n",
       "         0.7074, 0.0248, 0.1062, 0.1055, 0.9955, 0.7646, 0.8774, 0.1987, 0.9752,\n",
       "         0.8738, 0.1646, 0.9205, 0.4187, 0.2650, 0.6895, 0.1873, 0.1599, 0.8864,\n",
       "         0.2219, 0.9567, 0.7069, 0.9498, 0.1849, 0.5684, 0.6650, 0.7460, 0.9268,\n",
       "         0.1163, 0.9652, 0.7985, 0.9927, 0.6379, 0.3261, 0.9776, 0.8394, 0.5436,\n",
       "         0.0327, 0.5032, 0.3972, 0.7058, 0.8411, 0.9988, 0.9904, 0.5438, 0.7633,\n",
       "         0.4733, 0.2397, 0.4687, 0.3159, 0.5623, 0.2260, 0.1581, 0.3286, 0.4504,\n",
       "         0.0895, 0.8971, 0.0234, 0.5619, 0.6987, 0.0572, 0.2232, 0.0513, 0.3971,\n",
       "         0.5296, 0.6766, 0.2374, 0.6547, 0.9302, 0.9683, 0.4076, 0.9513, 0.4616,\n",
       "         0.1705],\n",
       "        [0.7116, 0.8320, 0.6531, 0.4971, 0.1514, 0.6679, 0.0954, 0.4372, 0.0603,\n",
       "         0.6062, 0.3553, 0.1852, 0.8561, 0.6951, 0.9906, 0.5738, 0.0704, 0.2624,\n",
       "         0.9255, 0.8972, 0.2835, 0.8402, 0.0862, 0.6019, 0.2588, 0.0138, 0.9241,\n",
       "         0.8857, 0.5759, 0.0060, 0.7496, 0.8172, 0.7631, 0.0244, 0.3693, 0.9613,\n",
       "         0.7097, 0.4720, 0.0839, 0.1880, 0.2317, 0.0201, 0.2381, 0.7081, 0.4478,\n",
       "         0.8575, 0.9159, 0.8786, 0.9609, 0.3356, 0.6552, 0.9725, 0.6757, 0.3638,\n",
       "         0.2705, 0.2616, 0.1560, 0.8420, 0.6814, 0.6962, 0.2384, 0.3589, 0.6219,\n",
       "         0.8430, 0.9628, 0.7435, 0.6338, 0.0982, 0.9009, 0.3854, 0.1112, 0.9310,\n",
       "         0.9572, 0.9879, 0.7192, 0.1664, 0.9212, 0.5045, 0.3586, 0.7432, 0.8553,\n",
       "         0.8709, 0.6814, 0.9737, 0.1116, 0.5431, 0.3582, 0.9437, 0.9032, 0.3154,\n",
       "         0.3143, 0.8601, 0.6457, 0.3979, 0.9344, 0.1134, 0.6647, 0.2699, 0.5611,\n",
       "         0.7292],\n",
       "        [0.2561, 0.4183, 0.4223, 0.5924, 0.3336, 0.9790, 0.6702, 0.6230, 0.9427,\n",
       "         0.9824, 0.2931, 0.3396, 0.1786, 0.4325, 0.6313, 0.3522, 0.9953, 0.3902,\n",
       "         0.7386, 0.1510, 0.4162, 0.4905, 0.7681, 0.6667, 0.5136, 0.0811, 0.6736,\n",
       "         0.4950, 0.5765, 0.2077, 0.7224, 0.3302, 0.9101, 0.1006, 0.6466, 0.1918,\n",
       "         0.3389, 0.4972, 0.7334, 0.9971, 0.7570, 0.0693, 0.4374, 0.4275, 0.0576,\n",
       "         0.6857, 0.9647, 0.1149, 0.6269, 0.2939, 0.7267, 0.9591, 0.3366, 0.6320,\n",
       "         0.6182, 0.4770, 0.4124, 0.4900, 0.3262, 0.8084, 0.6874, 0.8929, 0.2176,\n",
       "         0.0120, 0.4579, 0.5836, 0.2346, 0.3249, 0.1182, 0.5685, 0.0119, 0.2873,\n",
       "         0.0627, 0.2857, 0.5120, 0.0742, 0.9845, 0.9356, 0.2324, 0.2105, 0.2259,\n",
       "         0.4305, 0.5619, 0.6925, 0.0917, 0.1927, 0.2551, 0.9778, 0.0080, 0.8553,\n",
       "         0.1726, 0.9375, 0.7204, 0.6266, 0.1027, 0.4398, 0.8061, 0.7884, 0.0686,\n",
       "         0.7089]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_some_noise(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator class\n",
    "\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(800,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining discriminator class\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(200,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(ratings.shape[1], 1)\n",
    "gen = generator(100, ratings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=3706, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=1000, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=800, out_features=3706, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps = 300\n",
    "g_steps = 300\n",
    "\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# printing_steps = 200\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]\n",
    "    \n",
    "get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1. MSE distance between random real and fake samples 2892645.5\n",
      "Epoch number 2. MSE distance between random real and fake samples 2903131.75\n",
      "Epoch number 3. MSE distance between random real and fake samples 2881754.5\n",
      "Epoch number 4. MSE distance between random real and fake samples 2872223.5\n",
      "Epoch number 5. MSE distance between random real and fake samples 2824280.75\n",
      "Epoch number 6. MSE distance between random real and fake samples 2755321.25\n",
      "Epoch number 7. MSE distance between random real and fake samples 2681236.25\n",
      "Epoch number 8. MSE distance between random real and fake samples 2577546.0\n",
      "Epoch number 9. MSE distance between random real and fake samples 2352881.75\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "eval_losses = []\n",
    "for epoch in range(10):\n",
    "#     print (epoch)\n",
    "\n",
    "    # training discriminator\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()\n",
    "        \n",
    "        # training discriminator on real data\n",
    "        real_rows = get_random_batch(train, batch_size)\n",
    "        discriminator_real_outputs = dis(real_rows)\n",
    "   \n",
    "        dis_real_loss = criteriond1(discriminator_real_outputs, Variable(torch.ones(batch_size,1)))\n",
    "    \n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # training discriminator on data produced by generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        #output from generator is generated        \n",
    "        fake_rows = gen(z_vector).detach()\n",
    "#         print(fake_rows[:20])\n",
    "        dis_fake_out = dis(fake_rows)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out, Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()\n",
    "        \n",
    "    # training generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()\n",
    "        \n",
    "        #generating data for input for generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        \n",
    "        fake_rows = gen(z_vector)\n",
    "#         print(fake_rows.shape, z_vector.shape)\n",
    "#         print(fake_rows[:20])\n",
    "        dis_out_gen_training = dis(fake_rows)\n",
    "        gen_loss = criteriond2(dis_out_gen_training, Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()\n",
    "\n",
    "    # evaluation\n",
    "    if epoch % 10: # todo- to change\n",
    "        gen.eval()\n",
    "        z_vector_eval = make_some_noise(128)\n",
    "        fake_rows_eval = gen(z_vector_eval)\n",
    "        real_rows_eval = get_random_batch(train, 128)\n",
    "#         print(fake_rows[0][:10]) enable to see some results\n",
    "        eval_loss = F.mse_loss(fake_rows_eval, real_rows_eval, reduction='sum')\n",
    "        eval_losses.append(eval_loss)\n",
    "        print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "#         print('Epoch number {}. L1 distance between random real and fake samples {}'.format(epoch, torch.sum(torch.abs(fake_rows_eval - real_rows_eval))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vector = make_some_noise(16)\n",
    "fake_rows = gen(z_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.8868, 1.5460, 0.7210, 1.4805, 0.4095, 0.4374, 0.4806, 3.3735, 1.0225],\n",
       "        [4.8789, 1.5455, 0.7268, 1.5061, 0.4186, 0.4383, 0.4850, 3.3887, 1.0240],\n",
       "        [4.8836, 1.5315, 0.7159, 1.4835, 0.4150, 0.4350, 0.4822, 3.3891, 1.0137],\n",
       "        [4.8875, 1.5398, 0.7045, 1.4785, 0.4135, 0.4267, 0.4763, 3.3770, 0.9928],\n",
       "        [4.8858, 1.5279, 0.7118, 1.4874, 0.4094, 0.4289, 0.4770, 3.3779, 1.0195],\n",
       "        [4.8908, 1.5127, 0.6953, 1.4771, 0.3993, 0.4179, 0.4710, 3.3937, 0.9897],\n",
       "        [4.8864, 1.5381, 0.7168, 1.4804, 0.4123, 0.4347, 0.4813, 3.3925, 1.0239],\n",
       "        [4.8842, 1.5410, 0.7243, 1.4942, 0.4142, 0.4341, 0.4793, 3.3849, 1.0151],\n",
       "        [4.8890, 1.5223, 0.7087, 1.4809, 0.4029, 0.4261, 0.4709, 3.3784, 1.0046],\n",
       "        [4.8877, 1.5274, 0.7066, 1.4709, 0.4111, 0.4311, 0.4694, 3.3765, 1.0135],\n",
       "        [4.8861, 1.5244, 0.7153, 1.4758, 0.4117, 0.4269, 0.4723, 3.3905, 0.9996],\n",
       "        [4.8851, 1.5422, 0.7192, 1.4801, 0.4133, 0.4348, 0.4783, 3.3800, 1.0221],\n",
       "        [4.8875, 1.5215, 0.6990, 1.4769, 0.4093, 0.4295, 0.4733, 3.3812, 1.0100],\n",
       "        [4.8821, 1.5475, 0.7261, 1.4886, 0.4128, 0.4406, 0.4917, 3.3841, 1.0171],\n",
       "        [4.8854, 1.5349, 0.7162, 1.4833, 0.4111, 0.4304, 0.4776, 3.3927, 0.9996],\n",
       "        [4.8876, 1.5359, 0.7143, 1.4843, 0.4158, 0.4305, 0.4813, 3.3770, 1.0193]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we see generator produces very similar vectors \n",
    "fake_rows[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os\n",
    "# from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrD = 5e-4\n",
    "# lrG = 5e-4\n",
    "# batch_size = 100\n",
    "# cuda = True\n",
    "# epochs = 1000\n",
    "# device = 5\n",
    "# seed = 42\n",
    "# nz = 100\n",
    "# d_iter = 5\n",
    "# g_iter = 1\n",
    "# lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "# name = \"mnist-experiment\"\n",
    "# # configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "# torch.manual_seed(seed)\n",
    "# # if cuda:\n",
    "# # #     torch.cuda.set_device('cuda')\n",
    "# #     torch.cuda.manual_seed(seed)\n",
    "# # data_loader = torch.utils.data.DataLoader(\n",
    "# # datasets.MNIST('../data', train=True, download=True,\n",
    "# # transform=transforms.Compose([transforms.ToTensor(),])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 100\n",
    "cuda = True\n",
    "epochs = 60 #change\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "name = \"mnist-experiment\"\n",
    "# configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length=6\n",
    "# batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(features_length, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(features_length, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, features_length)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "        x = filt * x\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, features_length),\n",
    "#     torch.nn.Sigmoid()*5\n",
    "#     )\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(nz,1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024,features_length),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]\n",
    "    \n",
    "# networks\n",
    "netD = NetD(use_cuda=False)\n",
    "netG = NetG()\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NetD(torch.nn.Module):\n",
    "#     def __init__(self, use_cuda=True):\n",
    "#         super(NetD, self).__init__()\n",
    "#         self.use_cuda = use_cuda\n",
    "#         # top\n",
    "#         self.t1 = torch.nn.Linear(length, 1024)\n",
    "#         # bottom\n",
    "#         self.b1 = torch.nn.Linear(length, 1024)\n",
    "#         # combined\n",
    "#         self.fc = torch.nn.Linear(2 * 1024, length)\n",
    "#     def forward(self, xr, xf):\n",
    "#         # get filt\n",
    "# #         print(\"##########\"*40)\n",
    "#         filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "# #         if (filt == xr * xf).all():\n",
    "# #             print('AAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
    "            \n",
    "# #         print('xr & xf', xr * xf)\n",
    "# #         print('filt', filt)\n",
    "# #         print('xr.shape, xf.shape', xr.shape, xf.shape)\n",
    "# #         print('filt.shape', filt.shape)\n",
    "# #         print('xr', xr)\n",
    "# #         print('xf', xf)\n",
    "# #         print('filt', filt)\n",
    "# # #         return filt\n",
    "# #         # random swap\n",
    "#         idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "# #         print(idr.shape)\n",
    "# #         print('idr', idr)\n",
    "#         idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "# #         print('idrx', idrx)\n",
    "# #         print('idrx.shape', idrx.shape)\n",
    "# #         print('idrx', idrx[10:20, 100:200])\n",
    "#         if self.use_cuda: \n",
    "#             idrx = idrx.cuda()\n",
    "#         idrx = Variable(idrx)\n",
    "# #         print('xr.shape', xr.shape)\n",
    "# #         print('xr', xr[10:20, 100:200])\n",
    "# #         print('xr*idrx.shape', (xr*idrx).shape)\n",
    "# #         print('xr*idrx', (xr*idrx)[10:20, 100:200])\n",
    "# #         print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA', xr * idrx == xr)\n",
    "# #         for c in xr * idrx == xr:\n",
    "# #             print(c)\n",
    "#         xt = xr * idrx + xf * (1 - idrx)\n",
    "#         xb = xr * (1 - idrx) + xf * idrx\n",
    "# #         print('xt', xt)\n",
    "# #         print('xb', xb)\n",
    "#         # top : real\n",
    "#         xt = F.relu(self.t1(xt))\n",
    "#         # bottom : fake\n",
    "#         xb = F.relu(self.b1(xb))\n",
    "#         # combined\n",
    "# #         print(xt.shape, xb.shape)\n",
    "#         x = torch.cat((xt, xb), 1)\n",
    "# #         print('x', x)\n",
    "#         x = torch.tanh(self.fc(x))\n",
    "# #         print('xxxx', x.shape)\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('filt', filt[:10, :10])\n",
    "#         # apply filter, aggregate\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('filt', filt[:10, :10])\n",
    "#         x = filt * x\n",
    "# #         print('x', x)\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('xxxx', x.shape)\n",
    "# #         print('x', x[:10, :10])\n",
    "# #         print(x.mean(dim = 1).shape, x.mean(dim = 1))\n",
    "#         x = x.mean(dim = 1).squeeze()\n",
    "# #         print('x', x)\n",
    "# #         print('xxxx', x.shape)\n",
    "#         # use sign, because of swapping\n",
    "#         sgn = idr * 2 - 1\n",
    "#         if self.use_cuda: \n",
    "#             sgn = sgn.cuda()\n",
    "#         sgn = Variable(sgn.float())\n",
    "#         x = sgn * x\n",
    "# #         print('x', x)\n",
    "# #         print(\"##########\"*40)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # latent_vec_size = 100\n",
    "# # vec_size = 1000\n",
    "\n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, length),\n",
    "#     torch.nn.Sigmoid()\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # networks\n",
    "# netD = NetD(False)\n",
    "# print(netG)\n",
    "# print(netD)\n",
    "# optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "# optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "# one = torch.FloatTensor([1])\n",
    "# mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "cuda = False\n",
    "if cuda is True:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(length=6):\n",
    "     return Variable(torch.IntTensor(np.random.choice([0, 1], size=(batch_size, length))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3706])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_batch(train, batch_size=batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 5. MSE distance between random real and fake samples 0.6790403127670288\n",
      "Epoch number 11. MSE distance between random real and fake samples 0.6927008032798767\n",
      "Epoch number 17. MSE distance between random real and fake samples 0.7419093251228333\n",
      "Epoch number 23. MSE distance between random real and fake samples 0.6266229152679443\n",
      "Epoch number 29. MSE distance between random real and fake samples 0.6402091979980469\n",
      "Epoch number 35. MSE distance between random real and fake samples 0.6480994820594788\n",
      "Epoch number 41. MSE distance between random real and fake samples 0.5644475221633911\n",
      "Epoch number 47. MSE distance between random real and fake samples 0.6449011564254761\n",
      "Epoch number 52. MSE distance between random real and fake samples 0.619330108165741\n",
      "Epoch number 58. MSE distance between random real and fake samples 0.548399031162262\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "gen_iterations = 0\n",
    "eval_losses = []\n",
    "for epoch in range(epochs):\n",
    "#     data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < steps_per_epoch:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter and i < len(data_loader):\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "#             X, _ = data_iter.next()\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             print(X >= 0.5)\n",
    "# #             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "#             print(real.shape, fake.shape)\n",
    "    \n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real)\n",
    "#             print('fake', fake[:,0].sum())\n",
    "            out = netD(real, fake)\n",
    "            \n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "#             print(out.shape)\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter and i < len(data_loader):\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "#             print('output_D', outputD.item(), gen_iterations)\n",
    "#             print('output_G', outputG.item(), gen_iterations)\n",
    "#             print('std_D', stdD.item(), gen_iterations)\n",
    "#             print('std_G', stdG.item(), gen_iterations)\n",
    "            \n",
    "            # evaluation\n",
    "            if gen_iterations % 100 == 0: # todo- to change\n",
    "#                 gen.eval()\n",
    "#                 z_vector_eval = make_some_noise(128)\n",
    "#                 fake_rows_eval = gen(z_vector_eval)\n",
    "#                 real_rows_eval = get_random_batch(train, 128)\n",
    "        #         print(fake_rows[0][:10]) enable to see some results\n",
    "                eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "                eval_losses.append(eval_loss)\n",
    "                print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "\n",
    "#     #         print(gen_iterations)\n",
    "#             if gen_iterations % 100 == 0:\n",
    "#                 if not isdir('./images/{0}'.format(name)):\n",
    "#                     os.makedirs('./images/{0}'.format(name))\n",
    "#                 real = real.data[0:100,:]\n",
    "#                 real = real.view(real.size(0), 1, 28, 28)\n",
    "#                 vutils.save_image(real, './images/{0}/real_samples.png'.format(name, gen_iterations))\n",
    "#                 noise = torch.randn(min(100, batch_size), nz)\n",
    "#                 if cuda: \n",
    "#                     noise = noise.cuda()\n",
    "#                 fake = netG(Variable(noise, volatile=True))\n",
    "# #                 print('real', real)\n",
    "# #                 print('fake', fake)\n",
    "#                 # fake = (fake.data >= 0.5).float()\n",
    "#                 R = torch.rand(fake.size())\n",
    "#                 fake = (fake.data.cpu() >= R).float()\n",
    "#                 fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "#                 vutils.save_image(fake, './images/{0}/fake_samples_{1}.png'.format(name, gen_iterations))\n",
    "#     # do checkpointing\n",
    "# #     if not isdir('./checkpoint/{0}'.format(name)):\n",
    "# #         os.makedirs('./checkpoint/{0}'.format(name))\n",
    "#     torch.save(netG.state_dict(), './checkpoint/{0}/netG_epoch_{1}.pth'.format(name, epoch))\n",
    "#     torch.save(netD.state_dict(), './checkpoint/{0}/netD_epoch_{1}.pth'.format(name, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, nz)\n",
    "if cuda: \n",
    "    noise = noise.cuda()\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(359335)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(767)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1152)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226310"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348971"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gen_iterations = 0\n",
    "# for epoch in range(epochs):\n",
    "# #     data_iter = iter(data_loader)\n",
    "#     i = 0\n",
    "#     while i < 10:\n",
    "#         ############################\n",
    "#         # (1) Update D network\n",
    "#         ###########################\n",
    "#         for p in netD.parameters(): # reset requires_grad\n",
    "#             p.requires_grad = True # they are set to False below in netG update\n",
    "#         d_iter = d_iter\n",
    "#         j = 0\n",
    "#         while j < d_iter and i < 10:\n",
    "#             j += 1\n",
    "#             # load real data\n",
    "#             i += 1\n",
    "#             X = getRealSample()\n",
    "#             X = X.view(X.size(0), -1).float()\n",
    "# #             X = (X >= 0.5).float()\n",
    "#             if cuda: \n",
    "#                 X = X.cuda()\n",
    "#             real = Variable(X, requires_grad=True)\n",
    "#             # generate fake data\n",
    "#             noise = torch.randn(batch_size, nz)\n",
    "#             if cuda: \n",
    "#                 noise = noise.cuda()\n",
    "#             with torch.no_grad():\n",
    "#                 noisev = Variable(noise) # totally freeze netG\n",
    "#             fake = (Variable(netG(noisev).data, requires_grad=True) > 0.5).float()\n",
    "#             # compute gradient, take step\n",
    "#             netD.zero_grad()\n",
    "#             print(real, fake)\n",
    "#             out = netD(real, fake)\n",
    "# #             print(real.shape, fake.shape, out.shape)\n",
    "#             outputD = torch.mean(out) + lamba * out.norm()\n",
    "#             stdD = torch.std(out)\n",
    "# #             print('outputD.shape', outputD)\n",
    "#             outputD.backward(mone)\n",
    "#             optimizerD.step()\n",
    "# #             break\n",
    "# #         break\n",
    "# #     break\n",
    "\n",
    "#             g_iter = g_iter\n",
    "#             j = 0\n",
    "#             while j < g_iter and i < 10:\n",
    "#                 j += 1\n",
    "#                 for p in netD.parameters():\n",
    "#                     p.requires_grad = False # to avoid computation\n",
    "#                 netG.zero_grad()\n",
    "#                 # load real data\n",
    "#                 i += 1\n",
    "#                 X = getRealSample()\n",
    "#                 X = X.view(X.size(0), -1)\n",
    "# #                 X = (X >= 0.5).float()\n",
    "#                 if cuda: \n",
    "#                     X = X.cuda()\n",
    "#                 real = Variable(X.float(), requires_grad=True)\n",
    "#                 # update generator\n",
    "#                 noise = torch.randn(batch_size, nz)\n",
    "#                 if cuda: \n",
    "#                     noise = noise.cuda()\n",
    "#                 noisev = Variable(noise)\n",
    "#                 fake = Variable((netG(noisev) >=0.5).float(), requires_grad=True)\n",
    "#                 print(\"####\"*40)\n",
    "#                 print('REEEEAL', real)\n",
    "#                 print('FAAAKE', fake)\n",
    "#                 print(\"####\"*40)\n",
    "# #                 print(real.shape, fake.shape)\n",
    "#                 out = netD(real, fake)\n",
    "#                 outputG = torch.mean(out) + lamba * out.norm()\n",
    "#                 stdG = torch.std(out)\n",
    "#                 outputG.backward(one)\n",
    "#                 optimizerG.step()\n",
    "#                 gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f ' % (epoch, epochs, i, 10, gen_iterations, outputD.data.item(), outputG.data.item()))\n",
    "#             print('output_D', outputD.data.item(), gen_iterations)\n",
    "#             print('output_G', outputG.data.item(), gen_iterations)\n",
    "#             print('std_D', stdD.data.item(), gen_iterations)\n",
    "#             print('std_G', stdG.data.item(), gen_iterations)\n",
    "# #             if gen_iterations % 100 == 0:\n",
    "# #                 if not isdir('./images/{0}'.format(name)):\n",
    "# #                     os.mkdir('./images/{0}'.format(name))\n",
    "# #                 real = real.data[0:100,:]\n",
    "# #                 real = real.view(real.size(0), 1, 28, 28)\n",
    "# #                 vutils.save_image(real, './images/{0}/real_samples.png'.format(name, gen_iterations))\n",
    "# #                 noise = torch.randn(min(100, batch_size), nz)\n",
    "# #                 if cuda: \n",
    "# #                     noise = noise.cuda()\n",
    "# #                 fake = netG(Variable(noise, volatile=True))\n",
    "# #                 # fake = (fake.data >= 0.5).float()\n",
    "# #                 R = torch.rand(fake.size())\n",
    "# #                 fake = (fake.data.cpu() >= R).float()\n",
    "# #                 fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "# #                 vutils.save_image(fake, './images/{0}/fake_samples_{1}.png'.format(name, gen_iterations))\n",
    "\n",
    "# #             # do checkpointing\n",
    "# #             if not isdir('./checkpoint/{0}'.format(name)):\n",
    "# #                 os.mkdir('./checkpoint/{0}'.format(name))\n",
    "# #             torch.save(netG.state_dict(), './checkpoint/{0}/netG_epoch_{1}.pth'.format(name, epoch))\n",
    "# #             torch.save(netD.state_dict(), './checkpoint/{0}/netD_epoch_{1}.pth'.format(name, epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
