{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter \n",
    "import matrix_factorization\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Movielens-100k\n",
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip ml-100k.zip\n",
    "!cd ml-100k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('ml-100k.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    print (str(n_users) + ' users')\n",
    "    print (str(n_items) + ' items')\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Sparsity: 6.30%\n"
     ]
    }
   ],
   "source": [
    "print ('Sparsity: {:4.2f}%'.format(get_sparsity(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=10, replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.9179628673300955\n",
      "Test mse: 1.0113053267188021\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.304669364224531"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.710139043178159"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5945303210463734"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####################################### GANS ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise(batch_size):\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4625, 0.8899, 0.1385, 0.0472, 0.5384, 0.6960, 0.9908, 0.9145, 0.5137,\n",
       "         0.6804, 0.8615, 0.4312, 0.6037, 0.9117, 0.4875, 0.6603, 0.7794, 0.3952,\n",
       "         0.4483, 0.1756, 0.2478, 0.1236, 0.5203, 0.9911, 0.0862, 0.7621, 0.7322,\n",
       "         0.2437, 0.9434, 0.2282, 0.7428, 0.1790, 0.4105, 0.3193, 0.7175, 0.1299,\n",
       "         0.0746, 0.1848, 0.7205, 0.9461, 0.6725, 0.6661, 0.1551, 0.5163, 0.9645,\n",
       "         0.6228, 0.6040, 0.0699, 0.2416, 0.7396, 0.7768, 0.7044, 0.6805, 0.9212,\n",
       "         0.3998, 0.4781, 0.7919, 0.1231, 0.0625, 0.3906, 0.3922, 0.2182, 0.4140,\n",
       "         0.5691, 0.3555, 0.2843, 0.9089, 0.5347, 0.3190, 0.8424, 0.1724, 0.9083,\n",
       "         0.5839, 0.5719, 0.1140, 0.8031, 0.0887, 0.0116, 0.7744, 0.4654, 0.6525,\n",
       "         0.8710, 0.9873, 0.5563, 0.8061, 0.2056, 0.1669, 0.8843, 0.9240, 0.0941,\n",
       "         0.0692, 0.3054, 0.9895, 0.8850, 0.4217, 0.8719, 0.8767, 0.7187, 0.7997,\n",
       "         0.0846],\n",
       "        [0.7759, 0.3813, 0.0787, 0.3424, 0.7061, 0.4004, 0.9523, 0.9829, 0.7490,\n",
       "         0.7930, 0.3726, 0.8759, 0.0842, 0.0940, 0.1474, 0.8525, 0.0543, 0.2447,\n",
       "         0.8190, 0.4676, 0.6791, 0.2262, 0.6551, 0.2604, 0.9143, 0.9481, 0.4696,\n",
       "         0.1588, 0.6281, 0.9175, 0.1020, 0.6477, 0.0568, 0.5892, 0.8259, 0.5325,\n",
       "         0.5267, 0.5477, 0.9650, 0.4105, 0.7091, 0.7539, 0.1089, 0.9349, 0.5272,\n",
       "         0.3715, 0.0148, 0.2250, 0.8894, 0.9693, 0.0393, 0.3827, 0.0541, 0.2601,\n",
       "         0.4873, 0.7126, 0.2585, 0.4199, 0.7197, 0.6009, 0.7862, 0.7044, 0.3833,\n",
       "         0.4704, 0.3446, 0.0612, 0.9623, 0.7322, 0.5240, 0.0766, 0.1092, 0.2289,\n",
       "         0.4378, 0.1611, 0.6597, 0.4906, 0.3302, 0.6429, 0.9837, 0.2566, 0.1427,\n",
       "         0.9081, 0.0367, 0.1326, 0.9372, 0.4922, 0.2484, 0.8045, 0.0747, 0.9349,\n",
       "         0.0403, 0.2180, 0.1327, 0.3089, 0.6710, 0.5173, 0.7765, 0.3507, 0.7772,\n",
       "         0.4174],\n",
       "        [0.8933, 0.4190, 0.6681, 0.8710, 0.7352, 0.8089, 0.7582, 0.8797, 0.5696,\n",
       "         0.4129, 0.4720, 0.3494, 0.3527, 0.2968, 0.1784, 0.3895, 0.5543, 0.4736,\n",
       "         0.4291, 0.0226, 0.6117, 0.9319, 0.1009, 0.8157, 0.8066, 0.8535, 0.2042,\n",
       "         0.8900, 0.4611, 0.4039, 0.8842, 0.7482, 0.8040, 0.0015, 0.0556, 0.6521,\n",
       "         0.1802, 0.2967, 0.8726, 0.6233, 0.6132, 0.8241, 0.2317, 0.5308, 0.6909,\n",
       "         0.5802, 0.8059, 0.6866, 0.4646, 0.0392, 0.8144, 0.7795, 0.0149, 0.6981,\n",
       "         0.1307, 0.0496, 0.0553, 0.8627, 0.5344, 0.6697, 0.9965, 0.8607, 0.8070,\n",
       "         0.8899, 0.9352, 0.3395, 0.5816, 0.7271, 0.2205, 0.3196, 0.6971, 0.5954,\n",
       "         0.7680, 0.3761, 0.8360, 0.4402, 0.7562, 0.8389, 0.8744, 0.8861, 0.0463,\n",
       "         0.6742, 0.6429, 0.4727, 0.0852, 0.6364, 0.4591, 0.7694, 0.2233, 0.2872,\n",
       "         0.0498, 0.2447, 0.2086, 0.0231, 0.2694, 0.0702, 0.4243, 0.3150, 0.1464,\n",
       "         0.5990],\n",
       "        [0.7946, 0.8068, 0.7178, 0.4141, 0.2425, 0.3094, 0.4020, 0.3907, 0.1490,\n",
       "         0.8363, 0.7785, 0.9704, 0.3539, 0.7087, 0.0979, 0.6503, 0.8813, 0.0745,\n",
       "         0.8893, 0.0085, 0.3152, 0.0197, 0.7384, 0.1479, 0.1268, 0.8363, 0.9485,\n",
       "         0.2510, 0.3937, 0.5549, 0.2857, 0.4098, 0.5229, 0.1445, 0.7895, 0.4493,\n",
       "         0.1874, 0.3459, 0.0086, 0.3558, 0.6377, 0.0886, 0.5456, 0.0586, 0.2201,\n",
       "         0.0722, 0.5872, 0.9673, 0.6305, 0.0780, 0.0728, 0.1033, 0.8491, 0.9160,\n",
       "         0.2869, 0.2770, 0.3864, 0.6716, 0.9123, 0.9923, 0.8790, 0.0291, 0.2880,\n",
       "         0.4664, 0.8292, 0.1194, 0.0236, 0.9683, 0.1619, 0.9509, 0.6925, 0.6791,\n",
       "         0.7737, 0.0300, 0.3164, 0.3829, 0.6643, 0.0130, 0.3594, 0.6543, 0.5110,\n",
       "         0.2079, 0.0184, 0.2720, 0.1732, 0.6890, 0.3926, 0.1363, 0.3712, 0.4972,\n",
       "         0.9099, 0.8689, 0.4880, 0.4565, 0.6998, 0.1136, 0.6328, 0.5422, 0.9201,\n",
       "         0.8696],\n",
       "        [0.1482, 0.1976, 0.4870, 0.8031, 0.6934, 0.6237, 0.1736, 0.2657, 0.9302,\n",
       "         0.2268, 0.0204, 0.9938, 0.4396, 0.4528, 0.1477, 0.2736, 0.6060, 0.9152,\n",
       "         0.5112, 0.9910, 0.6457, 0.2762, 0.0675, 0.9782, 0.5061, 0.8434, 0.2684,\n",
       "         0.8008, 0.8064, 0.2911, 0.6972, 0.6441, 0.3086, 0.1944, 0.8039, 0.0079,\n",
       "         0.4791, 0.5474, 0.0683, 0.0750, 0.1469, 0.8898, 0.8440, 0.6618, 0.8433,\n",
       "         0.0644, 0.2696, 0.8769, 0.9549, 0.1172, 0.7799, 0.2059, 0.3203, 0.1838,\n",
       "         0.6380, 0.5082, 0.8636, 0.8823, 0.2408, 0.3657, 0.8581, 0.9427, 0.4931,\n",
       "         0.2350, 0.1424, 0.7951, 0.7374, 0.6474, 0.6148, 0.4771, 0.8763, 0.1604,\n",
       "         0.4354, 0.7953, 0.3053, 0.5515, 0.3373, 0.6450, 0.7340, 0.7281, 0.9476,\n",
       "         0.2281, 0.9588, 0.3811, 0.5362, 0.6484, 0.9849, 0.2414, 0.5663, 0.1563,\n",
       "         0.7299, 0.7561, 0.8694, 0.2356, 0.6635, 0.8279, 0.0012, 0.8972, 0.1676,\n",
       "         0.0366]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_some_noise(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator class\n",
    "\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(800,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining discriminator class\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(200,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(ratings.shape[1], 1)\n",
    "gen = generator(100, ratings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=1682, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=1000, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=800, out_features=1682, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps = 300\n",
    "g_steps = 300\n",
    "\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# printing_steps = 200\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [3., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]\n",
    "    \n",
    "get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1. MSE distance between random real and fake samples 1298359.125\n",
      "Epoch number 2. MSE distance between random real and fake samples 1268023.75\n",
      "Epoch number 3. MSE distance between random real and fake samples 1268135.5\n",
      "Epoch number 4. MSE distance between random real and fake samples 1233828.5\n",
      "Epoch number 5. MSE distance between random real and fake samples 1125817.75\n",
      "Epoch number 6. MSE distance between random real and fake samples 995061.8125\n",
      "Epoch number 7. MSE distance between random real and fake samples 831373.25\n",
      "Epoch number 8. MSE distance between random real and fake samples 670957.875\n",
      "Epoch number 9. MSE distance between random real and fake samples 550445.125\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "eval_losses = []\n",
    "for epoch in range(10):\n",
    "#     print (epoch)\n",
    "\n",
    "    # training discriminator\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()\n",
    "        \n",
    "        # training discriminator on real data\n",
    "        real_rows = get_random_batch(train, batch_size)\n",
    "        discriminator_real_outputs = dis(real_rows)\n",
    "   \n",
    "        dis_real_loss = criteriond1(discriminator_real_outputs, Variable(torch.ones(batch_size,1)))\n",
    "    \n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # training discriminator on data produced by generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        #output from generator is generated        \n",
    "        fake_rows = gen(z_vector).detach()\n",
    "#         print(fake_rows[:20])\n",
    "        dis_fake_out = dis(fake_rows)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out, Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()\n",
    "        \n",
    "    # training generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()\n",
    "        \n",
    "        #generating data for input for generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        \n",
    "        fake_rows = gen(z_vector)\n",
    "#         print(fake_rows.shape, z_vector.shape)\n",
    "#         print(fake_rows[:20])\n",
    "        dis_out_gen_training = dis(fake_rows)\n",
    "        gen_loss = criteriond2(dis_out_gen_training, Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()\n",
    "\n",
    "    # evaluation\n",
    "    if epoch % 10: # todo- to change\n",
    "        gen.eval()\n",
    "        z_vector_eval = make_some_noise(128)\n",
    "        fake_rows_eval = gen(z_vector_eval)\n",
    "        real_rows_eval = get_random_batch(train, 128)\n",
    "#         print(fake_rows[0][:10]) enable to see some results\n",
    "        eval_loss = F.mse_loss(fake_rows_eval, real_rows_eval, reduction='sum')\n",
    "        eval_losses.append(eval_loss)\n",
    "        print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "#         print('Epoch number {}. L1 distance between random real and fake samples {}'.format(epoch, torch.sum(torch.abs(fake_rows_eval - real_rows_eval))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vector = make_some_noise(16)\n",
    "fake_rows = gen(z_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9296, 1.1387, 1.5669, 4.4206, 0.4383, 0.2694, 4.9433, 4.7220, 4.8977],\n",
       "        [4.9277, 1.1527, 1.5739, 4.4191, 0.4444, 0.2746, 4.9425, 4.7164, 4.8955],\n",
       "        [4.9312, 1.1420, 1.5630, 4.4317, 0.4344, 0.2639, 4.9453, 4.7252, 4.8993],\n",
       "        [4.9308, 1.1444, 1.5674, 4.4309, 0.4359, 0.2632, 4.9453, 4.7279, 4.9002],\n",
       "        [4.9317, 1.1397, 1.5696, 4.4296, 0.4315, 0.2638, 4.9450, 4.7237, 4.8992],\n",
       "        [4.9310, 1.1437, 1.5655, 4.4315, 0.4401, 0.2631, 4.9450, 4.7255, 4.8991],\n",
       "        [4.9325, 1.1276, 1.5595, 4.4367, 0.4300, 0.2606, 4.9464, 4.7292, 4.9007],\n",
       "        [4.9297, 1.1481, 1.5686, 4.4245, 0.4381, 0.2660, 4.9439, 4.7202, 4.8971],\n",
       "        [4.9299, 1.1483, 1.5665, 4.4282, 0.4392, 0.2659, 4.9437, 4.7233, 4.8975],\n",
       "        [4.9301, 1.1490, 1.5645, 4.4264, 0.4349, 0.2656, 4.9448, 4.7249, 4.8983],\n",
       "        [4.9315, 1.1431, 1.5661, 4.4319, 0.4339, 0.2620, 4.9456, 4.7275, 4.8996],\n",
       "        [4.9292, 1.1445, 1.5628, 4.4257, 0.4406, 0.2674, 4.9435, 4.7210, 4.8979],\n",
       "        [4.9312, 1.1416, 1.5671, 4.4320, 0.4351, 0.2638, 4.9448, 4.7282, 4.8990],\n",
       "        [4.9294, 1.1467, 1.5673, 4.4256, 0.4388, 0.2665, 4.9446, 4.7207, 4.8984],\n",
       "        [4.9290, 1.1445, 1.5668, 4.4238, 0.4386, 0.2691, 4.9433, 4.7205, 4.8969],\n",
       "        [4.9295, 1.1496, 1.5724, 4.4223, 0.4402, 0.2676, 4.9440, 4.7211, 4.8972]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we see generator produces very similar vectors \n",
    "fake_rows[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os\n",
    "# from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrD = 5e-4\n",
    "# lrG = 5e-4\n",
    "# batch_size = 100\n",
    "# cuda = True\n",
    "# epochs = 1000\n",
    "# device = 5\n",
    "# seed = 42\n",
    "# nz = 100\n",
    "# d_iter = 5\n",
    "# g_iter = 1\n",
    "# lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "# name = \"mnist-experiment\"\n",
    "# # configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "# torch.manual_seed(seed)\n",
    "# # if cuda:\n",
    "# # #     torch.cuda.set_device('cuda')\n",
    "# #     torch.cuda.manual_seed(seed)\n",
    "# # data_loader = torch.utils.data.DataLoader(\n",
    "# # datasets.MNIST('../data', train=True, download=True,\n",
    "# # transform=transforms.Compose([transforms.ToTensor(),])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 100\n",
    "cuda = True\n",
    "epochs = 1000\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "name = \"mnist-experiment\"\n",
    "# configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length=6\n",
    "# batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=1024, out_features=784, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=784, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(28 * 28, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(28 * 28, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, 28 * 28)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "        x = filt * x\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "netG = torch.nn.Sequential(\n",
    "    torch.nn.Linear(nz, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 28 * 28),\n",
    "    torch.nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "# networks\n",
    "netD = NetD(use_cuda=False)\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NetD(torch.nn.Module):\n",
    "#     def __init__(self, use_cuda=True):\n",
    "#         super(NetD, self).__init__()\n",
    "#         self.use_cuda = use_cuda\n",
    "#         # top\n",
    "#         self.t1 = torch.nn.Linear(length, 1024)\n",
    "#         # bottom\n",
    "#         self.b1 = torch.nn.Linear(length, 1024)\n",
    "#         # combined\n",
    "#         self.fc = torch.nn.Linear(2 * 1024, length)\n",
    "#     def forward(self, xr, xf):\n",
    "#         # get filt\n",
    "# #         print(\"##########\"*40)\n",
    "#         filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "# #         if (filt == xr * xf).all():\n",
    "# #             print('AAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
    "            \n",
    "# #         print('xr & xf', xr * xf)\n",
    "# #         print('filt', filt)\n",
    "# #         print('xr.shape, xf.shape', xr.shape, xf.shape)\n",
    "# #         print('filt.shape', filt.shape)\n",
    "# #         print('xr', xr)\n",
    "# #         print('xf', xf)\n",
    "# #         print('filt', filt)\n",
    "# # #         return filt\n",
    "# #         # random swap\n",
    "#         idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "# #         print(idr.shape)\n",
    "# #         print('idr', idr)\n",
    "#         idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "# #         print('idrx', idrx)\n",
    "# #         print('idrx.shape', idrx.shape)\n",
    "# #         print('idrx', idrx[10:20, 100:200])\n",
    "#         if self.use_cuda: \n",
    "#             idrx = idrx.cuda()\n",
    "#         idrx = Variable(idrx)\n",
    "# #         print('xr.shape', xr.shape)\n",
    "# #         print('xr', xr[10:20, 100:200])\n",
    "# #         print('xr*idrx.shape', (xr*idrx).shape)\n",
    "# #         print('xr*idrx', (xr*idrx)[10:20, 100:200])\n",
    "# #         print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA', xr * idrx == xr)\n",
    "# #         for c in xr * idrx == xr:\n",
    "# #             print(c)\n",
    "#         xt = xr * idrx + xf * (1 - idrx)\n",
    "#         xb = xr * (1 - idrx) + xf * idrx\n",
    "# #         print('xt', xt)\n",
    "# #         print('xb', xb)\n",
    "#         # top : real\n",
    "#         xt = F.relu(self.t1(xt))\n",
    "#         # bottom : fake\n",
    "#         xb = F.relu(self.b1(xb))\n",
    "#         # combined\n",
    "# #         print(xt.shape, xb.shape)\n",
    "#         x = torch.cat((xt, xb), 1)\n",
    "# #         print('x', x)\n",
    "#         x = torch.tanh(self.fc(x))\n",
    "# #         print('xxxx', x.shape)\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('filt', filt[:10, :10])\n",
    "#         # apply filter, aggregate\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('filt', filt[:10, :10])\n",
    "#         x = filt * x\n",
    "# #         print('x', x)\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('xxxx', x.shape)\n",
    "# #         print('x', x[:10, :10])\n",
    "# #         print(x.mean(dim = 1).shape, x.mean(dim = 1))\n",
    "#         x = x.mean(dim = 1).squeeze()\n",
    "# #         print('x', x)\n",
    "# #         print('xxxx', x.shape)\n",
    "#         # use sign, because of swapping\n",
    "#         sgn = idr * 2 - 1\n",
    "#         if self.use_cuda: \n",
    "#             sgn = sgn.cuda()\n",
    "#         sgn = Variable(sgn.float())\n",
    "#         x = sgn * x\n",
    "# #         print('x', x)\n",
    "# #         print(\"##########\"*40)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # latent_vec_size = 100\n",
    "# # vec_size = 1000\n",
    "\n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, length),\n",
    "#     torch.nn.Sigmoid()\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # networks\n",
    "# netD = NetD(False)\n",
    "# print(netG)\n",
    "# print(netD)\n",
    "# optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "# optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "# one = torch.FloatTensor([1])\n",
    "# mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "cuda = False\n",
    "if cuda is True:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(length=6):\n",
    "     return Variable(torch.IntTensor(np.random.choice([0, 1], size=(batch_size, length))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 1],\n",
       "        [0, 1, 1, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 1],\n",
       "        [1, 1, 1, 1, 0, 1],\n",
       "        [0, 0, 1, 0, 1, 1],\n",
       "        [0, 0, 1, 1, 0, 0],\n",
       "        [1, 0, 0, 1, 1, 0],\n",
       "        [1, 1, 0, 1, 1, 1],\n",
       "        [1, 0, 0, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0],\n",
       "        [0, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [0, 1, 1, 0, 0, 1],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [1, 0, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 1, 1, 0, 0],\n",
       "        [0, 1, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 0, 1, 1],\n",
       "        [1, 0, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 1],\n",
       "        [1, 0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 1, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 1, 1, 0],\n",
       "        [1, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 1, 1],\n",
       "        [0, 1, 1, 0, 1, 1],\n",
       "        [0, 0, 1, 0, 1, 1],\n",
       "        [0, 1, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 0],\n",
       "        [1, 0, 0, 1, 0, 1],\n",
       "        [1, 0, 1, 0, 1, 1],\n",
       "        [1, 1, 0, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 1, 0, 1, 0],\n",
       "        [0, 1, 1, 1, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 1],\n",
       "        [1, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 1],\n",
       "        [1, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 1, 1],\n",
       "        [0, 1, 1, 0, 1, 1],\n",
       "        [0, 1, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 0, 0],\n",
       "        [0, 1, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 1, 0],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [0, 0, 1, 1, 0, 1],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 1, 0, 1, 0],\n",
       "        [1, 0, 1, 1, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 1],\n",
       "        [1, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 1, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 1, 1, 1],\n",
       "        [1, 1, 0, 0, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 0],\n",
       "        [1, 0, 1, 1, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 1, 1, 0, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRealSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000][6/600][1] Loss_D: 0.550235 Loss_G: 0.548149 \n",
      "output_D 0.550235390663147 1\n",
      "output_G 0.5481492877006531 1\n",
      "std_D 0.014410619623959064 1\n",
      "std_G 0.013932987116277218 1\n",
      "[0/1000][12/600][2] Loss_D: 0.154002 Loss_G: 0.156405 \n",
      "output_D 0.15400175750255585 2\n",
      "output_G 0.15640494227409363 2\n",
      "std_D 0.03249087184667587 2\n",
      "std_G 0.033301349729299545 2\n",
      "[0/1000][18/600][3] Loss_D: 0.147373 Loss_G: 0.151227 \n",
      "output_D 0.14737315475940704 3\n",
      "output_G 0.15122736990451813 3\n",
      "std_D 0.03753726929426193 3\n",
      "std_G 0.032259900122880936 3\n",
      "[0/1000][24/600][4] Loss_D: 0.138795 Loss_G: 0.144281 \n",
      "output_D 0.13879451155662537 4\n",
      "output_G 0.1442805379629135 4\n",
      "std_D 0.041734933853149414 4\n",
      "std_G 0.0332103855907917 4\n",
      "[0/1000][30/600][5] Loss_D: 0.082665 Loss_G: 0.084773 \n",
      "output_D 0.08266539871692657 5\n",
      "output_G 0.08477341383695602 5\n",
      "std_D 0.09033136814832687 5\n",
      "std_G 0.09517668932676315 5\n",
      "[0/1000][36/600][6] Loss_D: 0.093970 Loss_G: 0.117722 \n",
      "output_D 0.09397010505199432 6\n",
      "output_G 0.11772189289331436 6\n",
      "std_D 0.04645969718694687 6\n",
      "std_G 0.0751977488398552 6\n",
      "[0/1000][42/600][7] Loss_D: 0.138219 Loss_G: 0.085180 \n",
      "output_D 0.13821931183338165 7\n",
      "output_G 0.08517979085445404 7\n",
      "std_D 0.0402061827480793 7\n",
      "std_G 0.11812890321016312 7\n",
      "[0/1000][48/600][8] Loss_D: 0.133215 Loss_G: 0.100391 \n",
      "output_D 0.13321489095687866 8\n",
      "output_G 0.10039088129997253 8\n",
      "std_D 0.03074117749929428 8\n",
      "std_G 0.07877425104379654 8\n",
      "[0/1000][54/600][9] Loss_D: 0.106624 Loss_G: 0.090071 \n",
      "output_D 0.10662443190813065 9\n",
      "output_G 0.09007054567337036 9\n",
      "std_D 0.05783025175333023 9\n",
      "std_G 0.09207643568515778 9\n",
      "[0/1000][60/600][10] Loss_D: 0.094896 Loss_G: 0.074371 \n",
      "output_D 0.09489551931619644 10\n",
      "output_G 0.07437095791101456 10\n",
      "std_D 0.06542913615703583 10\n",
      "std_G 0.08459743112325668 10\n",
      "[0/1000][66/600][11] Loss_D: 0.079553 Loss_G: 0.117008 \n",
      "output_D 0.07955293357372284 11\n",
      "output_G 0.11700756847858429 11\n",
      "std_D 0.09539077430963516 11\n",
      "std_G 0.07691606879234314 11\n",
      "[0/1000][72/600][12] Loss_D: 0.139160 Loss_G: 0.147046 \n",
      "output_D 0.13916003704071045 12\n",
      "output_G 0.14704570174217224 12\n",
      "std_D 0.05440830439329147 12\n",
      "std_G 0.03322916477918625 12\n",
      "[0/1000][78/600][13] Loss_D: 0.139229 Loss_G: 0.144854 \n",
      "output_D 0.1392287164926529 13\n",
      "output_G 0.14485430717468262 13\n",
      "std_D 0.04308326169848442 13\n",
      "std_G 0.03260431066155434 13\n",
      "[0/1000][84/600][14] Loss_D: 0.152334 Loss_G: 0.146200 \n",
      "output_D 0.15233397483825684 14\n",
      "output_G 0.1461998075246811 14\n",
      "std_D 0.03907880187034607 14\n",
      "std_G 0.03233291953802109 14\n",
      "[0/1000][90/600][15] Loss_D: 0.143792 Loss_G: 0.149312 \n",
      "output_D 0.1437915563583374 15\n",
      "output_G 0.14931191504001617 15\n",
      "std_D 0.03833494335412979 15\n",
      "std_G 0.03752932697534561 15\n",
      "[0/1000][96/600][16] Loss_D: 0.149923 Loss_G: 0.147451 \n",
      "output_D 0.14992283284664154 16\n",
      "output_G 0.14745137095451355 16\n",
      "std_D 0.03615294024348259 16\n",
      "std_G 0.033862821757793427 16\n",
      "[0/1000][102/600][17] Loss_D: 0.153804 Loss_G: 0.149990 \n",
      "output_D 0.15380360186100006 17\n",
      "output_G 0.14998960494995117 17\n",
      "std_D 0.03628440573811531 17\n",
      "std_G 0.03765502944588661 17\n",
      "[0/1000][108/600][18] Loss_D: 0.140923 Loss_G: 0.145383 \n",
      "output_D 0.14092335104942322 18\n",
      "output_G 0.14538325369358063 18\n",
      "std_D 0.03715738654136658 18\n",
      "std_G 0.03778143972158432 18\n",
      "[0/1000][114/600][19] Loss_D: 0.150512 Loss_G: 0.147139 \n",
      "output_D 0.15051192045211792 19\n",
      "output_G 0.14713886380195618 19\n",
      "std_D 0.03621971607208252 19\n",
      "std_G 0.03231894597411156 19\n",
      "[0/1000][120/600][20] Loss_D: 0.156146 Loss_G: 0.150870 \n",
      "output_D 0.15614639222621918 20\n",
      "output_G 0.1508699506521225 20\n",
      "std_D 0.03312739357352257 20\n",
      "std_G 0.03270891308784485 20\n",
      "[0/1000][126/600][21] Loss_D: 0.156291 Loss_G: 0.162558 \n",
      "output_D 0.15629148483276367 21\n",
      "output_G 0.16255773603916168 21\n",
      "std_D 0.044397447258234024 21\n",
      "std_G 0.03820135071873665 21\n",
      "[0/1000][132/600][22] Loss_D: 0.155922 Loss_G: 0.156182 \n",
      "output_D 0.15592242777347565 22\n",
      "output_G 0.15618176758289337 22\n",
      "std_D 0.039645131677389145 22\n",
      "std_G 0.04446984454989433 22\n",
      "[0/1000][138/600][23] Loss_D: 0.148917 Loss_G: 0.151472 \n",
      "output_D 0.148916557431221 23\n",
      "output_G 0.151472270488739 23\n",
      "std_D 0.038137417286634445 23\n",
      "std_G 0.035634350031614304 23\n",
      "[0/1000][144/600][24] Loss_D: 0.148428 Loss_G: 0.156631 \n",
      "output_D 0.14842839539051056 24\n",
      "output_G 0.1566314846277237 24\n",
      "std_D 0.037138670682907104 24\n",
      "std_G 0.03936077281832695 24\n",
      "[0/1000][150/600][25] Loss_D: 0.162748 Loss_G: 0.157143 \n",
      "output_D 0.1627478301525116 25\n",
      "output_G 0.15714314579963684 25\n",
      "std_D 0.04375120997428894 25\n",
      "std_G 0.04320528730750084 25\n",
      "[0/1000][156/600][26] Loss_D: 0.143943 Loss_G: 0.154522 \n",
      "output_D 0.14394259452819824 26\n",
      "output_G 0.1545220911502838 26\n",
      "std_D 0.03610162436962128 26\n",
      "std_G 0.036767102777957916 26\n",
      "[0/1000][162/600][27] Loss_D: 0.140814 Loss_G: 0.152956 \n",
      "output_D 0.14081409573554993 27\n",
      "output_G 0.15295563638210297 27\n",
      "std_D 0.04867596924304962 27\n",
      "std_G 0.04070376977324486 27\n",
      "[0/1000][168/600][28] Loss_D: 0.144797 Loss_G: 0.149532 \n",
      "output_D 0.14479677379131317 28\n",
      "output_G 0.14953242242336273 28\n",
      "std_D 0.03638385608792305 28\n",
      "std_G 0.040009111166000366 28\n",
      "[0/1000][174/600][29] Loss_D: 0.157613 Loss_G: 0.153039 \n",
      "output_D 0.15761342644691467 29\n",
      "output_G 0.15303906798362732 29\n",
      "std_D 0.04392242804169655 29\n",
      "std_G 0.04340347275137901 29\n",
      "[0/1000][180/600][30] Loss_D: 0.143818 Loss_G: 0.147287 \n",
      "output_D 0.14381837844848633 30\n",
      "output_G 0.14728733897209167 30\n",
      "std_D 0.05020816996693611 30\n",
      "std_G 0.04387499392032623 30\n",
      "[0/1000][186/600][31] Loss_D: 0.153202 Loss_G: 0.154842 \n",
      "output_D 0.15320175886154175 31\n",
      "output_G 0.1548423022031784 31\n",
      "std_D 0.04235303774476051 31\n",
      "std_G 0.03550359606742859 31\n",
      "[0/1000][192/600][32] Loss_D: 0.156581 Loss_G: 0.162553 \n",
      "output_D 0.15658125281333923 32\n",
      "output_G 0.16255272924900055 32\n",
      "std_D 0.037739772349596024 32\n",
      "std_G 0.041756339371204376 32\n",
      "[0/1000][198/600][33] Loss_D: 0.159489 Loss_G: 0.159291 \n",
      "output_D 0.15948939323425293 33\n",
      "output_G 0.15929098427295685 33\n",
      "std_D 0.028972433879971504 33\n",
      "std_G 0.0400364063680172 33\n",
      "[0/1000][204/600][34] Loss_D: 0.167589 Loss_G: 0.164480 \n",
      "output_D 0.16758868098258972 34\n",
      "output_G 0.1644800752401352 34\n",
      "std_D 0.039534930139780045 34\n",
      "std_G 0.03394852206110954 34\n",
      "[0/1000][210/600][35] Loss_D: 0.160516 Loss_G: 0.164465 \n",
      "output_D 0.16051572561264038 35\n",
      "output_G 0.16446515917778015 35\n",
      "std_D 0.0372796505689621 35\n",
      "std_G 0.035135991871356964 35\n",
      "[0/1000][216/600][36] Loss_D: 0.162563 Loss_G: 0.158911 \n",
      "output_D 0.16256342828273773 36\n",
      "output_G 0.15891133248806 36\n",
      "std_D 0.03824298456311226 36\n",
      "std_G 0.03220712020993233 36\n",
      "[0/1000][222/600][37] Loss_D: 0.154684 Loss_G: 0.164904 \n",
      "output_D 0.15468378365039825 37\n",
      "output_G 0.16490359604358673 37\n",
      "std_D 0.02963273413479328 37\n",
      "std_G 0.03193700686097145 37\n",
      "[0/1000][228/600][38] Loss_D: 0.162753 Loss_G: 0.171841 \n",
      "output_D 0.1627526581287384 38\n",
      "output_G 0.17184124886989594 38\n",
      "std_D 0.03373764455318451 38\n",
      "std_G 0.031176885589957237 38\n",
      "[0/1000][234/600][39] Loss_D: 0.161528 Loss_G: 0.162413 \n",
      "output_D 0.16152772307395935 39\n",
      "output_G 0.16241255402565002 39\n",
      "std_D 0.03401622921228409 39\n",
      "std_G 0.03922693803906441 39\n",
      "[0/1000][240/600][40] Loss_D: 0.163088 Loss_G: 0.160538 \n",
      "output_D 0.16308830678462982 40\n",
      "output_G 0.16053776443004608 40\n",
      "std_D 0.03364305570721626 40\n",
      "std_G 0.03468281775712967 40\n",
      "[0/1000][246/600][41] Loss_D: 0.167465 Loss_G: 0.167482 \n",
      "output_D 0.16746503114700317 41\n",
      "output_G 0.16748222708702087 41\n",
      "std_D 0.03704372048377991 41\n",
      "std_G 0.03328573331236839 41\n",
      "[0/1000][252/600][42] Loss_D: 0.157422 Loss_G: 0.166277 \n",
      "output_D 0.1574217826128006 42\n",
      "output_G 0.166277214884758 42\n",
      "std_D 0.03441166505217552 42\n",
      "std_G 0.03716535493731499 42\n",
      "[0/1000][258/600][43] Loss_D: 0.164572 Loss_G: 0.165187 \n",
      "output_D 0.16457171738147736 43\n",
      "output_G 0.16518746316432953 43\n",
      "std_D 0.03637341409921646 43\n",
      "std_G 0.03663463518023491 43\n",
      "[0/1000][264/600][44] Loss_D: 0.163985 Loss_G: 0.169039 \n",
      "output_D 0.1639852225780487 44\n",
      "output_G 0.1690388023853302 44\n",
      "std_D 0.04338918998837471 44\n",
      "std_G 0.03649372607469559 44\n",
      "[0/1000][270/600][45] Loss_D: 0.160586 Loss_G: 0.171621 \n",
      "output_D 0.16058623790740967 45\n",
      "output_G 0.17162121832370758 45\n",
      "std_D 0.033911995589733124 45\n",
      "std_G 0.03258781507611275 45\n",
      "[0/1000][276/600][46] Loss_D: 0.162496 Loss_G: 0.164509 \n",
      "output_D 0.16249597072601318 46\n",
      "output_G 0.16450943052768707 46\n",
      "std_D 0.03432830795645714 46\n",
      "std_G 0.03725326433777809 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000][282/600][47] Loss_D: 0.155339 Loss_G: 0.163345 \n",
      "output_D 0.15533939003944397 47\n",
      "output_G 0.16334527730941772 47\n",
      "std_D 0.0378115251660347 47\n",
      "std_G 0.03554588556289673 47\n",
      "[0/1000][288/600][48] Loss_D: 0.156068 Loss_G: 0.162488 \n",
      "output_D 0.15606847405433655 48\n",
      "output_G 0.16248765587806702 48\n",
      "std_D 0.039401233196258545 48\n",
      "std_G 0.037283677607774734 48\n",
      "[0/1000][294/600][49] Loss_D: 0.160193 Loss_G: 0.156474 \n",
      "output_D 0.16019290685653687 49\n",
      "output_G 0.15647386014461517 49\n",
      "std_D 0.03516005352139473 49\n",
      "std_G 0.04240961745381355 49\n",
      "[0/1000][300/600][50] Loss_D: 0.166329 Loss_G: 0.160458 \n",
      "output_D 0.16632921993732452 50\n",
      "output_G 0.1604580581188202 50\n",
      "std_D 0.043835531920194626 50\n",
      "std_G 0.03669516369700432 50\n",
      "[0/1000][306/600][51] Loss_D: 0.136536 Loss_G: 0.149003 \n",
      "output_D 0.13653573393821716 51\n",
      "output_G 0.14900299906730652 51\n",
      "std_D 0.07308397442102432 51\n",
      "std_G 0.062139008194208145 51\n",
      "[0/1000][312/600][52] Loss_D: 0.162467 Loss_G: 0.161428 \n",
      "output_D 0.16246680915355682 52\n",
      "output_G 0.16142773628234863 52\n",
      "std_D 0.04539530724287033 52\n",
      "std_G 0.03895149379968643 52\n",
      "[0/1000][318/600][53] Loss_D: 0.165091 Loss_G: 0.159295 \n",
      "output_D 0.1650909036397934 53\n",
      "output_G 0.15929464995861053 53\n",
      "std_D 0.03880380094051361 53\n",
      "std_G 0.04192650318145752 53\n",
      "[0/1000][324/600][54] Loss_D: 0.147937 Loss_G: 0.155733 \n",
      "output_D 0.14793661236763 54\n",
      "output_G 0.15573251247406006 54\n",
      "std_D 0.06543317437171936 54\n",
      "std_G 0.035362858325242996 54\n",
      "[0/1000][330/600][55] Loss_D: 0.164127 Loss_G: 0.164161 \n",
      "output_D 0.16412679851055145 55\n",
      "output_G 0.164160817861557 55\n",
      "std_D 0.04113271087408066 55\n",
      "std_G 0.04510850831866264 55\n",
      "[0/1000][336/600][56] Loss_D: 0.158691 Loss_G: 0.153503 \n",
      "output_D 0.1586906760931015 56\n",
      "output_G 0.15350304543972015 56\n",
      "std_D 0.03829839825630188 56\n",
      "std_G 0.04535869136452675 56\n",
      "[0/1000][342/600][57] Loss_D: 0.160833 Loss_G: 0.158310 \n",
      "output_D 0.1608327329158783 57\n",
      "output_G 0.15831007063388824 57\n",
      "std_D 0.04312868043780327 57\n",
      "std_G 0.04080228880047798 57\n",
      "[0/1000][348/600][58] Loss_D: 0.153547 Loss_G: 0.153537 \n",
      "output_D 0.15354742109775543 58\n",
      "output_G 0.15353719890117645 58\n",
      "std_D 0.04350396245718002 58\n",
      "std_G 0.05997819826006889 58\n",
      "[0/1000][354/600][59] Loss_D: 0.150031 Loss_G: 0.172948 \n",
      "output_D 0.15003100037574768 59\n",
      "output_G 0.17294791340827942 59\n",
      "std_D 0.052280984818935394 59\n",
      "std_G 0.04000932350754738 59\n",
      "[0/1000][360/600][60] Loss_D: 0.161459 Loss_G: 0.169028 \n",
      "output_D 0.16145938634872437 60\n",
      "output_G 0.1690279245376587 60\n",
      "std_D 0.0417787991464138 60\n",
      "std_G 0.042123351246118546 60\n",
      "[0/1000][366/600][61] Loss_D: 0.165253 Loss_G: 0.167257 \n",
      "output_D 0.16525284945964813 61\n",
      "output_G 0.16725726425647736 61\n",
      "std_D 0.04584788531064987 61\n",
      "std_G 0.03905551880598068 61\n",
      "[0/1000][372/600][62] Loss_D: 0.167825 Loss_G: 0.170585 \n",
      "output_D 0.16782505810260773 62\n",
      "output_G 0.17058493196964264 62\n",
      "std_D 0.038957398384809494 62\n",
      "std_G 0.04071890935301781 62\n",
      "[0/1000][378/600][63] Loss_D: 0.159696 Loss_G: 0.157750 \n",
      "output_D 0.15969574451446533 63\n",
      "output_G 0.1577497124671936 63\n",
      "std_D 0.04174661263823509 63\n",
      "std_G 0.04683198034763336 63\n",
      "[0/1000][384/600][64] Loss_D: 0.159725 Loss_G: 0.157955 \n",
      "output_D 0.1597248911857605 64\n",
      "output_G 0.1579553335905075 64\n",
      "std_D 0.04458563029766083 64\n",
      "std_G 0.04488549008965492 64\n",
      "[0/1000][390/600][65] Loss_D: 0.159481 Loss_G: 0.169544 \n",
      "output_D 0.1594809889793396 65\n",
      "output_G 0.16954420506954193 65\n",
      "std_D 0.04989800974726677 65\n",
      "std_G 0.047468479722738266 65\n",
      "[0/1000][396/600][66] Loss_D: 0.166058 Loss_G: 0.172852 \n",
      "output_D 0.1660584658384323 66\n",
      "output_G 0.17285163700580597 66\n",
      "std_D 0.042544860392808914 66\n",
      "std_G 0.042374640703201294 66\n",
      "[0/1000][402/600][67] Loss_D: 0.162427 Loss_G: 0.172424 \n",
      "output_D 0.1624266356229782 67\n",
      "output_G 0.17242448031902313 67\n",
      "std_D 0.05014302581548691 67\n",
      "std_G 0.040021758526563644 67\n",
      "[0/1000][408/600][68] Loss_D: 0.170533 Loss_G: 0.167652 \n",
      "output_D 0.17053288221359253 68\n",
      "output_G 0.16765199601650238 68\n",
      "std_D 0.039054710417985916 68\n",
      "std_G 0.05325372889637947 68\n",
      "[0/1000][414/600][69] Loss_D: 0.169178 Loss_G: 0.167958 \n",
      "output_D 0.16917824745178223 69\n",
      "output_G 0.16795827448368073 69\n",
      "std_D 0.04010152816772461 69\n",
      "std_G 0.04097083956003189 69\n",
      "[0/1000][420/600][70] Loss_D: 0.174432 Loss_G: 0.168329 \n",
      "output_D 0.17443180084228516 70\n",
      "output_G 0.16832874715328217 70\n",
      "std_D 0.04099433496594429 70\n",
      "std_G 0.03455694019794464 70\n",
      "[0/1000][426/600][71] Loss_D: 0.167845 Loss_G: 0.169622 \n",
      "output_D 0.16784460842609406 71\n",
      "output_G 0.1696220189332962 71\n",
      "std_D 0.04920611158013344 71\n",
      "std_G 0.041611310094594955 71\n",
      "[0/1000][432/600][72] Loss_D: 0.173835 Loss_G: 0.168624 \n",
      "output_D 0.1738349050283432 72\n",
      "output_G 0.1686239093542099 72\n",
      "std_D 0.039495062083005905 72\n",
      "std_G 0.03762537240982056 72\n",
      "[0/1000][438/600][73] Loss_D: 0.164038 Loss_G: 0.172607 \n",
      "output_D 0.16403813660144806 73\n",
      "output_G 0.17260676622390747 73\n",
      "std_D 0.04590800404548645 73\n",
      "std_G 0.04025615379214287 73\n",
      "[0/1000][444/600][74] Loss_D: 0.170984 Loss_G: 0.171291 \n",
      "output_D 0.17098434269428253 74\n",
      "output_G 0.17129138112068176 74\n",
      "std_D 0.043204061686992645 74\n",
      "std_G 0.05431164801120758 74\n",
      "[0/1000][450/600][75] Loss_D: 0.168220 Loss_G: 0.171183 \n",
      "output_D 0.16822035610675812 75\n",
      "output_G 0.17118284106254578 75\n",
      "std_D 0.04063721373677254 75\n",
      "std_G 0.03471281751990318 75\n",
      "[0/1000][456/600][76] Loss_D: 0.170410 Loss_G: 0.166571 \n",
      "output_D 0.1704099476337433 76\n",
      "output_G 0.16657103598117828 76\n",
      "std_D 0.03871507570147514 76\n",
      "std_G 0.041714757680892944 76\n",
      "[0/1000][462/600][77] Loss_D: 0.172523 Loss_G: 0.165043 \n",
      "output_D 0.17252273857593536 77\n",
      "output_G 0.1650434136390686 77\n",
      "std_D 0.04873097315430641 77\n",
      "std_G 0.04876725375652313 77\n",
      "[0/1000][468/600][78] Loss_D: 0.173140 Loss_G: 0.166500 \n",
      "output_D 0.17313982546329498 78\n",
      "output_G 0.16649968922138214 78\n",
      "std_D 0.043293215334415436 78\n",
      "std_G 0.04022737964987755 78\n",
      "[0/1000][474/600][79] Loss_D: 0.165748 Loss_G: 0.165021 \n",
      "output_D 0.16574783623218536 79\n",
      "output_G 0.16502070426940918 79\n",
      "std_D 0.03566162288188934 79\n",
      "std_G 0.049749668687582016 79\n",
      "[0/1000][480/600][80] Loss_D: 0.162407 Loss_G: 0.164854 \n",
      "output_D 0.16240747272968292 80\n",
      "output_G 0.16485436260700226 80\n",
      "std_D 0.052440281957387924 80\n",
      "std_G 0.04849987104535103 80\n",
      "[0/1000][486/600][81] Loss_D: 0.159939 Loss_G: 0.161573 \n",
      "output_D 0.1599385142326355 81\n",
      "output_G 0.16157279908657074 81\n",
      "std_D 0.05267471447587013 81\n",
      "std_G 0.042767561972141266 81\n",
      "[0/1000][492/600][82] Loss_D: 0.168423 Loss_G: 0.169927 \n",
      "output_D 0.16842292249202728 82\n",
      "output_G 0.16992735862731934 82\n",
      "std_D 0.041205231100320816 82\n",
      "std_G 0.04188544303178787 82\n",
      "[0/1000][498/600][83] Loss_D: 0.161898 Loss_G: 0.168756 \n",
      "output_D 0.16189831495285034 83\n",
      "output_G 0.16875603795051575 83\n",
      "std_D 0.0410468764603138 83\n",
      "std_G 0.03568757697939873 83\n",
      "[0/1000][504/600][84] Loss_D: 0.170880 Loss_G: 0.168911 \n",
      "output_D 0.17088022828102112 84\n",
      "output_G 0.1689111888408661 84\n",
      "std_D 0.044599298387765884 84\n",
      "std_G 0.03751692175865173 84\n",
      "[0/1000][510/600][85] Loss_D: 0.165678 Loss_G: 0.173892 \n",
      "output_D 0.1656775027513504 85\n",
      "output_G 0.17389248311519623 85\n",
      "std_D 0.04915066063404083 85\n",
      "std_G 0.047210391610860825 85\n",
      "[0/1000][516/600][86] Loss_D: 0.169903 Loss_G: 0.166603 \n",
      "output_D 0.16990341246128082 86\n",
      "output_G 0.16660276055335999 86\n",
      "std_D 0.04535732790827751 86\n",
      "std_G 0.049483560025691986 86\n",
      "[0/1000][522/600][87] Loss_D: 0.166551 Loss_G: 0.173054 \n",
      "output_D 0.16655072569847107 87\n",
      "output_G 0.17305351793766022 87\n",
      "std_D 0.04417095705866814 87\n",
      "std_G 0.04702882096171379 87\n",
      "[0/1000][528/600][88] Loss_D: 0.173195 Loss_G: 0.174180 \n",
      "output_D 0.17319491505622864 88\n",
      "output_G 0.17418012022972107 88\n",
      "std_D 0.04327087104320526 88\n",
      "std_G 0.04591185227036476 88\n",
      "[0/1000][534/600][89] Loss_D: 0.169947 Loss_G: 0.167373 \n",
      "output_D 0.16994719207286835 89\n",
      "output_G 0.16737298667430878 89\n",
      "std_D 0.044863298535346985 89\n",
      "std_G 0.0454084649682045 89\n",
      "[0/1000][540/600][90] Loss_D: 0.173819 Loss_G: 0.171989 \n",
      "output_D 0.17381861805915833 90\n",
      "output_G 0.1719888597726822 90\n",
      "std_D 0.046818703413009644 90\n",
      "std_G 0.041834305971860886 90\n",
      "[0/1000][546/600][91] Loss_D: 0.174002 Loss_G: 0.178644 \n",
      "output_D 0.1740018129348755 91\n",
      "output_G 0.17864355444908142 91\n",
      "std_D 0.04466105252504349 91\n",
      "std_G 0.04628565534949303 91\n",
      "[0/1000][552/600][92] Loss_D: 0.174248 Loss_G: 0.167574 \n",
      "output_D 0.17424829304218292 92\n",
      "output_G 0.1675744503736496 92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_D 0.04197142645716667 92\n",
      "std_G 0.047980960458517075 92\n",
      "[0/1000][558/600][93] Loss_D: 0.160381 Loss_G: 0.170413 \n",
      "output_D 0.16038104891777039 93\n",
      "output_G 0.1704133003950119 93\n",
      "std_D 0.050312526524066925 93\n",
      "std_G 0.04206794127821922 93\n",
      "[0/1000][564/600][94] Loss_D: 0.135886 Loss_G: 0.164451 \n",
      "output_D 0.13588646054267883 94\n",
      "output_G 0.16445112228393555 94\n",
      "std_D 0.08739732950925827 94\n",
      "std_G 0.05581744387745857 94\n",
      "[0/1000][570/600][95] Loss_D: 0.161226 Loss_G: 0.162757 \n",
      "output_D 0.1612262725830078 95\n",
      "output_G 0.16275694966316223 95\n",
      "std_D 0.053873952478170395 95\n",
      "std_G 0.04350518807768822 95\n",
      "[0/1000][576/600][96] Loss_D: 0.166815 Loss_G: 0.171377 \n",
      "output_D 0.16681481897830963 96\n",
      "output_G 0.17137733101844788 96\n",
      "std_D 0.04511555656790733 96\n",
      "std_G 0.04135401174426079 96\n",
      "[0/1000][582/600][97] Loss_D: 0.169484 Loss_G: 0.169792 \n",
      "output_D 0.16948401927947998 97\n",
      "output_G 0.16979236900806427 97\n",
      "std_D 0.03970952704548836 97\n",
      "std_G 0.040902189910411835 97\n",
      "[0/1000][588/600][98] Loss_D: 0.160942 Loss_G: 0.169370 \n",
      "output_D 0.16094209253787994 98\n",
      "output_G 0.16937023401260376 98\n",
      "std_D 0.04241209849715233 98\n",
      "std_G 0.042193442583084106 98\n",
      "[0/1000][594/600][99] Loss_D: 0.170265 Loss_G: 0.171153 \n",
      "output_D 0.1702646166086197 99\n",
      "output_G 0.17115284502506256 99\n",
      "std_D 0.04669516906142235 99\n",
      "std_G 0.041837822645902634 99\n",
      "[0/1000][600/600][100] Loss_D: 0.168786 Loss_G: 0.173771 \n",
      "output_D 0.16878607869148254 100\n",
      "output_G 0.1737714558839798 100\n",
      "std_D 0.04912976175546646 100\n",
      "std_G 0.03951147943735123 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000][6/600][101] Loss_D: 0.173777 Loss_G: 0.167462 \n",
      "output_D 0.17377664148807526 101\n",
      "output_G 0.16746152937412262 101\n",
      "std_D 0.03914712369441986 101\n",
      "std_G 0.040017105638980865 101\n",
      "[1/1000][12/600][102] Loss_D: 0.176029 Loss_G: 0.175500 \n",
      "output_D 0.17602898180484772 102\n",
      "output_G 0.17550021409988403 102\n",
      "std_D 0.04076013341546059 102\n",
      "std_G 0.05044865608215332 102\n",
      "[1/1000][18/600][103] Loss_D: 0.147587 Loss_G: 0.127437 \n",
      "output_D 0.1475866287946701 103\n",
      "output_G 0.12743684649467468 103\n",
      "std_D 0.07681968063116074 103\n",
      "std_G 0.10917981714010239 103\n",
      "[1/1000][24/600][104] Loss_D: 0.167201 Loss_G: 0.161626 \n",
      "output_D 0.1672014445066452 104\n",
      "output_G 0.16162624955177307 104\n",
      "std_D 0.045524727553129196 104\n",
      "std_G 0.05568679794669151 104\n",
      "[1/1000][30/600][105] Loss_D: 0.173567 Loss_G: 0.162032 \n",
      "output_D 0.1735665649175644 105\n",
      "output_G 0.16203230619430542 105\n",
      "std_D 0.04253384470939636 105\n",
      "std_G 0.04633012041449547 105\n",
      "[1/1000][36/600][106] Loss_D: 0.175317 Loss_G: 0.157938 \n",
      "output_D 0.17531709372997284 106\n",
      "output_G 0.15793775022029877 106\n",
      "std_D 0.037427663803100586 106\n",
      "std_G 0.03640343248844147 106\n",
      "[1/1000][42/600][107] Loss_D: 0.156207 Loss_G: 0.156076 \n",
      "output_D 0.1562071144580841 107\n",
      "output_G 0.15607614815235138 107\n",
      "std_D 0.05567285045981407 107\n",
      "std_G 0.059362128376960754 107\n",
      "[1/1000][48/600][108] Loss_D: 0.159338 Loss_G: 0.156795 \n",
      "output_D 0.15933780372142792 108\n",
      "output_G 0.15679492056369781 108\n",
      "std_D 0.057403724640607834 108\n",
      "std_G 0.06260717660188675 108\n",
      "[1/1000][54/600][109] Loss_D: 0.170260 Loss_G: 0.172647 \n",
      "output_D 0.17025992274284363 109\n",
      "output_G 0.17264704406261444 109\n",
      "std_D 0.04790758341550827 109\n",
      "std_G 0.046686120331287384 109\n",
      "[1/1000][60/600][110] Loss_D: 0.168698 Loss_G: 0.163346 \n",
      "output_D 0.16869761049747467 110\n",
      "output_G 0.16334640979766846 110\n",
      "std_D 0.04471544921398163 110\n",
      "std_G 0.051984962075948715 110\n",
      "[1/1000][66/600][111] Loss_D: 0.168152 Loss_G: 0.160955 \n",
      "output_D 0.16815222799777985 111\n",
      "output_G 0.1609547734260559 111\n",
      "std_D 0.045970894396305084 111\n",
      "std_G 0.05115323141217232 111\n",
      "[1/1000][72/600][112] Loss_D: 0.159494 Loss_G: 0.169622 \n",
      "output_D 0.15949369966983795 112\n",
      "output_G 0.1696220338344574 112\n",
      "std_D 0.06431981176137924 112\n",
      "std_G 0.05216958001255989 112\n",
      "[1/1000][78/600][113] Loss_D: 0.163195 Loss_G: 0.165224 \n",
      "output_D 0.16319547593593597 113\n",
      "output_G 0.16522350907325745 113\n",
      "std_D 0.05746089294552803 113\n",
      "std_G 0.045869868248701096 113\n",
      "[1/1000][84/600][114] Loss_D: 0.160056 Loss_G: 0.166160 \n",
      "output_D 0.16005587577819824 114\n",
      "output_G 0.1661599576473236 114\n",
      "std_D 0.04308215156197548 114\n",
      "std_G 0.04022249951958656 114\n",
      "[1/1000][90/600][115] Loss_D: 0.171474 Loss_G: 0.169070 \n",
      "output_D 0.1714741587638855 115\n",
      "output_G 0.1690703183412552 115\n",
      "std_D 0.04045494645833969 115\n",
      "std_G 0.040731076151132584 115\n",
      "[1/1000][96/600][116] Loss_D: 0.174243 Loss_G: 0.168453 \n",
      "output_D 0.1742427945137024 116\n",
      "output_G 0.16845259070396423 116\n",
      "std_D 0.045587144792079926 116\n",
      "std_G 0.04233129695057869 116\n",
      "[1/1000][102/600][117] Loss_D: 0.179294 Loss_G: 0.178621 \n",
      "output_D 0.17929407954216003 117\n",
      "output_G 0.17862094938755035 117\n",
      "std_D 0.04046741500496864 117\n",
      "std_G 0.045971259474754333 117\n",
      "[1/1000][108/600][118] Loss_D: 0.168496 Loss_G: 0.173715 \n",
      "output_D 0.16849631071090698 118\n",
      "output_G 0.17371533811092377 118\n",
      "std_D 0.04171762615442276 118\n",
      "std_G 0.04303960129618645 118\n",
      "[1/1000][114/600][119] Loss_D: 0.172896 Loss_G: 0.179495 \n",
      "output_D 0.1728964000940323 119\n",
      "output_G 0.17949527502059937 119\n",
      "std_D 0.05238877236843109 119\n",
      "std_G 0.041400711983442307 119\n",
      "[1/1000][120/600][120] Loss_D: 0.168222 Loss_G: 0.156729 \n",
      "output_D 0.16822245717048645 120\n",
      "output_G 0.15672902762889862 120\n",
      "std_D 0.0428965725004673 120\n",
      "std_G 0.0519479475915432 120\n",
      "[1/1000][126/600][121] Loss_D: 0.167740 Loss_G: 0.173117 \n",
      "output_D 0.16774049401283264 121\n",
      "output_G 0.17311717569828033 121\n",
      "std_D 0.039515167474746704 121\n",
      "std_G 0.04550713673233986 121\n",
      "[1/1000][132/600][122] Loss_D: 0.170992 Loss_G: 0.178567 \n",
      "output_D 0.1709918975830078 122\n",
      "output_G 0.17856736481189728 122\n",
      "std_D 0.046652574092149734 122\n",
      "std_G 0.037490349262952805 122\n",
      "[1/1000][138/600][123] Loss_D: 0.180368 Loss_G: 0.182979 \n",
      "output_D 0.1803683191537857 123\n",
      "output_G 0.1829787939786911 123\n",
      "std_D 0.039244748651981354 123\n",
      "std_G 0.04106432944536209 123\n",
      "[1/1000][144/600][124] Loss_D: 0.177286 Loss_G: 0.172677 \n",
      "output_D 0.1772855669260025 124\n",
      "output_G 0.17267675697803497 124\n",
      "std_D 0.03748154267668724 124\n",
      "std_G 0.03929668664932251 124\n",
      "[1/1000][150/600][125] Loss_D: 0.180608 Loss_G: 0.171334 \n",
      "output_D 0.18060782551765442 125\n",
      "output_G 0.17133426666259766 125\n",
      "std_D 0.03610466420650482 125\n",
      "std_G 0.042553674429655075 125\n",
      "[1/1000][156/600][126] Loss_D: 0.173271 Loss_G: 0.171172 \n",
      "output_D 0.1732705533504486 126\n",
      "output_G 0.1711723953485489 126\n",
      "std_D 0.04425729066133499 126\n",
      "std_G 0.040151387453079224 126\n",
      "[1/1000][162/600][127] Loss_D: 0.168300 Loss_G: 0.174252 \n",
      "output_D 0.16829968988895416 127\n",
      "output_G 0.17425180971622467 127\n",
      "std_D 0.04173831269145012 127\n",
      "std_G 0.0432254895567894 127\n",
      "[1/1000][168/600][128] Loss_D: 0.171317 Loss_G: 0.169843 \n",
      "output_D 0.17131690680980682 128\n",
      "output_G 0.16984298825263977 128\n",
      "std_D 0.04547344148159027 128\n",
      "std_G 0.04160752519965172 128\n",
      "[1/1000][174/600][129] Loss_D: 0.172577 Loss_G: 0.177132 \n",
      "output_D 0.17257682979106903 129\n",
      "output_G 0.1771322637796402 129\n",
      "std_D 0.038855209946632385 129\n",
      "std_G 0.0357482023537159 129\n",
      "[1/1000][180/600][130] Loss_D: 0.167737 Loss_G: 0.178199 \n",
      "output_D 0.1677371859550476 130\n",
      "output_G 0.17819850146770477 130\n",
      "std_D 0.0396655797958374 130\n",
      "std_G 0.04200727492570877 130\n",
      "[1/1000][186/600][131] Loss_D: 0.175700 Loss_G: 0.173569 \n",
      "output_D 0.17569978535175323 131\n",
      "output_G 0.1735689342021942 131\n",
      "std_D 0.04154883697628975 131\n",
      "std_G 0.03824526444077492 131\n",
      "[1/1000][192/600][132] Loss_D: 0.173512 Loss_G: 0.177575 \n",
      "output_D 0.17351233959197998 132\n",
      "output_G 0.17757532000541687 132\n",
      "std_D 0.04357464984059334 132\n",
      "std_G 0.04265221580862999 132\n",
      "[1/1000][198/600][133] Loss_D: 0.176871 Loss_G: 0.171534 \n",
      "output_D 0.17687134444713593 133\n",
      "output_G 0.17153427004814148 133\n",
      "std_D 0.044526875019073486 133\n",
      "std_G 0.048700254410505295 133\n",
      "[1/1000][204/600][134] Loss_D: 0.179700 Loss_G: 0.169877 \n",
      "output_D 0.1796998232603073 134\n",
      "output_G 0.16987745463848114 134\n",
      "std_D 0.03960830718278885 134\n",
      "std_G 0.047536756843328476 134\n",
      "[1/1000][210/600][135] Loss_D: 0.177911 Loss_G: 0.170311 \n",
      "output_D 0.17791065573692322 135\n",
      "output_G 0.17031076550483704 135\n",
      "std_D 0.03727651759982109 135\n",
      "std_G 0.043315589427948 135\n",
      "[1/1000][216/600][136] Loss_D: 0.167372 Loss_G: 0.180016 \n",
      "output_D 0.16737206280231476 136\n",
      "output_G 0.18001586198806763 136\n",
      "std_D 0.04147665947675705 136\n",
      "std_G 0.04192477464675903 136\n",
      "[1/1000][222/600][137] Loss_D: 0.162408 Loss_G: 0.170602 \n",
      "output_D 0.1624079793691635 137\n",
      "output_G 0.1706017404794693 137\n",
      "std_D 0.04489758983254433 137\n",
      "std_G 0.04029163718223572 137\n",
      "[1/1000][228/600][138] Loss_D: 0.176979 Loss_G: 0.179958 \n",
      "output_D 0.17697852849960327 138\n",
      "output_G 0.1799582988023758 138\n",
      "std_D 0.04285634681582451 138\n",
      "std_G 0.04667877405881882 138\n",
      "[1/1000][234/600][139] Loss_D: 0.165485 Loss_G: 0.171057 \n",
      "output_D 0.16548490524291992 139\n",
      "output_G 0.17105694115161896 139\n",
      "std_D 0.04244152829051018 139\n",
      "std_G 0.04042980819940567 139\n",
      "[1/1000][240/600][140] Loss_D: 0.172731 Loss_G: 0.175953 \n",
      "output_D 0.17273063957691193 140\n",
      "output_G 0.17595258355140686 140\n",
      "std_D 0.04994989186525345 140\n",
      "std_G 0.05032692104578018 140\n",
      "[1/1000][246/600][141] Loss_D: 0.178550 Loss_G: 0.165557 \n",
      "output_D 0.17855048179626465 141\n",
      "output_G 0.1655566543340683 141\n",
      "std_D 0.044620826840400696 141\n",
      "std_G 0.0526108480989933 141\n",
      "[1/1000][252/600][142] Loss_D: 0.146129 Loss_G: 0.160927 \n",
      "output_D 0.14612865447998047 142\n",
      "output_G 0.16092698276042938 142\n",
      "std_D 0.07844867557287216 142\n",
      "std_G 0.06131010130047798 142\n",
      "[1/1000][258/600][143] Loss_D: 0.172045 Loss_G: 0.179362 \n",
      "output_D 0.1720447689294815 143\n",
      "output_G 0.17936190962791443 143\n",
      "std_D 0.03936758637428284 143\n",
      "std_G 0.040766242891550064 143\n",
      "[1/1000][264/600][144] Loss_D: 0.177310 Loss_G: 0.179095 \n",
      "output_D 0.1773102581501007 144\n",
      "output_G 0.17909546196460724 144\n",
      "std_D 0.037902262061834335 144\n",
      "std_G 0.041547805070877075 144\n",
      "[1/1000][270/600][145] Loss_D: 0.175854 Loss_G: 0.178575 \n",
      "output_D 0.17585378885269165 145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_G 0.17857526242733002 145\n",
      "std_D 0.043173909187316895 145\n",
      "std_G 0.03655928000807762 145\n",
      "[1/1000][276/600][146] Loss_D: 0.172286 Loss_G: 0.170266 \n",
      "output_D 0.17228573560714722 146\n",
      "output_G 0.1702662706375122 146\n",
      "std_D 0.04335607588291168 146\n",
      "std_G 0.037635836750268936 146\n",
      "[1/1000][282/600][147] Loss_D: 0.173596 Loss_G: 0.171716 \n",
      "output_D 0.1735963076353073 147\n",
      "output_G 0.17171603441238403 147\n",
      "std_D 0.045035745948553085 147\n",
      "std_G 0.042923454195261 147\n",
      "[1/1000][288/600][148] Loss_D: 0.170333 Loss_G: 0.170709 \n",
      "output_D 0.17033252120018005 148\n",
      "output_G 0.17070898413658142 148\n",
      "std_D 0.0462358295917511 148\n",
      "std_G 0.04044304043054581 148\n",
      "[1/1000][294/600][149] Loss_D: 0.172496 Loss_G: 0.176033 \n",
      "output_D 0.17249560356140137 149\n",
      "output_G 0.17603321373462677 149\n",
      "std_D 0.03643050044775009 149\n",
      "std_G 0.03712661564350128 149\n",
      "[1/1000][300/600][150] Loss_D: 0.178963 Loss_G: 0.169680 \n",
      "output_D 0.1789630949497223 150\n",
      "output_G 0.1696801781654358 150\n",
      "std_D 0.039775677025318146 150\n",
      "std_G 0.03626839444041252 150\n",
      "[1/1000][306/600][151] Loss_D: 0.174233 Loss_G: 0.178877 \n",
      "output_D 0.17423328757286072 151\n",
      "output_G 0.17887702584266663 151\n",
      "std_D 0.03748009726405144 151\n",
      "std_G 0.0395287349820137 151\n",
      "[1/1000][312/600][152] Loss_D: 0.178637 Loss_G: 0.177310 \n",
      "output_D 0.17863744497299194 152\n",
      "output_G 0.17730969190597534 152\n",
      "std_D 0.04206625744700432 152\n",
      "std_G 0.046915583312511444 152\n",
      "[1/1000][318/600][153] Loss_D: 0.167903 Loss_G: 0.169209 \n",
      "output_D 0.16790297627449036 153\n",
      "output_G 0.16920918226242065 153\n",
      "std_D 0.04920382797718048 153\n",
      "std_G 0.04266268014907837 153\n",
      "[1/1000][324/600][154] Loss_D: 0.172923 Loss_G: 0.170689 \n",
      "output_D 0.17292281985282898 154\n",
      "output_G 0.17068855464458466 154\n",
      "std_D 0.04344048351049423 154\n",
      "std_G 0.03963689133524895 154\n",
      "[1/1000][330/600][155] Loss_D: 0.175749 Loss_G: 0.182177 \n",
      "output_D 0.17574873566627502 155\n",
      "output_G 0.18217726051807404 155\n",
      "std_D 0.04073450341820717 155\n",
      "std_G 0.04205327108502388 155\n",
      "[1/1000][336/600][156] Loss_D: 0.178160 Loss_G: 0.182344 \n",
      "output_D 0.1781598925590515 156\n",
      "output_G 0.1823439598083496 156\n",
      "std_D 0.04618096351623535 156\n",
      "std_G 0.04153091087937355 156\n",
      "[1/1000][342/600][157] Loss_D: 0.171938 Loss_G: 0.176675 \n",
      "output_D 0.17193828523159027 157\n",
      "output_G 0.17667487263679504 157\n",
      "std_D 0.03657776862382889 157\n",
      "std_G 0.04060143977403641 157\n",
      "[1/1000][348/600][158] Loss_D: 0.182248 Loss_G: 0.181074 \n",
      "output_D 0.18224824965000153 158\n",
      "output_G 0.18107394874095917 158\n",
      "std_D 0.04155794531106949 158\n",
      "std_G 0.043162375688552856 158\n",
      "[1/1000][354/600][159] Loss_D: 0.183192 Loss_G: 0.170914 \n",
      "output_D 0.18319155275821686 159\n",
      "output_G 0.17091400921344757 159\n",
      "std_D 0.04199017584323883 159\n",
      "std_G 0.036057066172361374 159\n",
      "[1/1000][360/600][160] Loss_D: 0.183707 Loss_G: 0.179021 \n",
      "output_D 0.18370653688907623 160\n",
      "output_G 0.17902067303657532 160\n",
      "std_D 0.03825169801712036 160\n",
      "std_G 0.038840968161821365 160\n",
      "[1/1000][366/600][161] Loss_D: 0.173035 Loss_G: 0.177122 \n",
      "output_D 0.1730346530675888 161\n",
      "output_G 0.17712174355983734 161\n",
      "std_D 0.03922177106142044 161\n",
      "std_G 0.04207790270447731 161\n",
      "[1/1000][372/600][162] Loss_D: 0.178131 Loss_G: 0.178449 \n",
      "output_D 0.17813058197498322 162\n",
      "output_G 0.17844897508621216 162\n",
      "std_D 0.03535545617341995 162\n",
      "std_G 0.04193956032395363 162\n",
      "[1/1000][378/600][163] Loss_D: 0.176207 Loss_G: 0.174126 \n",
      "output_D 0.1762072741985321 163\n",
      "output_G 0.17412595450878143 163\n",
      "std_D 0.035671256482601166 163\n",
      "std_G 0.04481121897697449 163\n",
      "[1/1000][384/600][164] Loss_D: 0.173294 Loss_G: 0.184139 \n",
      "output_D 0.17329375445842743 164\n",
      "output_G 0.18413911759853363 164\n",
      "std_D 0.03966716304421425 164\n",
      "std_G 0.04427742585539818 164\n",
      "[1/1000][390/600][165] Loss_D: 0.174186 Loss_G: 0.173907 \n",
      "output_D 0.17418575286865234 165\n",
      "output_G 0.17390722036361694 165\n",
      "std_D 0.03459925577044487 165\n",
      "std_G 0.03738518804311752 165\n",
      "[1/1000][396/600][166] Loss_D: 0.177370 Loss_G: 0.178000 \n",
      "output_D 0.1773698478937149 166\n",
      "output_G 0.17800012230873108 166\n",
      "std_D 0.04125978425145149 166\n",
      "std_G 0.03440006077289581 166\n",
      "[1/1000][402/600][167] Loss_D: 0.184253 Loss_G: 0.169641 \n",
      "output_D 0.18425308167934418 167\n",
      "output_G 0.16964082419872284 167\n",
      "std_D 0.037983935326337814 167\n",
      "std_G 0.03731249272823334 167\n",
      "[1/1000][408/600][168] Loss_D: 0.180203 Loss_G: 0.182317 \n",
      "output_D 0.18020276725292206 168\n",
      "output_G 0.18231678009033203 168\n",
      "std_D 0.039510488510131836 168\n",
      "std_G 0.039855170994997025 168\n",
      "[1/1000][414/600][169] Loss_D: 0.180678 Loss_G: 0.173776 \n",
      "output_D 0.18067826330661774 169\n",
      "output_G 0.1737755835056305 169\n",
      "std_D 0.03794650360941887 169\n",
      "std_G 0.03445038944482803 169\n",
      "[1/1000][420/600][170] Loss_D: 0.177914 Loss_G: 0.183515 \n",
      "output_D 0.17791372537612915 170\n",
      "output_G 0.18351513147354126 170\n",
      "std_D 0.04240226000547409 170\n",
      "std_G 0.04316185414791107 170\n",
      "[1/1000][426/600][171] Loss_D: 0.175014 Loss_G: 0.181339 \n",
      "output_D 0.17501430213451385 171\n",
      "output_G 0.18133854866027832 171\n",
      "std_D 0.0397714264690876 171\n",
      "std_G 0.04188626632094383 171\n",
      "[1/1000][432/600][172] Loss_D: 0.181037 Loss_G: 0.179016 \n",
      "output_D 0.18103745579719543 172\n",
      "output_G 0.17901617288589478 172\n",
      "std_D 0.038744423538446426 172\n",
      "std_G 0.04130469635128975 172\n",
      "[1/1000][438/600][173] Loss_D: 0.178980 Loss_G: 0.184982 \n",
      "output_D 0.17897960543632507 173\n",
      "output_G 0.18498171865940094 173\n",
      "std_D 0.04102591052651405 173\n",
      "std_G 0.03840111196041107 173\n",
      "[1/1000][444/600][174] Loss_D: 0.183293 Loss_G: 0.178312 \n",
      "output_D 0.183293417096138 174\n",
      "output_G 0.17831173539161682 174\n",
      "std_D 0.04269176721572876 174\n",
      "std_G 0.03913629427552223 174\n",
      "[1/1000][450/600][175] Loss_D: 0.172370 Loss_G: 0.175990 \n",
      "output_D 0.17236952483654022 175\n",
      "output_G 0.1759898066520691 175\n",
      "std_D 0.04639654979109764 175\n",
      "std_G 0.03667542710900307 175\n",
      "[1/1000][456/600][176] Loss_D: 0.171765 Loss_G: 0.176833 \n",
      "output_D 0.17176513373851776 176\n",
      "output_G 0.17683321237564087 176\n",
      "std_D 0.0425398163497448 176\n",
      "std_G 0.042090464383363724 176\n",
      "[1/1000][462/600][177] Loss_D: 0.179253 Loss_G: 0.176034 \n",
      "output_D 0.17925329506397247 177\n",
      "output_G 0.17603404819965363 177\n",
      "std_D 0.03842645511031151 177\n",
      "std_G 0.039488378912210464 177\n",
      "[1/1000][468/600][178] Loss_D: 0.175995 Loss_G: 0.178438 \n",
      "output_D 0.17599482834339142 178\n",
      "output_G 0.1784375160932541 178\n",
      "std_D 0.03851475939154625 178\n",
      "std_G 0.040904466062784195 178\n",
      "[1/1000][474/600][179] Loss_D: 0.176774 Loss_G: 0.171307 \n",
      "output_D 0.17677399516105652 179\n",
      "output_G 0.1713067889213562 179\n",
      "std_D 0.03488389775156975 179\n",
      "std_G 0.038746945559978485 179\n",
      "[1/1000][480/600][180] Loss_D: 0.173504 Loss_G: 0.181335 \n",
      "output_D 0.1735040545463562 180\n",
      "output_G 0.18133459985256195 180\n",
      "std_D 0.034683454781770706 180\n",
      "std_G 0.03917115926742554 180\n",
      "[1/1000][486/600][181] Loss_D: 0.175422 Loss_G: 0.180720 \n",
      "output_D 0.17542177438735962 181\n",
      "output_G 0.18072006106376648 181\n",
      "std_D 0.03633473068475723 181\n",
      "std_G 0.043496038764715195 181\n",
      "[1/1000][492/600][182] Loss_D: 0.178629 Loss_G: 0.167057 \n",
      "output_D 0.17862892150878906 182\n",
      "output_G 0.1670566201210022 182\n",
      "std_D 0.03786987438797951 182\n",
      "std_G 0.041845519095659256 182\n",
      "[1/1000][498/600][183] Loss_D: 0.176359 Loss_G: 0.168050 \n",
      "output_D 0.1763591468334198 183\n",
      "output_G 0.1680501252412796 183\n",
      "std_D 0.04557426646351814 183\n",
      "std_G 0.047613970935344696 183\n",
      "[1/1000][504/600][184] Loss_D: 0.178017 Loss_G: 0.177140 \n",
      "output_D 0.1780165731906891 184\n",
      "output_G 0.1771395057439804 184\n",
      "std_D 0.03809245303273201 184\n",
      "std_G 0.042087119072675705 184\n",
      "[1/1000][510/600][185] Loss_D: 0.172803 Loss_G: 0.177833 \n",
      "output_D 0.17280304431915283 185\n",
      "output_G 0.17783263325691223 185\n",
      "std_D 0.04371611401438713 185\n",
      "std_G 0.04115532338619232 185\n",
      "[1/1000][516/600][186] Loss_D: 0.179757 Loss_G: 0.179306 \n",
      "output_D 0.17975695431232452 186\n",
      "output_G 0.1793058216571808 186\n",
      "std_D 0.04016244411468506 186\n",
      "std_G 0.03844544291496277 186\n",
      "[1/1000][522/600][187] Loss_D: 0.173672 Loss_G: 0.179831 \n",
      "output_D 0.17367202043533325 187\n",
      "output_G 0.17983071506023407 187\n",
      "std_D 0.0333900973200798 187\n",
      "std_G 0.04143017157912254 187\n",
      "[1/1000][528/600][188] Loss_D: 0.171677 Loss_G: 0.171335 \n",
      "output_D 0.17167730629444122 188\n",
      "output_G 0.171335369348526 188\n",
      "std_D 0.04033931717276573 188\n",
      "std_G 0.03762158006429672 188\n",
      "[1/1000][534/600][189] Loss_D: 0.175046 Loss_G: 0.181982 \n",
      "output_D 0.17504648864269257 189\n",
      "output_G 0.18198227882385254 189\n",
      "std_D 0.03330192342400551 189\n",
      "std_G 0.04026559367775917 189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000][540/600][190] Loss_D: 0.179504 Loss_G: 0.172120 \n",
      "output_D 0.17950376868247986 190\n",
      "output_G 0.17211954295635223 190\n",
      "std_D 0.03657415136694908 190\n",
      "std_G 0.03742630034685135 190\n",
      "[1/1000][546/600][191] Loss_D: 0.180040 Loss_G: 0.170811 \n",
      "output_D 0.1800403594970703 191\n",
      "output_G 0.17081093788146973 191\n",
      "std_D 0.045517731457948685 191\n",
      "std_G 0.041115038096904755 191\n",
      "[1/1000][552/600][192] Loss_D: 0.174809 Loss_G: 0.172436 \n",
      "output_D 0.1748088300228119 192\n",
      "output_G 0.17243647575378418 192\n",
      "std_D 0.040610551834106445 192\n",
      "std_G 0.03452393040060997 192\n",
      "[1/1000][558/600][193] Loss_D: 0.179422 Loss_G: 0.171331 \n",
      "output_D 0.17942243814468384 193\n",
      "output_G 0.1713314950466156 193\n",
      "std_D 0.04097643867135048 193\n",
      "std_G 0.043484319001436234 193\n",
      "[1/1000][564/600][194] Loss_D: 0.168719 Loss_G: 0.178774 \n",
      "output_D 0.1687188595533371 194\n",
      "output_G 0.17877401411533356 194\n",
      "std_D 0.03752245754003525 194\n",
      "std_G 0.037672072649002075 194\n",
      "[1/1000][570/600][195] Loss_D: 0.176627 Loss_G: 0.182416 \n",
      "output_D 0.1766269952058792 195\n",
      "output_G 0.18241634964942932 195\n",
      "std_D 0.04377128183841705 195\n",
      "std_G 0.03779437765479088 195\n",
      "[1/1000][576/600][196] Loss_D: 0.174016 Loss_G: 0.172483 \n",
      "output_D 0.17401646077632904 196\n",
      "output_G 0.172483429312706 196\n",
      "std_D 0.03739304095506668 196\n",
      "std_G 0.042833276093006134 196\n",
      "[1/1000][582/600][197] Loss_D: 0.180190 Loss_G: 0.177012 \n",
      "output_D 0.18019047379493713 197\n",
      "output_G 0.1770123392343521 197\n",
      "std_D 0.05126197636127472 197\n",
      "std_G 0.04339071735739708 197\n",
      "[1/1000][588/600][198] Loss_D: 0.172845 Loss_G: 0.174618 \n",
      "output_D 0.17284488677978516 198\n",
      "output_G 0.17461827397346497 198\n",
      "std_D 0.04074578732252121 198\n",
      "std_G 0.03864506259560585 198\n",
      "[1/1000][594/600][199] Loss_D: 0.171109 Loss_G: 0.179690 \n",
      "output_D 0.17110879719257355 199\n",
      "output_G 0.17968952655792236 199\n",
      "std_D 0.040514495223760605 199\n",
      "std_G 0.0396808385848999 199\n",
      "[1/1000][600/600][200] Loss_D: 0.127379 Loss_G: 0.139947 \n",
      "output_D 0.12737911939620972 200\n",
      "output_G 0.1399470567703247 200\n",
      "std_D 0.10440618544816971 200\n",
      "std_G 0.07477958500385284 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/1000][6/600][201] Loss_D: 0.175324 Loss_G: 0.180808 \n",
      "output_D 0.1753242015838623 201\n",
      "output_G 0.18080765008926392 201\n",
      "std_D 0.04512188211083412 201\n",
      "std_G 0.04502329230308533 201\n",
      "[2/1000][12/600][202] Loss_D: 0.178040 Loss_G: 0.166014 \n",
      "output_D 0.17804020643234253 202\n",
      "output_G 0.16601364314556122 202\n",
      "std_D 0.04402363300323486 202\n",
      "std_G 0.0380314365029335 202\n",
      "[2/1000][18/600][203] Loss_D: 0.178124 Loss_G: 0.177887 \n",
      "output_D 0.1781243532896042 203\n",
      "output_G 0.17788727581501007 203\n",
      "std_D 0.04091973975300789 203\n",
      "std_G 0.04026271030306816 203\n",
      "[2/1000][24/600][204] Loss_D: 0.175981 Loss_G: 0.182152 \n",
      "output_D 0.17598122358322144 204\n",
      "output_G 0.18215195834636688 204\n",
      "std_D 0.03589342534542084 204\n",
      "std_G 0.03798995539546013 204\n",
      "[2/1000][30/600][205] Loss_D: 0.182180 Loss_G: 0.174271 \n",
      "output_D 0.1821800023317337 205\n",
      "output_G 0.17427057027816772 205\n",
      "std_D 0.04005470126867294 205\n",
      "std_G 0.03747032582759857 205\n",
      "[2/1000][36/600][206] Loss_D: 0.176682 Loss_G: 0.178128 \n",
      "output_D 0.17668242752552032 206\n",
      "output_G 0.17812800407409668 206\n",
      "std_D 0.035069625824689865 206\n",
      "std_G 0.04523221403360367 206\n",
      "[2/1000][42/600][207] Loss_D: 0.184728 Loss_G: 0.182179 \n",
      "output_D 0.18472781777381897 207\n",
      "output_G 0.18217940628528595 207\n",
      "std_D 0.043418072164058685 207\n",
      "std_G 0.03631404787302017 207\n",
      "[2/1000][48/600][208] Loss_D: 0.172185 Loss_G: 0.176219 \n",
      "output_D 0.1721854954957962 208\n",
      "output_G 0.17621882259845734 208\n",
      "std_D 0.04128776118159294 208\n",
      "std_G 0.037856824696063995 208\n",
      "[2/1000][54/600][209] Loss_D: 0.181285 Loss_G: 0.174049 \n",
      "output_D 0.18128496408462524 209\n",
      "output_G 0.17404872179031372 209\n",
      "std_D 0.03310949355363846 209\n",
      "std_G 0.03225328400731087 209\n",
      "[2/1000][60/600][210] Loss_D: 0.181033 Loss_G: 0.176717 \n",
      "output_D 0.18103307485580444 210\n",
      "output_G 0.1767166256904602 210\n",
      "std_D 0.04068298265337944 210\n",
      "std_G 0.04127342253923416 210\n",
      "[2/1000][66/600][211] Loss_D: 0.172292 Loss_G: 0.182277 \n",
      "output_D 0.17229203879833221 211\n",
      "output_G 0.1822768747806549 211\n",
      "std_D 0.04407539963722229 211\n",
      "std_G 0.035113245248794556 211\n",
      "[2/1000][72/600][212] Loss_D: 0.183920 Loss_G: 0.177014 \n",
      "output_D 0.18391966819763184 212\n",
      "output_G 0.17701421678066254 212\n",
      "std_D 0.03869890421628952 212\n",
      "std_G 0.050438061356544495 212\n",
      "[2/1000][78/600][213] Loss_D: 0.182758 Loss_G: 0.176288 \n",
      "output_D 0.18275798857212067 213\n",
      "output_G 0.17628760635852814 213\n",
      "std_D 0.0410567931830883 213\n",
      "std_G 0.039607588201761246 213\n",
      "[2/1000][84/600][214] Loss_D: 0.175947 Loss_G: 0.177463 \n",
      "output_D 0.17594732344150543 214\n",
      "output_G 0.17746268212795258 214\n",
      "std_D 0.04296068474650383 214\n",
      "std_G 0.03959406539797783 214\n",
      "[2/1000][90/600][215] Loss_D: 0.179187 Loss_G: 0.179049 \n",
      "output_D 0.17918716371059418 215\n",
      "output_G 0.1790490746498108 215\n",
      "std_D 0.0391819030046463 215\n",
      "std_G 0.03882141038775444 215\n",
      "[2/1000][96/600][216] Loss_D: 0.173939 Loss_G: 0.176957 \n",
      "output_D 0.17393891513347626 216\n",
      "output_G 0.1769574135541916 216\n",
      "std_D 0.040943536907434464 216\n",
      "std_G 0.03985178470611572 216\n",
      "[2/1000][102/600][217] Loss_D: 0.183101 Loss_G: 0.177503 \n",
      "output_D 0.1831006407737732 217\n",
      "output_G 0.17750252783298492 217\n",
      "std_D 0.0381169430911541 217\n",
      "std_G 0.038423091173172 217\n",
      "[2/1000][108/600][218] Loss_D: 0.174516 Loss_G: 0.171922 \n",
      "output_D 0.17451557517051697 218\n",
      "output_G 0.17192180454730988 218\n",
      "std_D 0.04019225761294365 218\n",
      "std_G 0.03547367453575134 218\n",
      "[2/1000][114/600][219] Loss_D: 0.188259 Loss_G: 0.176338 \n",
      "output_D 0.18825946748256683 219\n",
      "output_G 0.17633792757987976 219\n",
      "std_D 0.03928040340542793 219\n",
      "std_G 0.03620466962456703 219\n",
      "[2/1000][120/600][220] Loss_D: 0.173808 Loss_G: 0.179286 \n",
      "output_D 0.17380817234516144 220\n",
      "output_G 0.17928610742092133 220\n",
      "std_D 0.038810845464468 220\n",
      "std_G 0.03677259758114815 220\n",
      "[2/1000][126/600][221] Loss_D: 0.175492 Loss_G: 0.188737 \n",
      "output_D 0.1754918098449707 221\n",
      "output_G 0.18873748183250427 221\n",
      "std_D 0.03873738273978233 221\n",
      "std_G 0.04140843078494072 221\n",
      "[2/1000][132/600][222] Loss_D: 0.170103 Loss_G: 0.147643 \n",
      "output_D 0.17010286450386047 222\n",
      "output_G 0.14764326810836792 222\n",
      "std_D 0.05128270387649536 222\n",
      "std_G 0.07685482501983643 222\n",
      "[2/1000][138/600][223] Loss_D: 0.172828 Loss_G: 0.183379 \n",
      "output_D 0.17282812297344208 223\n",
      "output_G 0.18337857723236084 223\n",
      "std_D 0.03755389526486397 223\n",
      "std_G 0.04076691344380379 223\n",
      "[2/1000][144/600][224] Loss_D: 0.178308 Loss_G: 0.182654 \n",
      "output_D 0.17830835282802582 224\n",
      "output_G 0.18265442550182343 224\n",
      "std_D 0.035194072872400284 224\n",
      "std_G 0.036750201135873795 224\n",
      "[2/1000][150/600][225] Loss_D: 0.183549 Loss_G: 0.184908 \n",
      "output_D 0.18354889750480652 225\n",
      "output_G 0.18490780889987946 225\n",
      "std_D 0.03971976414322853 225\n",
      "std_G 0.03795642778277397 225\n",
      "[2/1000][156/600][226] Loss_D: 0.176837 Loss_G: 0.172710 \n",
      "output_D 0.1768365502357483 226\n",
      "output_G 0.17270979285240173 226\n",
      "std_D 0.03665810450911522 226\n",
      "std_G 0.03926165774464607 226\n",
      "[2/1000][162/600][227] Loss_D: 0.168616 Loss_G: 0.186571 \n",
      "output_D 0.1686156839132309 227\n",
      "output_G 0.18657076358795166 227\n",
      "std_D 0.0380217619240284 227\n",
      "std_G 0.03787866234779358 227\n",
      "[2/1000][168/600][228] Loss_D: 0.175473 Loss_G: 0.177212 \n",
      "output_D 0.17547284066677094 228\n",
      "output_G 0.1772124469280243 228\n",
      "std_D 0.03697291761636734 228\n",
      "std_G 0.043660689145326614 228\n",
      "[2/1000][174/600][229] Loss_D: 0.175747 Loss_G: 0.175240 \n",
      "output_D 0.17574702203273773 229\n",
      "output_G 0.17523962259292603 229\n",
      "std_D 0.034335698932409286 229\n",
      "std_G 0.03639936447143555 229\n",
      "[2/1000][180/600][230] Loss_D: 0.169825 Loss_G: 0.169859 \n",
      "output_D 0.1698245108127594 230\n",
      "output_G 0.16985851526260376 230\n",
      "std_D 0.03263193741440773 230\n",
      "std_G 0.034115422517061234 230\n",
      "[2/1000][186/600][231] Loss_D: 0.179920 Loss_G: 0.175242 \n",
      "output_D 0.17992042005062103 231\n",
      "output_G 0.1752415895462036 231\n",
      "std_D 0.036200638860464096 231\n",
      "std_G 0.03967949375510216 231\n",
      "[2/1000][192/600][232] Loss_D: 0.174970 Loss_G: 0.179912 \n",
      "output_D 0.1749701201915741 232\n",
      "output_G 0.17991229891777039 232\n",
      "std_D 0.030795136466622353 232\n",
      "std_G 0.0384344756603241 232\n",
      "[2/1000][198/600][233] Loss_D: 0.174819 Loss_G: 0.173733 \n",
      "output_D 0.17481862008571625 233\n",
      "output_G 0.17373257875442505 233\n",
      "std_D 0.041415341198444366 233\n",
      "std_G 0.04532517492771149 233\n",
      "[2/1000][204/600][234] Loss_D: 0.173938 Loss_G: 0.159273 \n",
      "output_D 0.17393773794174194 234\n",
      "output_G 0.1592731773853302 234\n",
      "std_D 0.04048512876033783 234\n",
      "std_G 0.05455257371068001 234\n",
      "[2/1000][210/600][235] Loss_D: 0.181572 Loss_G: 0.171863 \n",
      "output_D 0.18157218396663666 235\n",
      "output_G 0.17186321318149567 235\n",
      "std_D 0.04059379920363426 235\n",
      "std_G 0.03982963413000107 235\n",
      "[2/1000][216/600][236] Loss_D: 0.175173 Loss_G: 0.177871 \n",
      "output_D 0.17517317831516266 236\n",
      "output_G 0.17787063121795654 236\n",
      "std_D 0.034058742225170135 236\n",
      "std_G 0.042636461555957794 236\n",
      "[2/1000][222/600][237] Loss_D: 0.173431 Loss_G: 0.167720 \n",
      "output_D 0.17343086004257202 237\n",
      "output_G 0.16772012412548065 237\n",
      "std_D 0.037881527096033096 237\n",
      "std_G 0.04371402785181999 237\n",
      "[2/1000][228/600][238] Loss_D: 0.167023 Loss_G: 0.173759 \n",
      "output_D 0.167022705078125 238\n",
      "output_G 0.17375904321670532 238\n",
      "std_D 0.037124019116163254 238\n",
      "std_G 0.03826171159744263 238\n",
      "[2/1000][234/600][239] Loss_D: 0.182116 Loss_G: 0.175119 \n",
      "output_D 0.18211622536182404 239\n",
      "output_G 0.17511910200119019 239\n",
      "std_D 0.0352938175201416 239\n",
      "std_G 0.037117116153240204 239\n",
      "[2/1000][240/600][240] Loss_D: 0.177936 Loss_G: 0.177828 \n",
      "output_D 0.17793624103069305 240\n",
      "output_G 0.17782768607139587 240\n",
      "std_D 0.0400528721511364 240\n",
      "std_G 0.03804339841008186 240\n",
      "[2/1000][246/600][241] Loss_D: 0.182555 Loss_G: 0.180255 \n",
      "output_D 0.18255461752414703 241\n",
      "output_G 0.18025526404380798 241\n",
      "std_D 0.041113097220659256 241\n",
      "std_G 0.039449602365493774 241\n",
      "[2/1000][252/600][242] Loss_D: 0.182967 Loss_G: 0.172739 \n",
      "output_D 0.1829669028520584 242\n",
      "output_G 0.1727391481399536 242\n",
      "std_D 0.042366765439510345 242\n",
      "std_G 0.04316719248890877 242\n",
      "[2/1000][258/600][243] Loss_D: 0.179886 Loss_G: 0.175408 \n",
      "output_D 0.1798858791589737 243\n",
      "output_G 0.1754084974527359 243\n",
      "std_D 0.045984040945768356 243\n",
      "std_G 0.03737470880150795 243\n",
      "[2/1000][264/600][244] Loss_D: 0.198384 Loss_G: 0.171885 \n",
      "output_D 0.19838355481624603 244\n",
      "output_G 0.17188549041748047 244\n",
      "std_D 0.04460683837532997 244\n",
      "std_G 0.04399126023054123 244\n",
      "[2/1000][270/600][245] Loss_D: 0.181454 Loss_G: 0.183494 \n",
      "output_D 0.1814543902873993 245\n",
      "output_G 0.1834942102432251 245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_D 0.041241273283958435 245\n",
      "std_G 0.03772002086043358 245\n",
      "[2/1000][276/600][246] Loss_D: 0.091194 Loss_G: 0.144210 \n",
      "output_D 0.091194286942482 246\n",
      "output_G 0.14421036839485168 246\n",
      "std_D 0.12303050607442856 246\n",
      "std_G 0.0827115997672081 246\n",
      "[2/1000][282/600][247] Loss_D: 0.179032 Loss_G: 0.177540 \n",
      "output_D 0.17903205752372742 247\n",
      "output_G 0.17754042148590088 247\n",
      "std_D 0.03749663010239601 247\n",
      "std_G 0.05008871480822563 247\n",
      "[2/1000][288/600][248] Loss_D: 0.175154 Loss_G: 0.175150 \n",
      "output_D 0.17515429854393005 248\n",
      "output_G 0.1751500517129898 248\n",
      "std_D 0.03468224033713341 248\n",
      "std_G 0.04378822445869446 248\n",
      "[2/1000][294/600][249] Loss_D: 0.170970 Loss_G: 0.175207 \n",
      "output_D 0.17097046971321106 249\n",
      "output_G 0.17520709335803986 249\n",
      "std_D 0.0416833832859993 249\n",
      "std_G 0.040903251618146896 249\n",
      "[2/1000][300/600][250] Loss_D: 0.177710 Loss_G: 0.175120 \n",
      "output_D 0.17771010100841522 250\n",
      "output_G 0.17511969804763794 250\n",
      "std_D 0.03663948178291321 250\n",
      "std_G 0.04026459529995918 250\n",
      "[2/1000][306/600][251] Loss_D: 0.175131 Loss_G: 0.177473 \n",
      "output_D 0.17513056099414825 251\n",
      "output_G 0.17747320234775543 251\n",
      "std_D 0.03653723746538162 251\n",
      "std_G 0.04124202951788902 251\n",
      "[2/1000][312/600][252] Loss_D: 0.175676 Loss_G: 0.178122 \n",
      "output_D 0.17567585408687592 252\n",
      "output_G 0.17812150716781616 252\n",
      "std_D 0.03526636213064194 252\n",
      "std_G 0.0356878787279129 252\n",
      "[2/1000][318/600][253] Loss_D: 0.178908 Loss_G: 0.175468 \n",
      "output_D 0.17890848219394684 253\n",
      "output_G 0.17546796798706055 253\n",
      "std_D 0.03988438472151756 253\n",
      "std_G 0.037746209651231766 253\n",
      "[2/1000][324/600][254] Loss_D: 0.179073 Loss_G: 0.174097 \n",
      "output_D 0.17907314002513885 254\n",
      "output_G 0.1740969866514206 254\n",
      "std_D 0.04106287658214569 254\n",
      "std_G 0.045073527842760086 254\n",
      "[2/1000][330/600][255] Loss_D: 0.174718 Loss_G: 0.176139 \n",
      "output_D 0.1747180074453354 255\n",
      "output_G 0.17613884806632996 255\n",
      "std_D 0.04694358631968498 255\n",
      "std_G 0.038605641573667526 255\n",
      "[2/1000][336/600][256] Loss_D: 0.181563 Loss_G: 0.178099 \n",
      "output_D 0.1815633922815323 256\n",
      "output_G 0.1780991405248642 256\n",
      "std_D 0.039362601935863495 256\n",
      "std_G 0.04285385087132454 256\n",
      "[2/1000][342/600][257] Loss_D: 0.172555 Loss_G: 0.181741 \n",
      "output_D 0.17255492508411407 257\n",
      "output_G 0.18174123764038086 257\n",
      "std_D 0.03911396116018295 257\n",
      "std_G 0.0434427484869957 257\n",
      "[2/1000][348/600][258] Loss_D: 0.178770 Loss_G: 0.174877 \n",
      "output_D 0.17877034842967987 258\n",
      "output_G 0.17487698793411255 258\n",
      "std_D 0.042561326175928116 258\n",
      "std_G 0.03498810902237892 258\n",
      "[2/1000][354/600][259] Loss_D: 0.179095 Loss_G: 0.171746 \n",
      "output_D 0.17909455299377441 259\n",
      "output_G 0.17174620926380157 259\n",
      "std_D 0.039723802357912064 259\n",
      "std_G 0.038608305156230927 259\n",
      "[2/1000][360/600][260] Loss_D: 0.176930 Loss_G: 0.172450 \n",
      "output_D 0.176929771900177 260\n",
      "output_G 0.17244970798492432 260\n",
      "std_D 0.034843675792217255 260\n",
      "std_G 0.046960603445768356 260\n",
      "[2/1000][366/600][261] Loss_D: 0.183995 Loss_G: 0.177929 \n",
      "output_D 0.18399463593959808 261\n",
      "output_G 0.1779288649559021 261\n",
      "std_D 0.04499547928571701 261\n",
      "std_G 0.05172019451856613 261\n",
      "[2/1000][372/600][262] Loss_D: 0.172587 Loss_G: 0.169715 \n",
      "output_D 0.17258691787719727 262\n",
      "output_G 0.16971458494663239 262\n",
      "std_D 0.03883514553308487 262\n",
      "std_G 0.03490800783038139 262\n",
      "[2/1000][378/600][263] Loss_D: 0.172749 Loss_G: 0.167747 \n",
      "output_D 0.17274890840053558 263\n",
      "output_G 0.16774702072143555 263\n",
      "std_D 0.03616458922624588 263\n",
      "std_G 0.03990656137466431 263\n",
      "[2/1000][384/600][264] Loss_D: 0.174808 Loss_G: 0.175535 \n",
      "output_D 0.17480820417404175 264\n",
      "output_G 0.17553526163101196 264\n",
      "std_D 0.04284258559346199 264\n",
      "std_G 0.038927581161260605 264\n",
      "[2/1000][390/600][265] Loss_D: 0.175791 Loss_G: 0.181864 \n",
      "output_D 0.17579084634780884 265\n",
      "output_G 0.18186436593532562 265\n",
      "std_D 0.037141554057598114 265\n",
      "std_G 0.04328878968954086 265\n",
      "[2/1000][396/600][266] Loss_D: 0.174802 Loss_G: 0.172234 \n",
      "output_D 0.1748022735118866 266\n",
      "output_G 0.1722336709499359 266\n",
      "std_D 0.04335629940032959 266\n",
      "std_G 0.03365408629179001 266\n",
      "[2/1000][402/600][267] Loss_D: 0.162047 Loss_G: 0.169963 \n",
      "output_D 0.16204652190208435 267\n",
      "output_G 0.1699628233909607 267\n",
      "std_D 0.051570553332567215 267\n",
      "std_G 0.05040120333433151 267\n",
      "[2/1000][408/600][268] Loss_D: 0.169861 Loss_G: 0.168053 \n",
      "output_D 0.169861301779747 268\n",
      "output_G 0.16805267333984375 268\n",
      "std_D 0.05258354917168617 268\n",
      "std_G 0.040975671261548996 268\n",
      "[2/1000][414/600][269] Loss_D: 0.177333 Loss_G: 0.175188 \n",
      "output_D 0.17733275890350342 269\n",
      "output_G 0.17518752813339233 269\n",
      "std_D 0.038700371980667114 269\n",
      "std_G 0.03634915500879288 269\n",
      "[2/1000][420/600][270] Loss_D: 0.181453 Loss_G: 0.170691 \n",
      "output_D 0.18145297467708588 270\n",
      "output_G 0.1706913262605667 270\n",
      "std_D 0.04202866181731224 270\n",
      "std_G 0.04025554284453392 270\n",
      "[2/1000][426/600][271] Loss_D: 0.170818 Loss_G: 0.174588 \n",
      "output_D 0.17081831395626068 271\n",
      "output_G 0.17458786070346832 271\n",
      "std_D 0.044417016208171844 271\n",
      "std_G 0.039993319660425186 271\n",
      "[2/1000][432/600][272] Loss_D: 0.179925 Loss_G: 0.186343 \n",
      "output_D 0.17992465198040009 272\n",
      "output_G 0.18634310364723206 272\n",
      "std_D 0.03999321162700653 272\n",
      "std_G 0.03961734101176262 272\n",
      "[2/1000][438/600][273] Loss_D: 0.166278 Loss_G: 0.179845 \n",
      "output_D 0.16627822816371918 273\n",
      "output_G 0.1798454374074936 273\n",
      "std_D 0.038416095077991486 273\n",
      "std_G 0.03971778228878975 273\n",
      "[2/1000][444/600][274] Loss_D: 0.177989 Loss_G: 0.174669 \n",
      "output_D 0.1779894083738327 274\n",
      "output_G 0.1746692955493927 274\n",
      "std_D 0.0430765300989151 274\n",
      "std_G 0.04009879752993584 274\n",
      "[2/1000][450/600][275] Loss_D: 0.178844 Loss_G: 0.177287 \n",
      "output_D 0.1788444221019745 275\n",
      "output_G 0.17728692293167114 275\n",
      "std_D 0.04220744967460632 275\n",
      "std_G 0.042899053543806076 275\n",
      "[2/1000][456/600][276] Loss_D: 0.177906 Loss_G: 0.174156 \n",
      "output_D 0.1779056191444397 276\n",
      "output_G 0.17415571212768555 276\n",
      "std_D 0.03677429258823395 276\n",
      "std_G 0.03978434205055237 276\n",
      "[2/1000][462/600][277] Loss_D: 0.182044 Loss_G: 0.178659 \n",
      "output_D 0.1820436716079712 277\n",
      "output_G 0.17865942418575287 277\n",
      "std_D 0.03548391908407211 277\n",
      "std_G 0.04408668726682663 277\n",
      "[2/1000][468/600][278] Loss_D: 0.172575 Loss_G: 0.178801 \n",
      "output_D 0.17257536947727203 278\n",
      "output_G 0.178800567984581 278\n",
      "std_D 0.03531423956155777 278\n",
      "std_G 0.041469842195510864 278\n",
      "[2/1000][474/600][279] Loss_D: 0.168922 Loss_G: 0.173542 \n",
      "output_D 0.16892209649085999 279\n",
      "output_G 0.1735420525074005 279\n",
      "std_D 0.04674969241023064 279\n",
      "std_G 0.033359795808792114 279\n",
      "[2/1000][480/600][280] Loss_D: 0.181063 Loss_G: 0.178251 \n",
      "output_D 0.18106278777122498 280\n",
      "output_G 0.17825111746788025 280\n",
      "std_D 0.04492577165365219 280\n",
      "std_G 0.03794005885720253 280\n",
      "[2/1000][486/600][281] Loss_D: 0.179253 Loss_G: 0.181822 \n",
      "output_D 0.17925314605236053 281\n",
      "output_G 0.18182235956192017 281\n",
      "std_D 0.03827875480055809 281\n",
      "std_G 0.038505300879478455 281\n",
      "[2/1000][492/600][282] Loss_D: 0.167666 Loss_G: 0.172891 \n",
      "output_D 0.16766586899757385 282\n",
      "output_G 0.17289075255393982 282\n",
      "std_D 0.03826310113072395 282\n",
      "std_G 0.034017451107501984 282\n",
      "[2/1000][498/600][283] Loss_D: 0.172703 Loss_G: 0.170411 \n",
      "output_D 0.17270325124263763 283\n",
      "output_G 0.1704108566045761 283\n",
      "std_D 0.0400787889957428 283\n",
      "std_G 0.03742144629359245 283\n",
      "[2/1000][504/600][284] Loss_D: 0.175521 Loss_G: 0.181546 \n",
      "output_D 0.1755206137895584 284\n",
      "output_G 0.1815461814403534 284\n",
      "std_D 0.039561886340379715 284\n",
      "std_G 0.034288302063941956 284\n",
      "[2/1000][510/600][285] Loss_D: 0.183063 Loss_G: 0.171179 \n",
      "output_D 0.18306252360343933 285\n",
      "output_G 0.17117904126644135 285\n",
      "std_D 0.036994680762290955 285\n",
      "std_G 0.03297362104058266 285\n",
      "[2/1000][516/600][286] Loss_D: 0.177137 Loss_G: 0.175387 \n",
      "output_D 0.1771373748779297 286\n",
      "output_G 0.17538729310035706 286\n",
      "std_D 0.03959101438522339 286\n",
      "std_G 0.04408416524529457 286\n",
      "[2/1000][522/600][287] Loss_D: 0.171258 Loss_G: 0.175081 \n",
      "output_D 0.17125818133354187 287\n",
      "output_G 0.17508064210414886 287\n",
      "std_D 0.039998896420001984 287\n",
      "std_G 0.04653064161539078 287\n",
      "[2/1000][528/600][288] Loss_D: 0.173418 Loss_G: 0.170005 \n",
      "output_D 0.17341792583465576 288\n",
      "output_G 0.17000477015972137 288\n",
      "std_D 0.04191330075263977 288\n",
      "std_G 0.038532353937625885 288\n",
      "[2/1000][534/600][289] Loss_D: 0.176293 Loss_G: 0.176659 \n",
      "output_D 0.17629344761371613 289\n",
      "output_G 0.17665860056877136 289\n",
      "std_D 0.03325263410806656 289\n",
      "std_G 0.040458593517541885 289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/1000][540/600][290] Loss_D: 0.168571 Loss_G: 0.170913 \n",
      "output_D 0.1685710847377777 290\n",
      "output_G 0.1709126979112625 290\n",
      "std_D 0.038899440318346024 290\n",
      "std_G 0.04845327138900757 290\n",
      "[2/1000][546/600][291] Loss_D: 0.178442 Loss_G: 0.178516 \n",
      "output_D 0.1784418821334839 291\n",
      "output_G 0.17851628363132477 291\n",
      "std_D 0.04015784710645676 291\n",
      "std_G 0.04111874848604202 291\n",
      "[2/1000][552/600][292] Loss_D: 0.169379 Loss_G: 0.169127 \n",
      "output_D 0.16937941312789917 292\n",
      "output_G 0.16912692785263062 292\n",
      "std_D 0.04587368667125702 292\n",
      "std_G 0.04221714660525322 292\n",
      "[2/1000][558/600][293] Loss_D: 0.176146 Loss_G: 0.177820 \n",
      "output_D 0.1761457473039627 293\n",
      "output_G 0.1778201460838318 293\n",
      "std_D 0.0385574996471405 293\n",
      "std_G 0.03479939326643944 293\n",
      "[2/1000][564/600][294] Loss_D: 0.171317 Loss_G: 0.184168 \n",
      "output_D 0.17131677269935608 294\n",
      "output_G 0.18416818976402283 294\n",
      "std_D 0.03951532021164894 294\n",
      "std_G 0.04161757230758667 294\n",
      "[2/1000][570/600][295] Loss_D: 0.176465 Loss_G: 0.170358 \n",
      "output_D 0.17646515369415283 295\n",
      "output_G 0.1703575849533081 295\n",
      "std_D 0.03476991131901741 295\n",
      "std_G 0.03456995263695717 295\n",
      "[2/1000][576/600][296] Loss_D: 0.177029 Loss_G: 0.176055 \n",
      "output_D 0.17702850699424744 296\n",
      "output_G 0.1760551631450653 296\n",
      "std_D 0.03893772512674332 296\n",
      "std_G 0.03394602984189987 296\n",
      "[2/1000][582/600][297] Loss_D: 0.184705 Loss_G: 0.179691 \n",
      "output_D 0.18470467627048492 297\n",
      "output_G 0.1796906441450119 297\n",
      "std_D 0.04126744344830513 297\n",
      "std_G 0.04024238884449005 297\n",
      "[2/1000][588/600][298] Loss_D: 0.153445 Loss_G: 0.154862 \n",
      "output_D 0.15344488620758057 298\n",
      "output_G 0.15486201643943787 298\n",
      "std_D 0.08373844623565674 298\n",
      "std_G 0.05935374274849892 298\n",
      "[2/1000][594/600][299] Loss_D: 0.177014 Loss_G: 0.176327 \n",
      "output_D 0.17701369524002075 299\n",
      "output_G 0.1763269454240799 299\n",
      "std_D 0.040111053735017776 299\n",
      "std_G 0.04025905951857567 299\n",
      "[2/1000][600/600][300] Loss_D: 0.177614 Loss_G: 0.179747 \n",
      "output_D 0.1776135116815567 300\n",
      "output_G 0.17974720895290375 300\n",
      "std_D 0.04031717777252197 300\n",
      "std_G 0.03926612809300423 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/1000][6/600][301] Loss_D: 0.172582 Loss_G: 0.174969 \n",
      "output_D 0.17258165776729584 301\n",
      "output_G 0.1749689280986786 301\n",
      "std_D 0.04392623528838158 301\n",
      "std_G 0.03823446109890938 301\n",
      "[3/1000][12/600][302] Loss_D: 0.181720 Loss_G: 0.178805 \n",
      "output_D 0.1817202866077423 302\n",
      "output_G 0.1788051277399063 302\n",
      "std_D 0.03715774789452553 302\n",
      "std_G 0.040508151054382324 302\n",
      "[3/1000][18/600][303] Loss_D: 0.173497 Loss_G: 0.172514 \n",
      "output_D 0.17349672317504883 303\n",
      "output_G 0.17251399159431458 303\n",
      "std_D 0.03973176330327988 303\n",
      "std_G 0.040369536727666855 303\n",
      "[3/1000][24/600][304] Loss_D: 0.184831 Loss_G: 0.173306 \n",
      "output_D 0.184830904006958 304\n",
      "output_G 0.17330583930015564 304\n",
      "std_D 0.04104379937052727 304\n",
      "std_G 0.036392487585544586 304\n",
      "[3/1000][30/600][305] Loss_D: 0.168069 Loss_G: 0.180762 \n",
      "output_D 0.1680690348148346 305\n",
      "output_G 0.18076245486736298 305\n",
      "std_D 0.040441419929265976 305\n",
      "std_G 0.04080383479595184 305\n",
      "[3/1000][36/600][306] Loss_D: 0.176629 Loss_G: 0.187432 \n",
      "output_D 0.17662851512432098 306\n",
      "output_G 0.18743166327476501 306\n",
      "std_D 0.033606547862291336 306\n",
      "std_G 0.04263301566243172 306\n",
      "[3/1000][42/600][307] Loss_D: 0.177665 Loss_G: 0.173676 \n",
      "output_D 0.17766530811786652 307\n",
      "output_G 0.17367568612098694 307\n",
      "std_D 0.038290295749902725 307\n",
      "std_G 0.03567515313625336 307\n",
      "[3/1000][48/600][308] Loss_D: 0.172210 Loss_G: 0.183537 \n",
      "output_D 0.17220951616764069 308\n",
      "output_G 0.18353667855262756 308\n",
      "std_D 0.04173066094517708 308\n",
      "std_G 0.04123016074299812 308\n",
      "[3/1000][54/600][309] Loss_D: 0.185551 Loss_G: 0.178099 \n",
      "output_D 0.1855509877204895 309\n",
      "output_G 0.17809906601905823 309\n",
      "std_D 0.039194878190755844 309\n",
      "std_G 0.034920383244752884 309\n",
      "[3/1000][60/600][310] Loss_D: 0.174226 Loss_G: 0.180145 \n",
      "output_D 0.17422597110271454 310\n",
      "output_G 0.18014530837535858 310\n",
      "std_D 0.03990616649389267 310\n",
      "std_G 0.042322978377342224 310\n",
      "[3/1000][66/600][311] Loss_D: 0.175484 Loss_G: 0.176996 \n",
      "output_D 0.17548415064811707 311\n",
      "output_G 0.1769964098930359 311\n",
      "std_D 0.03876467049121857 311\n",
      "std_G 0.03431915491819382 311\n",
      "[3/1000][72/600][312] Loss_D: 0.176354 Loss_G: 0.169331 \n",
      "output_D 0.17635434865951538 312\n",
      "output_G 0.16933076083660126 312\n",
      "std_D 0.03813578188419342 312\n",
      "std_G 0.03588761389255524 312\n",
      "[3/1000][78/600][313] Loss_D: 0.175199 Loss_G: 0.175085 \n",
      "output_D 0.1751994788646698 313\n",
      "output_G 0.17508545517921448 313\n",
      "std_D 0.03829242289066315 313\n",
      "std_G 0.03561301901936531 313\n",
      "[3/1000][84/600][314] Loss_D: 0.170018 Loss_G: 0.179684 \n",
      "output_D 0.17001783847808838 314\n",
      "output_G 0.17968425154685974 314\n",
      "std_D 0.04506484419107437 314\n",
      "std_G 0.04070236161351204 314\n",
      "[3/1000][90/600][315] Loss_D: 0.181050 Loss_G: 0.177687 \n",
      "output_D 0.18105006217956543 315\n",
      "output_G 0.17768654227256775 315\n",
      "std_D 0.03646158054471016 315\n",
      "std_G 0.03891398012638092 315\n",
      "[3/1000][96/600][316] Loss_D: 0.172945 Loss_G: 0.174182 \n",
      "output_D 0.17294462025165558 316\n",
      "output_G 0.1741824746131897 316\n",
      "std_D 0.04330529272556305 316\n",
      "std_G 0.03706715255975723 316\n",
      "[3/1000][102/600][317] Loss_D: 0.174109 Loss_G: 0.178087 \n",
      "output_D 0.1741091012954712 317\n",
      "output_G 0.17808732390403748 317\n",
      "std_D 0.03744260221719742 317\n",
      "std_G 0.04043114557862282 317\n",
      "[3/1000][108/600][318] Loss_D: 0.173219 Loss_G: 0.175319 \n",
      "output_D 0.17321932315826416 318\n",
      "output_G 0.17531903088092804 318\n",
      "std_D 0.03889206796884537 318\n",
      "std_G 0.039302486926317215 318\n",
      "[3/1000][114/600][319] Loss_D: 0.178933 Loss_G: 0.174721 \n",
      "output_D 0.178932785987854 319\n",
      "output_G 0.17472124099731445 319\n",
      "std_D 0.04605052247643471 319\n",
      "std_G 0.04033931717276573 319\n",
      "[3/1000][120/600][320] Loss_D: 0.179843 Loss_G: 0.181677 \n",
      "output_D 0.1798425167798996 320\n",
      "output_G 0.18167689442634583 320\n",
      "std_D 0.036836039274930954 320\n",
      "std_G 0.040013834834098816 320\n",
      "[3/1000][126/600][321] Loss_D: 0.172398 Loss_G: 0.171032 \n",
      "output_D 0.17239774763584137 321\n",
      "output_G 0.17103171348571777 321\n",
      "std_D 0.03952180594205856 321\n",
      "std_G 0.041265107691287994 321\n",
      "[3/1000][132/600][322] Loss_D: 0.179990 Loss_G: 0.179652 \n",
      "output_D 0.1799902319908142 322\n",
      "output_G 0.17965203523635864 322\n",
      "std_D 0.041902460157871246 322\n",
      "std_G 0.03976042568683624 322\n",
      "[3/1000][138/600][323] Loss_D: 0.182765 Loss_G: 0.175337 \n",
      "output_D 0.1827651709318161 323\n",
      "output_G 0.17533676326274872 323\n",
      "std_D 0.03856450691819191 323\n",
      "std_G 0.03414170444011688 323\n",
      "[3/1000][144/600][324] Loss_D: 0.174190 Loss_G: 0.178514 \n",
      "output_D 0.1741897463798523 324\n",
      "output_G 0.17851391434669495 324\n",
      "std_D 0.046473339200019836 324\n",
      "std_G 0.03810350224375725 324\n",
      "[3/1000][150/600][325] Loss_D: 0.165266 Loss_G: 0.174006 \n",
      "output_D 0.16526634991168976 325\n",
      "output_G 0.1740058958530426 325\n",
      "std_D 0.03742464631795883 325\n",
      "std_G 0.03641099855303764 325\n",
      "[3/1000][156/600][326] Loss_D: 0.169317 Loss_G: 0.171672 \n",
      "output_D 0.1693166196346283 326\n",
      "output_G 0.17167235910892487 326\n",
      "std_D 0.03970637544989586 326\n",
      "std_G 0.03885065019130707 326\n",
      "[3/1000][162/600][327] Loss_D: 0.149902 Loss_G: 0.135926 \n",
      "output_D 0.1499023735523224 327\n",
      "output_G 0.13592584431171417 327\n",
      "std_D 0.0736616924405098 327\n",
      "std_G 0.1003773882985115 327\n",
      "[3/1000][168/600][328] Loss_D: 0.173156 Loss_G: 0.173114 \n",
      "output_D 0.17315615713596344 328\n",
      "output_G 0.17311371862888336 328\n",
      "std_D 0.041226550936698914 328\n",
      "std_G 0.03895856812596321 328\n",
      "[3/1000][174/600][329] Loss_D: 0.169972 Loss_G: 0.177065 \n",
      "output_D 0.16997212171554565 329\n",
      "output_G 0.17706502974033356 329\n",
      "std_D 0.03871564567089081 329\n",
      "std_G 0.03401804342865944 329\n",
      "[3/1000][180/600][330] Loss_D: 0.174617 Loss_G: 0.169564 \n",
      "output_D 0.17461712658405304 330\n",
      "output_G 0.1695639193058014 330\n",
      "std_D 0.03835829719901085 330\n",
      "std_G 0.04606734216213226 330\n",
      "[3/1000][186/600][331] Loss_D: 0.179253 Loss_G: 0.180106 \n",
      "output_D 0.1792525202035904 331\n",
      "output_G 0.1801060289144516 331\n",
      "std_D 0.03999641537666321 331\n",
      "std_G 0.03726992383599281 331\n",
      "[3/1000][192/600][332] Loss_D: 0.175276 Loss_G: 0.168225 \n",
      "output_D 0.17527642846107483 332\n",
      "output_G 0.1682254821062088 332\n",
      "std_D 0.040610380470752716 332\n",
      "std_G 0.03366348519921303 332\n",
      "[3/1000][198/600][333] Loss_D: 0.171192 Loss_G: 0.173589 \n",
      "output_D 0.17119212448596954 333\n",
      "output_G 0.17358875274658203 333\n",
      "std_D 0.0365443155169487 333\n",
      "std_G 0.04047732427716255 333\n",
      "[3/1000][204/600][334] Loss_D: 0.176795 Loss_G: 0.172036 \n",
      "output_D 0.17679546773433685 334\n",
      "output_G 0.1720360517501831 334\n",
      "std_D 0.04322722181677818 334\n",
      "std_G 0.03580097854137421 334\n",
      "[3/1000][210/600][335] Loss_D: 0.180100 Loss_G: 0.173975 \n",
      "output_D 0.18010012805461884 335\n",
      "output_G 0.17397524416446686 335\n",
      "std_D 0.04156392812728882 335\n",
      "std_G 0.038221508264541626 335\n",
      "[3/1000][216/600][336] Loss_D: 0.174194 Loss_G: 0.172715 \n",
      "output_D 0.174193874001503 336\n",
      "output_G 0.17271512746810913 336\n",
      "std_D 0.03684009239077568 336\n",
      "std_G 0.03264465928077698 336\n",
      "[3/1000][222/600][337] Loss_D: 0.176151 Loss_G: 0.168139 \n",
      "output_D 0.17615073919296265 337\n",
      "output_G 0.1681385189294815 337\n",
      "std_D 0.040851350873708725 337\n",
      "std_G 0.04188865050673485 337\n",
      "[3/1000][228/600][338] Loss_D: 0.162538 Loss_G: 0.174313 \n",
      "output_D 0.16253843903541565 338\n",
      "output_G 0.17431297898292542 338\n",
      "std_D 0.03674750402569771 338\n",
      "std_G 0.041661955416202545 338\n",
      "[3/1000][234/600][339] Loss_D: 0.174501 Loss_G: 0.179800 \n",
      "output_D 0.17450115084648132 339\n",
      "output_G 0.1797996610403061 339\n",
      "std_D 0.036842696368694305 339\n",
      "std_G 0.03880593553185463 339\n",
      "[3/1000][240/600][340] Loss_D: 0.172755 Loss_G: 0.176492 \n",
      "output_D 0.17275477945804596 340\n",
      "output_G 0.17649200558662415 340\n",
      "std_D 0.041317276656627655 340\n",
      "std_G 0.038426220417022705 340\n",
      "[3/1000][246/600][341] Loss_D: 0.173110 Loss_G: 0.173306 \n",
      "output_D 0.1731097549200058 341\n",
      "output_G 0.1733059138059616 341\n",
      "std_D 0.0365082211792469 341\n",
      "std_G 0.033678844571113586 341\n",
      "[3/1000][252/600][342] Loss_D: 0.175225 Loss_G: 0.178882 \n",
      "output_D 0.17522545158863068 342\n",
      "output_G 0.17888203263282776 342\n",
      "std_D 0.03610117733478546 342\n",
      "std_G 0.03526744246482849 342\n",
      "[3/1000][258/600][343] Loss_D: 0.181179 Loss_G: 0.171928 \n",
      "output_D 0.18117864429950714 343\n",
      "output_G 0.17192789912223816 343\n",
      "std_D 0.04117245227098465 343\n",
      "std_G 0.03819459304213524 343\n",
      "[3/1000][264/600][344] Loss_D: 0.170123 Loss_G: 0.170289 \n",
      "output_D 0.1701228767633438 344\n",
      "output_G 0.17028912901878357 344\n",
      "std_D 0.0382157601416111 344\n",
      "std_G 0.039006974548101425 344\n",
      "[3/1000][270/600][345] Loss_D: 0.172679 Loss_G: 0.179050 \n",
      "output_D 0.17267915606498718 345\n",
      "output_G 0.17904973030090332 345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_D 0.038017671555280685 345\n",
      "std_G 0.04025699943304062 345\n",
      "[3/1000][276/600][346] Loss_D: 0.176051 Loss_G: 0.179859 \n",
      "output_D 0.1760510951280594 346\n",
      "output_G 0.17985866963863373 346\n",
      "std_D 0.03763243183493614 346\n",
      "std_G 0.036833856254816055 346\n",
      "[3/1000][282/600][347] Loss_D: 0.180880 Loss_G: 0.174800 \n",
      "output_D 0.18087996542453766 347\n",
      "output_G 0.17480017244815826 347\n",
      "std_D 0.033654842525720596 347\n",
      "std_G 0.0391504243016243 347\n",
      "[3/1000][288/600][348] Loss_D: 0.185042 Loss_G: 0.178150 \n",
      "output_D 0.18504168093204498 348\n",
      "output_G 0.17814967036247253 348\n",
      "std_D 0.04180093854665756 348\n",
      "std_G 0.03822033107280731 348\n",
      "[3/1000][294/600][349] Loss_D: 0.176556 Loss_G: 0.179057 \n",
      "output_D 0.1765560805797577 349\n",
      "output_G 0.17905671894550323 349\n",
      "std_D 0.040067169815301895 349\n",
      "std_G 0.037801314145326614 349\n",
      "[3/1000][300/600][350] Loss_D: 0.169857 Loss_G: 0.167843 \n",
      "output_D 0.16985686123371124 350\n",
      "output_G 0.16784344613552094 350\n",
      "std_D 0.041556164622306824 350\n",
      "std_G 0.040633250027894974 350\n",
      "[3/1000][306/600][351] Loss_D: 0.170467 Loss_G: 0.178606 \n",
      "output_D 0.17046701908111572 351\n",
      "output_G 0.17860589921474457 351\n",
      "std_D 0.03417094424366951 351\n",
      "std_G 0.040763773024082184 351\n",
      "[3/1000][312/600][352] Loss_D: 0.173390 Loss_G: 0.167789 \n",
      "output_D 0.17338991165161133 352\n",
      "output_G 0.16778942942619324 352\n",
      "std_D 0.03428374603390694 352\n",
      "std_G 0.03646944835782051 352\n",
      "[3/1000][318/600][353] Loss_D: 0.165469 Loss_G: 0.177431 \n",
      "output_D 0.16546927392482758 353\n",
      "output_G 0.1774314045906067 353\n",
      "std_D 0.03651239722967148 353\n",
      "std_G 0.03424933925271034 353\n",
      "[3/1000][324/600][354] Loss_D: 0.183089 Loss_G: 0.170695 \n",
      "output_D 0.1830889880657196 354\n",
      "output_G 0.1706952452659607 354\n",
      "std_D 0.03219251334667206 354\n",
      "std_G 0.04435407742857933 354\n",
      "[3/1000][330/600][355] Loss_D: 0.168574 Loss_G: 0.180492 \n",
      "output_D 0.1685735434293747 355\n",
      "output_G 0.1804918348789215 355\n",
      "std_D 0.03515195846557617 355\n",
      "std_G 0.04440832510590553 355\n",
      "[3/1000][336/600][356] Loss_D: 0.174581 Loss_G: 0.169398 \n",
      "output_D 0.1745808720588684 356\n",
      "output_G 0.1693975329399109 356\n",
      "std_D 0.039336197078228 356\n",
      "std_G 0.04000762104988098 356\n",
      "[3/1000][342/600][357] Loss_D: 0.133689 Loss_G: 0.147556 \n",
      "output_D 0.1336885541677475 357\n",
      "output_G 0.147555872797966 357\n",
      "std_D 0.09142187982797623 357\n",
      "std_G 0.0774141326546669 357\n",
      "[3/1000][348/600][358] Loss_D: 0.174616 Loss_G: 0.181046 \n",
      "output_D 0.17461563646793365 358\n",
      "output_G 0.1810464859008789 358\n",
      "std_D 0.039708614349365234 358\n",
      "std_G 0.0439879409968853 358\n",
      "[3/1000][354/600][359] Loss_D: 0.175729 Loss_G: 0.172451 \n",
      "output_D 0.17572936415672302 359\n",
      "output_G 0.1724512279033661 359\n",
      "std_D 0.03680561110377312 359\n",
      "std_G 0.03139737248420715 359\n",
      "[3/1000][360/600][360] Loss_D: 0.172376 Loss_G: 0.175307 \n",
      "output_D 0.17237631976604462 360\n",
      "output_G 0.17530666291713715 360\n",
      "std_D 0.04660901054739952 360\n",
      "std_G 0.04047425463795662 360\n",
      "[3/1000][366/600][361] Loss_D: 0.172810 Loss_G: 0.173047 \n",
      "output_D 0.1728096902370453 361\n",
      "output_G 0.17304718494415283 361\n",
      "std_D 0.035787858068943024 361\n",
      "std_G 0.037129297852516174 361\n",
      "[3/1000][372/600][362] Loss_D: 0.176300 Loss_G: 0.174741 \n",
      "output_D 0.17630049586296082 362\n",
      "output_G 0.1747414618730545 362\n",
      "std_D 0.03865775465965271 362\n",
      "std_G 0.03743402659893036 362\n",
      "[3/1000][378/600][363] Loss_D: 0.174324 Loss_G: 0.176760 \n",
      "output_D 0.17432372272014618 363\n",
      "output_G 0.1767600178718567 363\n",
      "std_D 0.04637438431382179 363\n",
      "std_G 0.03925776481628418 363\n",
      "[3/1000][384/600][364] Loss_D: 0.171437 Loss_G: 0.176574 \n",
      "output_D 0.1714368611574173 364\n",
      "output_G 0.17657430469989777 364\n",
      "std_D 0.04447288066148758 364\n",
      "std_G 0.04407607018947601 364\n",
      "[3/1000][390/600][365] Loss_D: 0.175398 Loss_G: 0.174920 \n",
      "output_D 0.17539766430854797 365\n",
      "output_G 0.17492033541202545 365\n",
      "std_D 0.0395820327103138 365\n",
      "std_G 0.0427909716963768 365\n",
      "[3/1000][396/600][366] Loss_D: 0.168365 Loss_G: 0.169573 \n",
      "output_D 0.16836532950401306 366\n",
      "output_G 0.16957299411296844 366\n",
      "std_D 0.03785303235054016 366\n",
      "std_G 0.03409440070390701 366\n",
      "[3/1000][402/600][367] Loss_D: 0.182558 Loss_G: 0.175425 \n",
      "output_D 0.18255776166915894 367\n",
      "output_G 0.1754245162010193 367\n",
      "std_D 0.041942302137613297 367\n",
      "std_G 0.04042676463723183 367\n",
      "[3/1000][408/600][368] Loss_D: 0.164208 Loss_G: 0.168995 \n",
      "output_D 0.1642080694437027 368\n",
      "output_G 0.16899511218070984 368\n",
      "std_D 0.038482826203107834 368\n",
      "std_G 0.040225397795438766 368\n",
      "[3/1000][414/600][369] Loss_D: 0.164957 Loss_G: 0.172780 \n",
      "output_D 0.1649574488401413 369\n",
      "output_G 0.17278018593788147 369\n",
      "std_D 0.03747553005814552 369\n",
      "std_G 0.03851546347141266 369\n",
      "[3/1000][420/600][370] Loss_D: 0.179805 Loss_G: 0.183056 \n",
      "output_D 0.17980486154556274 370\n",
      "output_G 0.18305625021457672 370\n",
      "std_D 0.039297252893447876 370\n",
      "std_G 0.03626551106572151 370\n",
      "[3/1000][426/600][371] Loss_D: 0.176453 Loss_G: 0.170277 \n",
      "output_D 0.17645315825939178 371\n",
      "output_G 0.17027652263641357 371\n",
      "std_D 0.03688382729887962 371\n",
      "std_G 0.03906934708356857 371\n",
      "[3/1000][432/600][372] Loss_D: 0.173444 Loss_G: 0.166071 \n",
      "output_D 0.17344364523887634 372\n",
      "output_G 0.16607104241847992 372\n",
      "std_D 0.037519071251153946 372\n",
      "std_G 0.03687966242432594 372\n",
      "[3/1000][438/600][373] Loss_D: 0.176384 Loss_G: 0.164561 \n",
      "output_D 0.17638425529003143 373\n",
      "output_G 0.16456054151058197 373\n",
      "std_D 0.04140951484441757 373\n",
      "std_G 0.0449734628200531 373\n",
      "[3/1000][444/600][374] Loss_D: 0.169764 Loss_G: 0.182684 \n",
      "output_D 0.16976408660411835 374\n",
      "output_G 0.1826843023300171 374\n",
      "std_D 0.040556345134973526 374\n",
      "std_G 0.042846936732530594 374\n",
      "[3/1000][450/600][375] Loss_D: 0.176103 Loss_G: 0.175332 \n",
      "output_D 0.17610286176204681 375\n",
      "output_G 0.17533166706562042 375\n",
      "std_D 0.042282480746507645 375\n",
      "std_G 0.04137253016233444 375\n",
      "[3/1000][456/600][376] Loss_D: 0.173212 Loss_G: 0.169992 \n",
      "output_D 0.1732119917869568 376\n",
      "output_G 0.16999192535877228 376\n",
      "std_D 0.03486901894211769 376\n",
      "std_G 0.03857539966702461 376\n",
      "[3/1000][462/600][377] Loss_D: 0.172697 Loss_G: 0.165890 \n",
      "output_D 0.1726965308189392 377\n",
      "output_G 0.16589036583900452 377\n",
      "std_D 0.0348932258784771 377\n",
      "std_G 0.0371444933116436 377\n",
      "[3/1000][468/600][378] Loss_D: 0.177470 Loss_G: 0.174683 \n",
      "output_D 0.1774699091911316 378\n",
      "output_G 0.17468316853046417 378\n",
      "std_D 0.04321447014808655 378\n",
      "std_G 0.04479047283530235 378\n",
      "[3/1000][474/600][379] Loss_D: 0.171451 Loss_G: 0.169804 \n",
      "output_D 0.17145052552223206 379\n",
      "output_G 0.16980420053005219 379\n",
      "std_D 0.034248918294906616 379\n",
      "std_G 0.03793849050998688 379\n",
      "[3/1000][480/600][380] Loss_D: 0.173444 Loss_G: 0.177281 \n",
      "output_D 0.1734437495470047 380\n",
      "output_G 0.1772814840078354 380\n",
      "std_D 0.05008591711521149 380\n",
      "std_G 0.03816027194261551 380\n",
      "[3/1000][486/600][381] Loss_D: 0.168704 Loss_G: 0.177159 \n",
      "output_D 0.16870436072349548 381\n",
      "output_G 0.17715874314308167 381\n",
      "std_D 0.04738757759332657 381\n",
      "std_G 0.04440521076321602 381\n",
      "[3/1000][492/600][382] Loss_D: 0.174753 Loss_G: 0.177499 \n",
      "output_D 0.17475305497646332 382\n",
      "output_G 0.17749927937984467 382\n",
      "std_D 0.043703172355890274 382\n",
      "std_G 0.04115445166826248 382\n",
      "[3/1000][498/600][383] Loss_D: 0.177869 Loss_G: 0.168234 \n",
      "output_D 0.1778692603111267 383\n",
      "output_G 0.1682339757680893 383\n",
      "std_D 0.03775543347001076 383\n",
      "std_G 0.04527422785758972 383\n",
      "[3/1000][504/600][384] Loss_D: 0.180920 Loss_G: 0.176688 \n",
      "output_D 0.18092022836208344 384\n",
      "output_G 0.17668810486793518 384\n",
      "std_D 0.033604856580495834 384\n",
      "std_G 0.03869740664958954 384\n",
      "[3/1000][510/600][385] Loss_D: 0.171263 Loss_G: 0.170082 \n",
      "output_D 0.17126277089118958 385\n",
      "output_G 0.17008233070373535 385\n",
      "std_D 0.045043013989925385 385\n",
      "std_G 0.0569295659661293 385\n",
      "[3/1000][516/600][386] Loss_D: 0.181932 Loss_G: 0.172121 \n",
      "output_D 0.18193188309669495 386\n",
      "output_G 0.17212146520614624 386\n",
      "std_D 0.04255952686071396 386\n",
      "std_G 0.038577042520046234 386\n",
      "[3/1000][522/600][387] Loss_D: 0.183705 Loss_G: 0.170291 \n",
      "output_D 0.18370549380779266 387\n",
      "output_G 0.17029108107089996 387\n",
      "std_D 0.04399436339735985 387\n",
      "std_G 0.03665049001574516 387\n",
      "[3/1000][528/600][388] Loss_D: 0.174424 Loss_G: 0.174514 \n",
      "output_D 0.17442399263381958 388\n",
      "output_G 0.17451409995555878 388\n",
      "std_D 0.04136158153414726 388\n",
      "std_G 0.037097278982400894 388\n",
      "[3/1000][534/600][389] Loss_D: 0.174928 Loss_G: 0.172849 \n",
      "output_D 0.17492760717868805 389\n",
      "output_G 0.17284893989562988 389\n",
      "std_D 0.03919006139039993 389\n",
      "std_G 0.04430554062128067 389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/1000][540/600][390] Loss_D: 0.173516 Loss_G: 0.174675 \n",
      "output_D 0.17351646721363068 390\n",
      "output_G 0.17467518150806427 390\n",
      "std_D 0.037105049937963486 390\n",
      "std_G 0.03878543898463249 390\n",
      "[3/1000][546/600][391] Loss_D: 0.174820 Loss_G: 0.177043 \n",
      "output_D 0.17482005059719086 391\n",
      "output_G 0.1770431250333786 391\n",
      "std_D 0.032900370657444 391\n",
      "std_G 0.045182205736637115 391\n",
      "[3/1000][552/600][392] Loss_D: 0.177482 Loss_G: 0.172256 \n",
      "output_D 0.17748208343982697 392\n",
      "output_G 0.17225581407546997 392\n",
      "std_D 0.03566949442028999 392\n",
      "std_G 0.040072739124298096 392\n",
      "[3/1000][558/600][393] Loss_D: 0.173562 Loss_G: 0.171582 \n",
      "output_D 0.17356231808662415 393\n",
      "output_G 0.17158202826976776 393\n",
      "std_D 0.0419655404984951 393\n",
      "std_G 0.036443617194890976 393\n",
      "[3/1000][564/600][394] Loss_D: 0.170038 Loss_G: 0.176839 \n",
      "output_D 0.17003807425498962 394\n",
      "output_G 0.17683930695056915 394\n",
      "std_D 0.04188515990972519 394\n",
      "std_G 0.03573371842503548 394\n",
      "[3/1000][570/600][395] Loss_D: 0.173309 Loss_G: 0.174428 \n",
      "output_D 0.1733093112707138 395\n",
      "output_G 0.1744283139705658 395\n",
      "std_D 0.03659077361226082 395\n",
      "std_G 0.03821257874369621 395\n",
      "[3/1000][576/600][396] Loss_D: 0.175452 Loss_G: 0.172524 \n",
      "output_D 0.17545221745967865 396\n",
      "output_G 0.17252421379089355 396\n",
      "std_D 0.03857513517141342 396\n",
      "std_G 0.037510547786951065 396\n",
      "[3/1000][582/600][397] Loss_D: 0.173545 Loss_G: 0.172819 \n",
      "output_D 0.1735450029373169 397\n",
      "output_G 0.17281854152679443 397\n",
      "std_D 0.03959592431783676 397\n",
      "std_G 0.04055853560566902 397\n",
      "[3/1000][588/600][398] Loss_D: 0.169210 Loss_G: 0.180097 \n",
      "output_D 0.1692095249891281 398\n",
      "output_G 0.18009686470031738 398\n",
      "std_D 0.03760305047035217 398\n",
      "std_G 0.04051708057522774 398\n",
      "[3/1000][594/600][399] Loss_D: 0.178546 Loss_G: 0.178691 \n",
      "output_D 0.17854565382003784 399\n",
      "output_G 0.17869149148464203 399\n",
      "std_D 0.04685531184077263 399\n",
      "std_G 0.0401267372071743 399\n",
      "[3/1000][600/600][400] Loss_D: 0.181325 Loss_G: 0.173652 \n",
      "output_D 0.18132466077804565 400\n",
      "output_G 0.17365221679210663 400\n",
      "std_D 0.03762500360608101 400\n",
      "std_G 0.03471853956580162 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/1000][6/600][401] Loss_D: 0.175767 Loss_G: 0.169257 \n",
      "output_D 0.17576676607131958 401\n",
      "output_G 0.16925698518753052 401\n",
      "std_D 0.040474243462085724 401\n",
      "std_G 0.034624092280864716 401\n",
      "[4/1000][12/600][402] Loss_D: 0.180285 Loss_G: 0.169642 \n",
      "output_D 0.18028497695922852 402\n",
      "output_G 0.16964191198349 402\n",
      "std_D 0.03771878033876419 402\n",
      "std_G 0.03876933827996254 402\n",
      "[4/1000][18/600][403] Loss_D: 0.179550 Loss_G: 0.172957 \n",
      "output_D 0.17954979836940765 403\n",
      "output_G 0.17295749485492706 403\n",
      "std_D 0.04058569297194481 403\n",
      "std_G 0.037466783076524734 403\n",
      "[4/1000][24/600][404] Loss_D: 0.177209 Loss_G: 0.172471 \n",
      "output_D 0.17720919847488403 404\n",
      "output_G 0.1724708080291748 404\n",
      "std_D 0.03767887502908707 404\n",
      "std_G 0.0387534573674202 404\n",
      "[4/1000][30/600][405] Loss_D: 0.176532 Loss_G: 0.173907 \n",
      "output_D 0.17653213441371918 405\n",
      "output_G 0.173906609416008 405\n",
      "std_D 0.03760814666748047 405\n",
      "std_G 0.03642669692635536 405\n",
      "[4/1000][36/600][406] Loss_D: 0.173958 Loss_G: 0.175150 \n",
      "output_D 0.17395827174186707 406\n",
      "output_G 0.1751498430967331 406\n",
      "std_D 0.039751291275024414 406\n",
      "std_G 0.04077543690800667 406\n",
      "[4/1000][42/600][407] Loss_D: 0.173520 Loss_G: 0.179086 \n",
      "output_D 0.17351968586444855 407\n",
      "output_G 0.17908568680286407 407\n",
      "std_D 0.03869662806391716 407\n",
      "std_G 0.042231183499097824 407\n",
      "[4/1000][48/600][408] Loss_D: 0.177055 Loss_G: 0.174298 \n",
      "output_D 0.17705529928207397 408\n",
      "output_G 0.17429843544960022 408\n",
      "std_D 0.03849145770072937 408\n",
      "std_G 0.035346489399671555 408\n",
      "[4/1000][54/600][409] Loss_D: 0.170412 Loss_G: 0.174080 \n",
      "output_D 0.17041164636611938 409\n",
      "output_G 0.17408011853694916 409\n",
      "std_D 0.04119214043021202 409\n",
      "std_G 0.03760999068617821 409\n",
      "[4/1000][60/600][410] Loss_D: 0.173455 Loss_G: 0.171376 \n",
      "output_D 0.17345479130744934 410\n",
      "output_G 0.17137576639652252 410\n",
      "std_D 0.036726489663124084 410\n",
      "std_G 0.0379314124584198 410\n",
      "[4/1000][66/600][411] Loss_D: 0.177719 Loss_G: 0.176565 \n",
      "output_D 0.17771901190280914 411\n",
      "output_G 0.17656542360782623 411\n",
      "std_D 0.03492525592446327 411\n",
      "std_G 0.037615273147821426 411\n",
      "[4/1000][72/600][412] Loss_D: 0.179241 Loss_G: 0.183331 \n",
      "output_D 0.17924141883850098 412\n",
      "output_G 0.18333105742931366 412\n",
      "std_D 0.03827016428112984 412\n",
      "std_G 0.04229085147380829 412\n",
      "[4/1000][78/600][413] Loss_D: 0.172948 Loss_G: 0.183822 \n",
      "output_D 0.17294754087924957 413\n",
      "output_G 0.18382209539413452 413\n",
      "std_D 0.0385841429233551 413\n",
      "std_G 0.035634901374578476 413\n",
      "[4/1000][84/600][414] Loss_D: 0.177478 Loss_G: 0.171321 \n",
      "output_D 0.17747771739959717 414\n",
      "output_G 0.17132118344306946 414\n",
      "std_D 0.03827796131372452 414\n",
      "std_G 0.038225207477808 414\n",
      "[4/1000][90/600][415] Loss_D: 0.177496 Loss_G: 0.169023 \n",
      "output_D 0.177495539188385 415\n",
      "output_G 0.169022798538208 415\n",
      "std_D 0.035454198718070984 415\n",
      "std_G 0.037486352026462555 415\n",
      "[4/1000][96/600][416] Loss_D: 0.179069 Loss_G: 0.176192 \n",
      "output_D 0.1790686845779419 416\n",
      "output_G 0.17619214951992035 416\n",
      "std_D 0.03754517063498497 416\n",
      "std_G 0.04376448318362236 416\n",
      "[4/1000][102/600][417] Loss_D: 0.169521 Loss_G: 0.174228 \n",
      "output_D 0.1695205122232437 417\n",
      "output_G 0.1742277890443802 417\n",
      "std_D 0.03620123118162155 417\n",
      "std_G 0.040367964655160904 417\n",
      "[4/1000][108/600][418] Loss_D: 0.169257 Loss_G: 0.181973 \n",
      "output_D 0.1692570298910141 418\n",
      "output_G 0.18197324872016907 418\n",
      "std_D 0.03757643327116966 418\n",
      "std_G 0.03822384402155876 418\n",
      "[4/1000][114/600][419] Loss_D: 0.184184 Loss_G: 0.171762 \n",
      "output_D 0.18418383598327637 419\n",
      "output_G 0.17176218330860138 419\n",
      "std_D 0.04029195010662079 419\n",
      "std_G 0.03712206333875656 419\n",
      "[4/1000][120/600][420] Loss_D: 0.159560 Loss_G: 0.123562 \n",
      "output_D 0.15956011414527893 420\n",
      "output_G 0.12356238067150116 420\n",
      "std_D 0.06016466021537781 420\n",
      "std_G 0.09736772626638412 420\n",
      "[4/1000][126/600][421] Loss_D: 0.172605 Loss_G: 0.173137 \n",
      "output_D 0.1726047396659851 421\n",
      "output_G 0.17313727736473083 421\n",
      "std_D 0.052457500249147415 421\n",
      "std_G 0.037364792078733444 421\n",
      "[4/1000][132/600][422] Loss_D: 0.176055 Loss_G: 0.177894 \n",
      "output_D 0.17605453729629517 422\n",
      "output_G 0.1778940111398697 422\n",
      "std_D 0.03961116820573807 422\n",
      "std_G 0.03846196085214615 422\n",
      "[4/1000][138/600][423] Loss_D: 0.172732 Loss_G: 0.171687 \n",
      "output_D 0.1727323830127716 423\n",
      "output_G 0.17168670892715454 423\n",
      "std_D 0.03645586594939232 423\n",
      "std_G 0.039218224585056305 423\n",
      "[4/1000][144/600][424] Loss_D: 0.168918 Loss_G: 0.163945 \n",
      "output_D 0.16891849040985107 424\n",
      "output_G 0.16394522786140442 424\n",
      "std_D 0.047380492091178894 424\n",
      "std_G 0.04740132391452789 424\n",
      "[4/1000][150/600][425] Loss_D: 0.177085 Loss_G: 0.172092 \n",
      "output_D 0.17708535492420197 425\n",
      "output_G 0.17209197580814362 425\n",
      "std_D 0.04274595156311989 425\n",
      "std_G 0.037890639156103134 425\n",
      "[4/1000][156/600][426] Loss_D: 0.165992 Loss_G: 0.171240 \n",
      "output_D 0.16599184274673462 426\n",
      "output_G 0.17123976349830627 426\n",
      "std_D 0.038583725690841675 426\n",
      "std_G 0.037187471985816956 426\n",
      "[4/1000][162/600][427] Loss_D: 0.171785 Loss_G: 0.169374 \n",
      "output_D 0.17178520560264587 427\n",
      "output_G 0.16937440633773804 427\n",
      "std_D 0.036643438041210175 427\n",
      "std_G 0.03724539279937744 427\n",
      "[4/1000][168/600][428] Loss_D: 0.174803 Loss_G: 0.172890 \n",
      "output_D 0.17480282485485077 428\n",
      "output_G 0.17289017140865326 428\n",
      "std_D 0.038998961448669434 428\n",
      "std_G 0.04334722086787224 428\n",
      "[4/1000][174/600][429] Loss_D: 0.168842 Loss_G: 0.174858 \n",
      "output_D 0.16884157061576843 429\n",
      "output_G 0.17485816776752472 429\n",
      "std_D 0.043262530118227005 429\n",
      "std_G 0.03958198055624962 429\n",
      "[4/1000][180/600][430] Loss_D: 0.173490 Loss_G: 0.169873 \n",
      "output_D 0.1734897941350937 430\n",
      "output_G 0.16987332701683044 430\n",
      "std_D 0.03901175782084465 430\n",
      "std_G 0.044015321880578995 430\n",
      "[4/1000][186/600][431] Loss_D: 0.179960 Loss_G: 0.176748 \n",
      "output_D 0.1799602061510086 431\n",
      "output_G 0.17674773931503296 431\n",
      "std_D 0.04151720553636551 431\n",
      "std_G 0.04039246216416359 431\n",
      "[4/1000][192/600][432] Loss_D: 0.171600 Loss_G: 0.172531 \n",
      "output_D 0.17160016298294067 432\n",
      "output_G 0.17253144085407257 432\n",
      "std_D 0.03845088556408882 432\n",
      "std_G 0.041314125061035156 432\n",
      "[4/1000][198/600][433] Loss_D: 0.180292 Loss_G: 0.168258 \n",
      "output_D 0.18029168248176575 433\n",
      "output_G 0.16825799643993378 433\n",
      "std_D 0.0407903827726841 433\n",
      "std_G 0.034828510135412216 433\n",
      "[4/1000][204/600][434] Loss_D: 0.174651 Loss_G: 0.180192 \n",
      "output_D 0.1746508777141571 434\n",
      "output_G 0.18019238114356995 434\n",
      "std_D 0.03835446015000343 434\n",
      "std_G 0.03650109842419624 434\n",
      "[4/1000][210/600][435] Loss_D: 0.175686 Loss_G: 0.174283 \n",
      "output_D 0.17568621039390564 435\n",
      "output_G 0.174282506108284 435\n",
      "std_D 0.038438402116298676 435\n",
      "std_G 0.04107736423611641 435\n",
      "[4/1000][216/600][436] Loss_D: 0.174570 Loss_G: 0.179005 \n",
      "output_D 0.17456978559494019 436\n",
      "output_G 0.17900484800338745 436\n",
      "std_D 0.04692357778549194 436\n",
      "std_G 0.03908179700374603 436\n",
      "[4/1000][222/600][437] Loss_D: 0.172875 Loss_G: 0.177577 \n",
      "output_D 0.17287464439868927 437\n",
      "output_G 0.17757725715637207 437\n",
      "std_D 0.040210530161857605 437\n",
      "std_G 0.03605048358440399 437\n",
      "[4/1000][228/600][438] Loss_D: 0.170357 Loss_G: 0.173413 \n",
      "output_D 0.1703571379184723 438\n",
      "output_G 0.17341290414333344 438\n",
      "std_D 0.03464318439364433 438\n",
      "std_G 0.04265405237674713 438\n",
      "[4/1000][234/600][439] Loss_D: 0.175178 Loss_G: 0.178731 \n",
      "output_D 0.175177663564682 439\n",
      "output_G 0.1787310093641281 439\n",
      "std_D 0.039901793003082275 439\n",
      "std_G 0.0460086390376091 439\n",
      "[4/1000][240/600][440] Loss_D: 0.176140 Loss_G: 0.175956 \n",
      "output_D 0.1761396825313568 440\n",
      "output_G 0.1759556531906128 440\n",
      "std_D 0.038902223110198975 440\n",
      "std_G 0.04160331189632416 440\n",
      "[4/1000][246/600][441] Loss_D: 0.177974 Loss_G: 0.175784 \n",
      "output_D 0.1779739111661911 441\n",
      "output_G 0.1757843792438507 441\n",
      "std_D 0.04105156287550926 441\n",
      "std_G 0.0394684262573719 441\n",
      "[4/1000][252/600][442] Loss_D: 0.179996 Loss_G: 0.182153 \n",
      "output_D 0.17999564111232758 442\n",
      "output_G 0.18215295672416687 442\n",
      "std_D 0.041875459253787994 442\n",
      "std_G 0.04144025593996048 442\n",
      "[4/1000][258/600][443] Loss_D: 0.170918 Loss_G: 0.168109 \n",
      "output_D 0.17091786861419678 443\n",
      "output_G 0.16810859739780426 443\n",
      "std_D 0.039405129849910736 443\n",
      "std_G 0.040471646934747696 443\n",
      "[4/1000][264/600][444] Loss_D: 0.173210 Loss_G: 0.168475 \n",
      "output_D 0.17321038246154785 444\n",
      "output_G 0.16847515106201172 444\n",
      "std_D 0.03912182152271271 444\n",
      "std_G 0.03345055133104324 444\n",
      "[4/1000][270/600][445] Loss_D: 0.175985 Loss_G: 0.171476 \n",
      "output_D 0.17598459124565125 445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_G 0.17147624492645264 445\n",
      "std_D 0.037872929126024246 445\n",
      "std_G 0.03842851519584656 445\n",
      "[4/1000][276/600][446] Loss_D: 0.172197 Loss_G: 0.175269 \n",
      "output_D 0.17219698429107666 446\n",
      "output_G 0.17526927590370178 446\n",
      "std_D 0.04333200678229332 446\n",
      "std_G 0.035524770617485046 446\n",
      "[4/1000][282/600][447] Loss_D: 0.172678 Loss_G: 0.178896 \n",
      "output_D 0.17267769575119019 447\n",
      "output_G 0.17889630794525146 447\n",
      "std_D 0.0425553023815155 447\n",
      "std_G 0.0395699143409729 447\n",
      "[4/1000][288/600][448] Loss_D: 0.177206 Loss_G: 0.167601 \n",
      "output_D 0.17720560729503632 448\n",
      "output_G 0.16760121285915375 448\n",
      "std_D 0.04174347221851349 448\n",
      "std_G 0.0396447479724884 448\n",
      "[4/1000][294/600][449] Loss_D: 0.171913 Loss_G: 0.173311 \n",
      "output_D 0.1719132363796234 449\n",
      "output_G 0.1733110398054123 449\n",
      "std_D 0.03542192280292511 449\n",
      "std_G 0.039253681898117065 449\n",
      "[4/1000][300/600][450] Loss_D: 0.177724 Loss_G: 0.173721 \n",
      "output_D 0.17772404849529266 450\n",
      "output_G 0.17372052371501923 450\n",
      "std_D 0.04594973102211952 450\n",
      "std_G 0.036874957382678986 450\n",
      "[4/1000][306/600][451] Loss_D: 0.176083 Loss_G: 0.175572 \n",
      "output_D 0.17608283460140228 451\n",
      "output_G 0.175572007894516 451\n",
      "std_D 0.05255837365984917 451\n",
      "std_G 0.041571423411369324 451\n",
      "[4/1000][312/600][452] Loss_D: 0.165393 Loss_G: 0.167934 \n",
      "output_D 0.16539345681667328 452\n",
      "output_G 0.16793407499790192 452\n",
      "std_D 0.044196873903274536 452\n",
      "std_G 0.03998197242617607 452\n",
      "[4/1000][318/600][453] Loss_D: 0.178577 Loss_G: 0.176467 \n",
      "output_D 0.1785774976015091 453\n",
      "output_G 0.17646722495555878 453\n",
      "std_D 0.04307237267494202 453\n",
      "std_G 0.03927066549658775 453\n",
      "[4/1000][324/600][454] Loss_D: 0.167094 Loss_G: 0.175396 \n",
      "output_D 0.16709353029727936 454\n",
      "output_G 0.17539624869823456 454\n",
      "std_D 0.03927844762802124 454\n",
      "std_G 0.03365929797291756 454\n",
      "[4/1000][330/600][455] Loss_D: 0.176151 Loss_G: 0.170994 \n",
      "output_D 0.17615143954753876 455\n",
      "output_G 0.17099367082118988 455\n",
      "std_D 0.04050937667489052 455\n",
      "std_G 0.03768245875835419 455\n",
      "[4/1000][336/600][456] Loss_D: 0.170793 Loss_G: 0.174496 \n",
      "output_D 0.1707931011915207 456\n",
      "output_G 0.17449623346328735 456\n",
      "std_D 0.03348099812865257 456\n",
      "std_G 0.039010267704725266 456\n",
      "[4/1000][342/600][457] Loss_D: 0.170508 Loss_G: 0.175310 \n",
      "output_D 0.17050766944885254 457\n",
      "output_G 0.17530956864356995 457\n",
      "std_D 0.039145734161138535 457\n",
      "std_G 0.03710732236504555 457\n",
      "[4/1000][348/600][458] Loss_D: 0.170915 Loss_G: 0.177103 \n",
      "output_D 0.17091453075408936 458\n",
      "output_G 0.17710347473621368 458\n",
      "std_D 0.037642620503902435 458\n",
      "std_G 0.03623627871274948 458\n",
      "[4/1000][354/600][459] Loss_D: 0.170964 Loss_G: 0.186639 \n",
      "output_D 0.1709640771150589 459\n",
      "output_G 0.18663866817951202 459\n",
      "std_D 0.04046183452010155 459\n",
      "std_G 0.036306388676166534 459\n",
      "[4/1000][360/600][460] Loss_D: 0.186665 Loss_G: 0.178607 \n",
      "output_D 0.18666483461856842 460\n",
      "output_G 0.1786065697669983 460\n",
      "std_D 0.039160702377557755 460\n",
      "std_G 0.03698522970080376 460\n",
      "[4/1000][366/600][461] Loss_D: 0.167551 Loss_G: 0.165218 \n",
      "output_D 0.16755057871341705 461\n",
      "output_G 0.1652175486087799 461\n",
      "std_D 0.03713184595108032 461\n",
      "std_G 0.035860173404216766 461\n",
      "[4/1000][372/600][462] Loss_D: 0.177966 Loss_G: 0.176925 \n",
      "output_D 0.17796620726585388 462\n",
      "output_G 0.17692473530769348 462\n",
      "std_D 0.03669514134526253 462\n",
      "std_G 0.04036105051636696 462\n",
      "[4/1000][378/600][463] Loss_D: 0.174473 Loss_G: 0.171836 \n",
      "output_D 0.17447322607040405 463\n",
      "output_G 0.17183595895767212 463\n",
      "std_D 0.03735468536615372 463\n",
      "std_G 0.03529246151447296 463\n",
      "[4/1000][384/600][464] Loss_D: 0.170539 Loss_G: 0.173353 \n",
      "output_D 0.17053930461406708 464\n",
      "output_G 0.17335262894630432 464\n",
      "std_D 0.037060316652059555 464\n",
      "std_G 0.033032964915037155 464\n",
      "[4/1000][390/600][465] Loss_D: 0.168701 Loss_G: 0.175637 \n",
      "output_D 0.16870103776454926 465\n",
      "output_G 0.17563700675964355 465\n",
      "std_D 0.03536107763648033 465\n",
      "std_G 0.03917549550533295 465\n",
      "[4/1000][396/600][466] Loss_D: 0.173164 Loss_G: 0.176312 \n",
      "output_D 0.17316411435604095 466\n",
      "output_G 0.17631244659423828 466\n",
      "std_D 0.039985112845897675 466\n",
      "std_G 0.03620331361889839 466\n",
      "[4/1000][402/600][467] Loss_D: 0.176097 Loss_G: 0.165283 \n",
      "output_D 0.17609699070453644 467\n",
      "output_G 0.16528284549713135 467\n",
      "std_D 0.03825604170560837 467\n",
      "std_G 0.03892470896244049 467\n",
      "[4/1000][408/600][468] Loss_D: 0.168404 Loss_G: 0.177259 \n",
      "output_D 0.16840411722660065 468\n",
      "output_G 0.1772589385509491 468\n",
      "std_D 0.03779338300228119 468\n",
      "std_G 0.03595852851867676 468\n",
      "[4/1000][414/600][469] Loss_D: 0.169921 Loss_G: 0.178996 \n",
      "output_D 0.16992059350013733 469\n",
      "output_G 0.17899566888809204 469\n",
      "std_D 0.03347151353955269 469\n",
      "std_G 0.045807648450136185 469\n",
      "[4/1000][420/600][470] Loss_D: 0.174793 Loss_G: 0.177469 \n",
      "output_D 0.17479345202445984 470\n",
      "output_G 0.17746873199939728 470\n",
      "std_D 0.0407819002866745 470\n",
      "std_G 0.040027108043432236 470\n",
      "[4/1000][426/600][471] Loss_D: 0.174250 Loss_G: 0.167423 \n",
      "output_D 0.17424984276294708 471\n",
      "output_G 0.16742295026779175 471\n",
      "std_D 0.04452115669846535 471\n",
      "std_G 0.03956377133727074 471\n",
      "[4/1000][432/600][472] Loss_D: 0.171131 Loss_G: 0.174993 \n",
      "output_D 0.17113056778907776 472\n",
      "output_G 0.17499253153800964 472\n",
      "std_D 0.03940974920988083 472\n",
      "std_G 0.04084782302379608 472\n",
      "[4/1000][438/600][473] Loss_D: 0.169478 Loss_G: 0.170451 \n",
      "output_D 0.16947828233242035 473\n",
      "output_G 0.1704506129026413 473\n",
      "std_D 0.035268306732177734 473\n",
      "std_G 0.04113488644361496 473\n",
      "[4/1000][444/600][474] Loss_D: 0.171613 Loss_G: 0.169438 \n",
      "output_D 0.17161305248737335 474\n",
      "output_G 0.1694381833076477 474\n",
      "std_D 0.036789149045944214 474\n",
      "std_G 0.037399355322122574 474\n",
      "[4/1000][450/600][475] Loss_D: 0.172344 Loss_G: 0.173985 \n",
      "output_D 0.17234385013580322 475\n",
      "output_G 0.1739848107099533 475\n",
      "std_D 0.03901377320289612 475\n",
      "std_G 0.03723315894603729 475\n",
      "[4/1000][456/600][476] Loss_D: 0.173752 Loss_G: 0.179937 \n",
      "output_D 0.1737518012523651 476\n",
      "output_G 0.1799367368221283 476\n",
      "std_D 0.04158562421798706 476\n",
      "std_G 0.04314325004816055 476\n",
      "[4/1000][462/600][477] Loss_D: 0.167914 Loss_G: 0.176508 \n",
      "output_D 0.16791382431983948 477\n",
      "output_G 0.1765075922012329 477\n",
      "std_D 0.036489225924015045 477\n",
      "std_G 0.039053741842508316 477\n",
      "[4/1000][468/600][478] Loss_D: 0.170056 Loss_G: 0.171354 \n",
      "output_D 0.17005568742752075 478\n",
      "output_G 0.1713542640209198 478\n",
      "std_D 0.039471402764320374 478\n",
      "std_G 0.037577129900455475 478\n",
      "[4/1000][474/600][479] Loss_D: 0.174832 Loss_G: 0.171595 \n",
      "output_D 0.17483171820640564 479\n",
      "output_G 0.17159536480903625 479\n",
      "std_D 0.04085390269756317 479\n",
      "std_G 0.038180429488420486 479\n",
      "[4/1000][480/600][480] Loss_D: 0.175860 Loss_G: 0.172916 \n",
      "output_D 0.17585989832878113 480\n",
      "output_G 0.17291566729545593 480\n",
      "std_D 0.04131300002336502 480\n",
      "std_G 0.03869418799877167 480\n",
      "[4/1000][486/600][481] Loss_D: 0.171148 Loss_G: 0.168942 \n",
      "output_D 0.17114754021167755 481\n",
      "output_G 0.16894163191318512 481\n",
      "std_D 0.04374874010682106 481\n",
      "std_G 0.04043916240334511 481\n",
      "[4/1000][492/600][482] Loss_D: 0.179411 Loss_G: 0.174790 \n",
      "output_D 0.1794108897447586 482\n",
      "output_G 0.17478987574577332 482\n",
      "std_D 0.03980892524123192 482\n",
      "std_G 0.03933678939938545 482\n",
      "[4/1000][498/600][483] Loss_D: 0.173323 Loss_G: 0.176361 \n",
      "output_D 0.17332258820533752 483\n",
      "output_G 0.1763610541820526 483\n",
      "std_D 0.03759852796792984 483\n",
      "std_G 0.04422833397984505 483\n",
      "[4/1000][504/600][484] Loss_D: 0.183791 Loss_G: 0.173375 \n",
      "output_D 0.18379075825214386 484\n",
      "output_G 0.17337501049041748 484\n",
      "std_D 0.03823570907115936 484\n",
      "std_G 0.040367841720581055 484\n",
      "[4/1000][510/600][485] Loss_D: 0.172548 Loss_G: 0.180680 \n",
      "output_D 0.17254820466041565 485\n",
      "output_G 0.18068024516105652 485\n",
      "std_D 0.03929472714662552 485\n",
      "std_G 0.038557641208171844 485\n",
      "[4/1000][516/600][486] Loss_D: 0.175440 Loss_G: 0.179311 \n",
      "output_D 0.1754399985074997 486\n",
      "output_G 0.17931117117404938 486\n",
      "std_D 0.042004574090242386 486\n",
      "std_G 0.03297187760472298 486\n",
      "[4/1000][522/600][487] Loss_D: 0.183259 Loss_G: 0.174765 \n",
      "output_D 0.18325923383235931 487\n",
      "output_G 0.17476482689380646 487\n",
      "std_D 0.03899361938238144 487\n",
      "std_G 0.03974725678563118 487\n",
      "[4/1000][528/600][488] Loss_D: 0.174465 Loss_G: 0.170199 \n",
      "output_D 0.17446544766426086 488\n",
      "output_G 0.17019878327846527 488\n",
      "std_D 0.04168872535228729 488\n",
      "std_G 0.03909287601709366 488\n",
      "[4/1000][534/600][489] Loss_D: 0.171875 Loss_G: 0.176696 \n",
      "output_D 0.17187462747097015 489\n",
      "output_G 0.17669589817523956 489\n",
      "std_D 0.04243044927716255 489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_G 0.045492105185985565 489\n",
      "[4/1000][540/600][490] Loss_D: 0.169229 Loss_G: 0.177164 \n",
      "output_D 0.1692294031381607 490\n",
      "output_G 0.17716403305530548 490\n",
      "std_D 0.03693314269185066 490\n",
      "std_G 0.042060352861881256 490\n",
      "[4/1000][546/600][491] Loss_D: 0.179657 Loss_G: 0.176218 \n",
      "output_D 0.17965704202651978 491\n",
      "output_G 0.1762184351682663 491\n",
      "std_D 0.0366785041987896 491\n",
      "std_G 0.03711284324526787 491\n",
      "[4/1000][552/600][492] Loss_D: 0.182057 Loss_G: 0.176774 \n",
      "output_D 0.18205732107162476 492\n",
      "output_G 0.1767737865447998 492\n",
      "std_D 0.03925854340195656 492\n",
      "std_G 0.036449890583753586 492\n",
      "[4/1000][558/600][493] Loss_D: 0.155475 Loss_G: 0.064662 \n",
      "output_D 0.15547479689121246 493\n",
      "output_G 0.064661905169487 493\n",
      "std_D 0.07369241118431091 493\n",
      "std_G 0.15713930130004883 493\n",
      "[4/1000][564/600][494] Loss_D: 0.174617 Loss_G: 0.172360 \n",
      "output_D 0.17461657524108887 494\n",
      "output_G 0.17236033082008362 494\n",
      "std_D 0.05940616875886917 494\n",
      "std_G 0.05092109367251396 494\n",
      "[4/1000][570/600][495] Loss_D: 0.175288 Loss_G: 0.180967 \n",
      "output_D 0.17528817057609558 495\n",
      "output_G 0.18096688389778137 495\n",
      "std_D 0.04475224018096924 495\n",
      "std_G 0.04288732632994652 495\n",
      "[4/1000][576/600][496] Loss_D: 0.171605 Loss_G: 0.177867 \n",
      "output_D 0.17160484194755554 496\n",
      "output_G 0.17786666750907898 496\n",
      "std_D 0.03640899062156677 496\n",
      "std_G 0.041325151920318604 496\n",
      "[4/1000][582/600][497] Loss_D: 0.190443 Loss_G: 0.174945 \n",
      "output_D 0.1904432326555252 497\n",
      "output_G 0.1749453991651535 497\n",
      "std_D 0.042756080627441406 497\n",
      "std_G 0.04488353803753853 497\n",
      "[4/1000][588/600][498] Loss_D: 0.179398 Loss_G: 0.180894 \n",
      "output_D 0.1793982982635498 498\n",
      "output_G 0.18089404702186584 498\n",
      "std_D 0.042367804795503616 498\n",
      "std_G 0.04066005349159241 498\n",
      "[4/1000][594/600][499] Loss_D: 0.180618 Loss_G: 0.184641 \n",
      "output_D 0.18061847984790802 499\n",
      "output_G 0.18464131653308868 499\n",
      "std_D 0.042617641389369965 499\n",
      "std_G 0.0427137054502964 499\n",
      "[4/1000][600/600][500] Loss_D: 0.173882 Loss_G: 0.177413 \n",
      "output_D 0.17388159036636353 500\n",
      "output_G 0.177412748336792 500\n",
      "std_D 0.04147942364215851 500\n",
      "std_G 0.042811669409275055 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/1000][6/600][501] Loss_D: 0.173098 Loss_G: 0.175217 \n",
      "output_D 0.1730983555316925 501\n",
      "output_G 0.17521712183952332 501\n",
      "std_D 0.04124006628990173 501\n",
      "std_G 0.039504166692495346 501\n",
      "[5/1000][12/600][502] Loss_D: 0.180833 Loss_G: 0.178677 \n",
      "output_D 0.18083268404006958 502\n",
      "output_G 0.1786772459745407 502\n",
      "std_D 0.04378724470734596 502\n",
      "std_G 0.042971301823854446 502\n",
      "[5/1000][18/600][503] Loss_D: 0.174942 Loss_G: 0.172883 \n",
      "output_D 0.17494212090969086 503\n",
      "output_G 0.17288348078727722 503\n",
      "std_D 0.03904050961136818 503\n",
      "std_G 0.038488417863845825 503\n",
      "[5/1000][24/600][504] Loss_D: 0.185551 Loss_G: 0.174265 \n",
      "output_D 0.18555058538913727 504\n",
      "output_G 0.17426468431949615 504\n",
      "std_D 0.03633980453014374 504\n",
      "std_G 0.03795177489519119 504\n",
      "[5/1000][30/600][505] Loss_D: 0.177842 Loss_G: 0.179563 \n",
      "output_D 0.17784187197685242 505\n",
      "output_G 0.1795629858970642 505\n",
      "std_D 0.03993035480380058 505\n",
      "std_G 0.03350723534822464 505\n",
      "[5/1000][36/600][506] Loss_D: 0.180245 Loss_G: 0.187047 \n",
      "output_D 0.18024496734142303 506\n",
      "output_G 0.18704719841480255 506\n",
      "std_D 0.04392220824956894 506\n",
      "std_G 0.045060478150844574 506\n",
      "[5/1000][42/600][507] Loss_D: 0.182702 Loss_G: 0.178291 \n",
      "output_D 0.1827017068862915 507\n",
      "output_G 0.17829129099845886 507\n",
      "std_D 0.040645334869623184 507\n",
      "std_G 0.037475503981113434 507\n",
      "[5/1000][48/600][508] Loss_D: 0.178538 Loss_G: 0.181984 \n",
      "output_D 0.17853783071041107 508\n",
      "output_G 0.18198446929454803 508\n",
      "std_D 0.03851138427853584 508\n",
      "std_G 0.03914059326052666 508\n",
      "[5/1000][54/600][509] Loss_D: 0.176626 Loss_G: 0.179787 \n",
      "output_D 0.17662592232227325 509\n",
      "output_G 0.17978699505329132 509\n",
      "std_D 0.03784793242812157 509\n",
      "std_G 0.04156450554728508 509\n",
      "[5/1000][60/600][510] Loss_D: 0.178026 Loss_G: 0.175855 \n",
      "output_D 0.1780257374048233 510\n",
      "output_G 0.17585542798042297 510\n",
      "std_D 0.038112591952085495 510\n",
      "std_G 0.04342721402645111 510\n",
      "[5/1000][66/600][511] Loss_D: 0.178564 Loss_G: 0.181988 \n",
      "output_D 0.1785636693239212 511\n",
      "output_G 0.1819881945848465 511\n",
      "std_D 0.039707861840724945 511\n",
      "std_G 0.03826725855469704 511\n",
      "[5/1000][72/600][512] Loss_D: 0.182489 Loss_G: 0.184223 \n",
      "output_D 0.18248870968818665 512\n",
      "output_G 0.18422313034534454 512\n",
      "std_D 0.041420746594667435 512\n",
      "std_G 0.04012080654501915 512\n",
      "[5/1000][78/600][513] Loss_D: 0.178989 Loss_G: 0.185236 \n",
      "output_D 0.17898911237716675 513\n",
      "output_G 0.18523594737052917 513\n",
      "std_D 0.039073459804058075 513\n",
      "std_G 0.03904053196310997 513\n",
      "[5/1000][84/600][514] Loss_D: 0.185402 Loss_G: 0.184295 \n",
      "output_D 0.18540243804454803 514\n",
      "output_G 0.18429496884346008 514\n",
      "std_D 0.03873298317193985 514\n",
      "std_G 0.04377562552690506 514\n",
      "[5/1000][90/600][515] Loss_D: 0.180333 Loss_G: 0.185394 \n",
      "output_D 0.18033267557621002 515\n",
      "output_G 0.18539419770240784 515\n",
      "std_D 0.03592588007450104 515\n",
      "std_G 0.03817437216639519 515\n",
      "[5/1000][96/600][516] Loss_D: 0.167763 Loss_G: 0.173305 \n",
      "output_D 0.16776253283023834 516\n",
      "output_G 0.17330503463745117 516\n",
      "std_D 0.03762727603316307 516\n",
      "std_G 0.040833260864019394 516\n",
      "[5/1000][102/600][517] Loss_D: 0.181135 Loss_G: 0.189075 \n",
      "output_D 0.18113474547863007 517\n",
      "output_G 0.18907544016838074 517\n",
      "std_D 0.038514282554388046 517\n",
      "std_G 0.04304168000817299 517\n",
      "[5/1000][108/600][518] Loss_D: 0.185515 Loss_G: 0.172417 \n",
      "output_D 0.1855151504278183 518\n",
      "output_G 0.17241725325584412 518\n",
      "std_D 0.03537468984723091 518\n",
      "std_G 0.03869227319955826 518\n",
      "[5/1000][114/600][519] Loss_D: 0.183671 Loss_G: 0.173325 \n",
      "output_D 0.18367145955562592 519\n",
      "output_G 0.17332489788532257 519\n",
      "std_D 0.041146170347929 519\n",
      "std_G 0.041987739503383636 519\n",
      "[5/1000][120/600][520] Loss_D: 0.178414 Loss_G: 0.181889 \n",
      "output_D 0.1784142255783081 520\n",
      "output_G 0.18188856542110443 520\n",
      "std_D 0.042426832020282745 520\n",
      "std_G 0.0362606979906559 520\n",
      "[5/1000][126/600][521] Loss_D: 0.183239 Loss_G: 0.187861 \n",
      "output_D 0.18323948979377747 521\n",
      "output_G 0.1878611296415329 521\n",
      "std_D 0.04163036867976189 521\n",
      "std_G 0.049420565366744995 521\n",
      "[5/1000][132/600][522] Loss_D: 0.174804 Loss_G: 0.178147 \n",
      "output_D 0.17480352520942688 522\n",
      "output_G 0.1781468242406845 522\n",
      "std_D 0.039164040237665176 522\n",
      "std_G 0.039240762591362 522\n",
      "[5/1000][138/600][523] Loss_D: 0.174980 Loss_G: 0.174916 \n",
      "output_D 0.1749802678823471 523\n",
      "output_G 0.17491590976715088 523\n",
      "std_D 0.039343979209661484 523\n",
      "std_G 0.041293226182460785 523\n",
      "[5/1000][144/600][524] Loss_D: 0.167128 Loss_G: 0.167279 \n",
      "output_D 0.16712820529937744 524\n",
      "output_G 0.16727901995182037 524\n",
      "std_D 0.036155473440885544 524\n",
      "std_G 0.04102884232997894 524\n",
      "[5/1000][150/600][525] Loss_D: 0.174987 Loss_G: 0.176639 \n",
      "output_D 0.17498727142810822 525\n",
      "output_G 0.17663875222206116 525\n",
      "std_D 0.036988869309425354 525\n",
      "std_G 0.03851974382996559 525\n",
      "[5/1000][156/600][526] Loss_D: 0.174406 Loss_G: 0.180897 \n",
      "output_D 0.17440567910671234 526\n",
      "output_G 0.18089693784713745 526\n",
      "std_D 0.05328476428985596 526\n",
      "std_G 0.04349089413881302 526\n",
      "[5/1000][162/600][527] Loss_D: 0.182591 Loss_G: 0.178699 \n",
      "output_D 0.18259139358997345 527\n",
      "output_G 0.17869850993156433 527\n",
      "std_D 0.04766815900802612 527\n",
      "std_G 0.0350722000002861 527\n",
      "[5/1000][168/600][528] Loss_D: 0.181946 Loss_G: 0.178533 \n",
      "output_D 0.1819458156824112 528\n",
      "output_G 0.1785333901643753 528\n",
      "std_D 0.04202152043581009 528\n",
      "std_G 0.04074371978640556 528\n",
      "[5/1000][174/600][529] Loss_D: 0.178491 Loss_G: 0.177370 \n",
      "output_D 0.17849120497703552 529\n",
      "output_G 0.17737028002738953 529\n",
      "std_D 0.04107102006673813 529\n",
      "std_G 0.04063862934708595 529\n",
      "[5/1000][180/600][530] Loss_D: 0.176947 Loss_G: 0.180768 \n",
      "output_D 0.17694729566574097 530\n",
      "output_G 0.18076826632022858 530\n",
      "std_D 0.04130168259143829 530\n",
      "std_G 0.04076913371682167 530\n",
      "[5/1000][186/600][531] Loss_D: 0.177589 Loss_G: 0.180040 \n",
      "output_D 0.17758946120738983 531\n",
      "output_G 0.18004046380519867 531\n",
      "std_D 0.039123207330703735 531\n",
      "std_G 0.03694019839167595 531\n",
      "[5/1000][192/600][532] Loss_D: 0.187668 Loss_G: 0.176339 \n",
      "output_D 0.18766827881336212 532\n",
      "output_G 0.17633938789367676 532\n",
      "std_D 0.044021766632795334 532\n",
      "std_G 0.04002922400832176 532\n",
      "[5/1000][198/600][533] Loss_D: 0.184033 Loss_G: 0.172830 \n",
      "output_D 0.18403306603431702 533\n",
      "output_G 0.17283034324645996 533\n",
      "std_D 0.03607575222849846 533\n",
      "std_G 0.03772740066051483 533\n",
      "[5/1000][204/600][534] Loss_D: 0.175545 Loss_G: 0.176525 \n",
      "output_D 0.1755451112985611 534\n",
      "output_G 0.1765252649784088 534\n",
      "std_D 0.03986678645014763 534\n",
      "std_G 0.04298999160528183 534\n",
      "[5/1000][210/600][535] Loss_D: 0.179891 Loss_G: 0.176006 \n",
      "output_D 0.1798906773328781 535\n",
      "output_G 0.17600610852241516 535\n",
      "std_D 0.039632730185985565 535\n",
      "std_G 0.038091693073511124 535\n",
      "[5/1000][216/600][536] Loss_D: 0.178587 Loss_G: 0.176758 \n",
      "output_D 0.17858661711215973 536\n",
      "output_G 0.17675839364528656 536\n",
      "std_D 0.044003818184137344 536\n",
      "std_G 0.039763081818819046 536\n",
      "[5/1000][222/600][537] Loss_D: 0.177696 Loss_G: 0.181770 \n",
      "output_D 0.17769640684127808 537\n",
      "output_G 0.18176960945129395 537\n",
      "std_D 0.04372210428118706 537\n",
      "std_G 0.040818363428115845 537\n",
      "[5/1000][228/600][538] Loss_D: 0.183338 Loss_G: 0.180186 \n",
      "output_D 0.1833384782075882 538\n",
      "output_G 0.18018631637096405 538\n",
      "std_D 0.0426936112344265 538\n",
      "std_G 0.04229225218296051 538\n",
      "[5/1000][234/600][539] Loss_D: 0.170351 Loss_G: 0.175789 \n",
      "output_D 0.1703513264656067 539\n",
      "output_G 0.17578868567943573 539\n",
      "std_D 0.040866248309612274 539\n",
      "std_G 0.0394747331738472 539\n",
      "[5/1000][240/600][540] Loss_D: 0.177922 Loss_G: 0.184517 \n",
      "output_D 0.1779220849275589 540\n",
      "output_G 0.1845165640115738 540\n",
      "std_D 0.03605223074555397 540\n",
      "std_G 0.04145509749650955 540\n",
      "[5/1000][246/600][541] Loss_D: 0.179516 Loss_G: 0.172449 \n",
      "output_D 0.17951630055904388 541\n",
      "output_G 0.1724487543106079 541\n",
      "std_D 0.035590413957834244 541\n",
      "std_G 0.03922338783740997 541\n",
      "[5/1000][252/600][542] Loss_D: 0.183547 Loss_G: 0.179553 \n",
      "output_D 0.18354660272598267 542\n",
      "output_G 0.17955335974693298 542\n",
      "std_D 0.043534815311431885 542\n",
      "std_G 0.04253489151597023 542\n",
      "[5/1000][258/600][543] Loss_D: 0.177818 Loss_G: 0.177126 \n",
      "output_D 0.17781810462474823 543\n",
      "output_G 0.1771257370710373 543\n",
      "std_D 0.04588012397289276 543\n",
      "std_G 0.040770046412944794 543\n",
      "[5/1000][264/600][544] Loss_D: 0.170973 Loss_G: 0.174425 \n",
      "output_D 0.17097297310829163 544\n",
      "output_G 0.17442499101161957 544\n",
      "std_D 0.04055139049887657 544\n",
      "std_G 0.04299718886613846 544\n",
      "[5/1000][270/600][545] Loss_D: 0.186877 Loss_G: 0.177465 \n",
      "output_D 0.1868770569562912 545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_G 0.17746523022651672 545\n",
      "std_D 0.03957499563694 545\n",
      "std_G 0.042010869830846786 545\n",
      "[5/1000][276/600][546] Loss_D: 0.182322 Loss_G: 0.172839 \n",
      "output_D 0.18232229351997375 546\n",
      "output_G 0.17283882200717926 546\n",
      "std_D 0.03643493726849556 546\n",
      "std_G 0.0354100726544857 546\n",
      "[5/1000][282/600][547] Loss_D: 0.177086 Loss_G: 0.175650 \n",
      "output_D 0.17708562314510345 547\n",
      "output_G 0.17564977705478668 547\n",
      "std_D 0.0424775667488575 547\n",
      "std_G 0.036517538130283356 547\n",
      "[5/1000][288/600][548] Loss_D: 0.180064 Loss_G: 0.182260 \n",
      "output_D 0.18006354570388794 548\n",
      "output_G 0.18225990235805511 548\n",
      "std_D 0.03876768425107002 548\n",
      "std_G 0.039693839848041534 548\n",
      "[5/1000][294/600][549] Loss_D: 0.177987 Loss_G: 0.180113 \n",
      "output_D 0.17798738181591034 549\n",
      "output_G 0.18011263012886047 549\n",
      "std_D 0.0355948880314827 549\n",
      "std_G 0.044119689613580704 549\n",
      "[5/1000][300/600][550] Loss_D: 0.175566 Loss_G: 0.173739 \n",
      "output_D 0.17556621134281158 550\n",
      "output_G 0.1737392693758011 550\n",
      "std_D 0.0411028116941452 550\n",
      "std_G 0.045939646661281586 550\n",
      "[5/1000][306/600][551] Loss_D: 0.180786 Loss_G: 0.174535 \n",
      "output_D 0.18078584969043732 551\n",
      "output_G 0.17453472316265106 551\n",
      "std_D 0.03649072349071503 551\n",
      "std_G 0.04194127768278122 551\n",
      "[5/1000][312/600][552] Loss_D: 0.181668 Loss_G: 0.183672 \n",
      "output_D 0.1816677302122116 552\n",
      "output_G 0.1836717426776886 552\n",
      "std_D 0.03377947211265564 552\n",
      "std_G 0.0430353507399559 552\n",
      "[5/1000][318/600][553] Loss_D: 0.177135 Loss_G: 0.180234 \n",
      "output_D 0.17713458836078644 553\n",
      "output_G 0.18023371696472168 553\n",
      "std_D 0.04100111871957779 553\n",
      "std_G 0.03740112856030464 553\n",
      "[5/1000][324/600][554] Loss_D: 0.177690 Loss_G: 0.175586 \n",
      "output_D 0.17768950760364532 554\n",
      "output_G 0.17558647692203522 554\n",
      "std_D 0.04323532432317734 554\n",
      "std_G 0.04048449546098709 554\n",
      "[5/1000][330/600][555] Loss_D: 0.173054 Loss_G: 0.174417 \n",
      "output_D 0.17305436730384827 555\n",
      "output_G 0.1744166910648346 555\n",
      "std_D 0.03382788971066475 555\n",
      "std_G 0.03854455053806305 555\n",
      "[5/1000][336/600][556] Loss_D: 0.179040 Loss_G: 0.175445 \n",
      "output_D 0.17904023826122284 556\n",
      "output_G 0.17544496059417725 556\n",
      "std_D 0.03729536011815071 556\n",
      "std_G 0.03996512293815613 556\n",
      "[5/1000][342/600][557] Loss_D: 0.176491 Loss_G: 0.183509 \n",
      "output_D 0.1764909029006958 557\n",
      "output_G 0.18350949883460999 557\n",
      "std_D 0.034962914884090424 557\n",
      "std_G 0.03964255005121231 557\n",
      "[5/1000][348/600][558] Loss_D: 0.181941 Loss_G: 0.180694 \n",
      "output_D 0.1819409281015396 558\n",
      "output_G 0.18069428205490112 558\n",
      "std_D 0.038944926112890244 558\n",
      "std_G 0.0453050322830677 558\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gen_iterations = 0\n",
    "for epoch in range(epochs):\n",
    "    data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < len(data_loader):\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter and i < len(data_loader):\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "            X, _ = data_iter.next()\n",
    "            X = X.view(X.size(0), -1)\n",
    "            X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real)\n",
    "#             print('fake', fake[:,0].sum())\n",
    "            out = netD(real, fake)\n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter and i < len(data_loader):\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X, _ = data_iter.next()\n",
    "            X = X.view(X.size(0), -1)\n",
    "            X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "            print('output_D', outputD.item(), gen_iterations)\n",
    "            print('output_G', outputG.item(), gen_iterations)\n",
    "            print('std_D', stdD.item(), gen_iterations)\n",
    "            print('std_G', stdG.item(), gen_iterations)\n",
    "\n",
    "    #         print(gen_iterations)\n",
    "            if gen_iterations % 100 == 0:\n",
    "                if not isdir('./images/{0}'.format(name)):\n",
    "                    os.makedirs('./images/{0}'.format(name))\n",
    "                real = real.data[0:100,:]\n",
    "                real = real.view(real.size(0), 1, 28, 28)\n",
    "                vutils.save_image(real, './images/{0}/real_samples.png'.format(name, gen_iterations))\n",
    "                noise = torch.randn(min(100, batch_size), nz)\n",
    "                if cuda: \n",
    "                    noise = noise.cuda()\n",
    "                fake = netG(Variable(noise, volatile=True))\n",
    "#                 print('real', real)\n",
    "#                 print('fake', fake)\n",
    "                # fake = (fake.data >= 0.5).float()\n",
    "                R = torch.rand(fake.size())\n",
    "                fake = (fake.data.cpu() >= R).float()\n",
    "                fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "                vutils.save_image(fake, './images/{0}/fake_samples_{1}.png'.format(name, gen_iterations))\n",
    "    # do checkpointing\n",
    "#     if not isdir('./checkpoint/{0}'.format(name)):\n",
    "#         os.makedirs('./checkpoint/{0}'.format(name))\n",
    "    torch.save(netG.state_dict(), './checkpoint/{0}/netG_epoch_{1}.pth'.format(name, epoch))\n",
    "    torch.save(netD.state_dict(), './checkpoint/{0}/netD_epoch_{1}.pth'.format(name, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Невозможно создать файл, так как он уже существует: './checkpoint/mnist-experiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-d5360f21a85d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./checkpoint/{0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Невозможно создать файл, так как он уже существует: './checkpoint/mnist-experiment'"
     ]
    }
   ],
   "source": [
    "os.makedirs('./checkpoint/{0}'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gen_iterations = 0\n",
    "# for epoch in range(epochs):\n",
    "# #     data_iter = iter(data_loader)\n",
    "#     i = 0\n",
    "#     while i < 10:\n",
    "#         ############################\n",
    "#         # (1) Update D network\n",
    "#         ###########################\n",
    "#         for p in netD.parameters(): # reset requires_grad\n",
    "#             p.requires_grad = True # they are set to False below in netG update\n",
    "#         d_iter = d_iter\n",
    "#         j = 0\n",
    "#         while j < d_iter and i < 10:\n",
    "#             j += 1\n",
    "#             # load real data\n",
    "#             i += 1\n",
    "#             X = getRealSample()\n",
    "#             X = X.view(X.size(0), -1).float()\n",
    "# #             X = (X >= 0.5).float()\n",
    "#             if cuda: \n",
    "#                 X = X.cuda()\n",
    "#             real = Variable(X, requires_grad=True)\n",
    "#             # generate fake data\n",
    "#             noise = torch.randn(batch_size, nz)\n",
    "#             if cuda: \n",
    "#                 noise = noise.cuda()\n",
    "#             with torch.no_grad():\n",
    "#                 noisev = Variable(noise) # totally freeze netG\n",
    "#             fake = (Variable(netG(noisev).data, requires_grad=True) > 0.5).float()\n",
    "#             # compute gradient, take step\n",
    "#             netD.zero_grad()\n",
    "#             print(real, fake)\n",
    "#             out = netD(real, fake)\n",
    "# #             print(real.shape, fake.shape, out.shape)\n",
    "#             outputD = torch.mean(out) + lamba * out.norm()\n",
    "#             stdD = torch.std(out)\n",
    "# #             print('outputD.shape', outputD)\n",
    "#             outputD.backward(mone)\n",
    "#             optimizerD.step()\n",
    "# #             break\n",
    "# #         break\n",
    "# #     break\n",
    "\n",
    "#             g_iter = g_iter\n",
    "#             j = 0\n",
    "#             while j < g_iter and i < 10:\n",
    "#                 j += 1\n",
    "#                 for p in netD.parameters():\n",
    "#                     p.requires_grad = False # to avoid computation\n",
    "#                 netG.zero_grad()\n",
    "#                 # load real data\n",
    "#                 i += 1\n",
    "#                 X = getRealSample()\n",
    "#                 X = X.view(X.size(0), -1)\n",
    "# #                 X = (X >= 0.5).float()\n",
    "#                 if cuda: \n",
    "#                     X = X.cuda()\n",
    "#                 real = Variable(X.float(), requires_grad=True)\n",
    "#                 # update generator\n",
    "#                 noise = torch.randn(batch_size, nz)\n",
    "#                 if cuda: \n",
    "#                     noise = noise.cuda()\n",
    "#                 noisev = Variable(noise)\n",
    "#                 fake = Variable((netG(noisev) >=0.5).float(), requires_grad=True)\n",
    "#                 print(\"####\"*40)\n",
    "#                 print('REEEEAL', real)\n",
    "#                 print('FAAAKE', fake)\n",
    "#                 print(\"####\"*40)\n",
    "# #                 print(real.shape, fake.shape)\n",
    "#                 out = netD(real, fake)\n",
    "#                 outputG = torch.mean(out) + lamba * out.norm()\n",
    "#                 stdG = torch.std(out)\n",
    "#                 outputG.backward(one)\n",
    "#                 optimizerG.step()\n",
    "#                 gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f ' % (epoch, epochs, i, 10, gen_iterations, outputD.data.item(), outputG.data.item()))\n",
    "#             print('output_D', outputD.data.item(), gen_iterations)\n",
    "#             print('output_G', outputG.data.item(), gen_iterations)\n",
    "#             print('std_D', stdD.data.item(), gen_iterations)\n",
    "#             print('std_G', stdG.data.item(), gen_iterations)\n",
    "# #             if gen_iterations % 100 == 0:\n",
    "# #                 if not isdir('./images/{0}'.format(name)):\n",
    "# #                     os.mkdir('./images/{0}'.format(name))\n",
    "# #                 real = real.data[0:100,:]\n",
    "# #                 real = real.view(real.size(0), 1, 28, 28)\n",
    "# #                 vutils.save_image(real, './images/{0}/real_samples.png'.format(name, gen_iterations))\n",
    "# #                 noise = torch.randn(min(100, batch_size), nz)\n",
    "# #                 if cuda: \n",
    "# #                     noise = noise.cuda()\n",
    "# #                 fake = netG(Variable(noise, volatile=True))\n",
    "# #                 # fake = (fake.data >= 0.5).float()\n",
    "# #                 R = torch.rand(fake.size())\n",
    "# #                 fake = (fake.data.cpu() >= R).float()\n",
    "# #                 fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "# #                 vutils.save_image(fake, './images/{0}/fake_samples_{1}.png'.format(name, gen_iterations))\n",
    "\n",
    "# #             # do checkpointing\n",
    "# #             if not isdir('./checkpoint/{0}'.format(name)):\n",
    "# #                 os.mkdir('./checkpoint/{0}'.format(name))\n",
    "# #             torch.save(netG.state_dict(), './checkpoint/{0}/netG_epoch_{1}.pth'.format(name, epoch))\n",
    "# #             torch.save(netD.state_dict(), './checkpoint/{0}/netD_epoch_{1}.pth'.format(name, epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
