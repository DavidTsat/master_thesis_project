{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in c:\\users\\david\\anaconda3\\lib\\site-packages (0.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from matrix_factorization.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter \n",
    "import matrix_factorization\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 5778k    0 21621    0     0  22220      0  0:04:26 --:--:--  0:04:26 22220\n",
      " 18 5778k   18 1077k    0     0   509k      0  0:00:11  0:00:02  0:00:09  509k\n",
      " 46 5778k   46 2673k    0     0   911k      0  0:00:06  0:00:02  0:00:04  911k\n",
      " 80 5778k   80 4647k    0     0  1192k      0  0:00:04  0:00:03  0:00:01 1192k\n",
      "100 5778k  100 5778k    0     0  1316k      0  0:00:04  0:00:04 --:--:-- 1316k\n",
      "\"unzip\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "‘ЁбвҐ¬Ґ ­Ґ г¤ Ґвбп ­ ©вЁ гЄ § ­­л© Їгвм.\n"
     ]
    }
   ],
   "source": [
    "# # Downloading Movielens-1m\n",
    "# !curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "# !unzip ml-1m.zip\n",
    "# !cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_list = [i.strip().split(\"::\") for i in open('./ml-1m/ratings.dat', 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open('./ml-1m/users.dat', 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open('./ml-1m/movies.dat', 'r').readlines()]\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1 10 100 1000 1002 1003 1004 1005 1006 1007  ... 99 990 991 992 993  \\\n",
       "UserID                                                ...                      \n",
       "1        5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "10       5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "100      0  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1000     5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1001     4  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "\n",
       "MovieID 994 996 997 998 999  \n",
       "UserID                       \n",
       "1         0   0   0   0   0  \n",
       "10        0   0   0   0   0  \n",
       "100       0   0   0   0   0  \n",
       "1000      0   0   0   0   0  \n",
       "1001      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "R_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(R_df.values, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users = df.user_id.unique().shape[0]\n",
    "# n_items = df.item_id.unique().shape[0]\n",
    "# ratings = np.zeros((n_users, n_items))\n",
    "# for row in df.itertuples():\n",
    "#     ratings[row[1]-1, row[2]-1] = row[3]\n",
    "# ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(R_df.values, dtype=int)\n",
    "n_users = ratings.shape[0]\n",
    "n_items = ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    print (str(n_users) + ' users')\n",
    "    print (str(n_items) + ' items')\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n",
      "Sparsity: 4.47%\n"
     ]
    }
   ],
   "source": [
    "print ('Sparsity: {:4.2f}%'.format(get_sparsity(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=20, replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    \n",
    "#     print(test)\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.9286971547839014"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5396654074473827"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.8264795643096374\n",
      "Test mse: 0.9051574489352089\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####################################### GANS ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise(batch_size):\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4891, 0.0480, 0.4328, 0.5273, 0.2739, 0.1254, 0.6244, 0.2886, 0.5066,\n",
       "         0.4386, 0.7570, 0.3903, 0.5721, 0.7924, 0.9148, 0.4773, 0.6147, 0.7759,\n",
       "         0.6119, 0.5610, 0.2065, 0.2106, 0.9634, 0.4180, 0.5345, 0.2175, 0.2276,\n",
       "         0.4741, 0.1934, 0.5994, 0.2499, 0.5632, 0.5812, 0.4502, 0.3586, 0.1817,\n",
       "         0.6220, 0.9690, 0.7638, 0.2439, 0.7871, 0.4661, 0.5860, 0.9622, 0.8094,\n",
       "         0.0068, 0.5864, 0.3436, 0.7492, 0.6887, 0.4608, 0.8557, 0.4435, 0.8783,\n",
       "         0.8425, 0.1054, 0.6342, 0.7254, 0.6636, 0.9609, 0.7821, 0.4482, 0.8318,\n",
       "         0.2091, 0.3771, 0.5064, 0.3089, 0.4505, 0.0976, 0.6955, 0.5214, 0.6317,\n",
       "         0.9549, 0.9568, 0.1392, 0.5199, 0.9159, 0.8548, 0.0679, 0.6710, 0.7768,\n",
       "         0.1556, 0.1837, 0.8537, 0.0647, 0.5919, 0.7968, 0.5959, 0.5825, 0.3339,\n",
       "         0.4790, 0.0257, 0.9455, 0.1554, 0.7733, 0.1021, 0.5377, 0.4398, 0.0525,\n",
       "         0.2579],\n",
       "        [0.4281, 0.5136, 0.8456, 0.9292, 0.9391, 0.2389, 0.9294, 0.7106, 0.9308,\n",
       "         0.6865, 0.4579, 0.4508, 0.1919, 0.1435, 0.3691, 0.3437, 0.1066, 0.3580,\n",
       "         0.2208, 0.4503, 0.8098, 0.0037, 0.7170, 0.8537, 0.2381, 0.7997, 0.6771,\n",
       "         0.5730, 0.7136, 0.0601, 0.9589, 0.8410, 0.1881, 0.5080, 0.9487, 0.7992,\n",
       "         0.9770, 0.1549, 0.2268, 0.5908, 0.8174, 0.7709, 0.8785, 0.3403, 0.1541,\n",
       "         0.2507, 0.1947, 0.1867, 0.0631, 0.5066, 0.5280, 0.2648, 0.5779, 0.7277,\n",
       "         0.6906, 0.0332, 0.2546, 0.3650, 0.6630, 0.1034, 0.2618, 0.7200, 0.0814,\n",
       "         0.4630, 0.0637, 0.3460, 0.3736, 0.5539, 0.9596, 0.7742, 0.6555, 0.9046,\n",
       "         0.3218, 0.4907, 0.3033, 0.1505, 0.1986, 0.6794, 0.1266, 0.3281, 0.0710,\n",
       "         0.7526, 0.3505, 0.2787, 0.2887, 0.3150, 0.1393, 0.3881, 0.3465, 0.6074,\n",
       "         0.4140, 0.3225, 0.8183, 0.9510, 0.1005, 0.3068, 0.8995, 0.5312, 0.9878,\n",
       "         0.3146],\n",
       "        [0.2089, 0.4573, 0.1757, 0.9282, 0.0599, 0.3659, 0.0765, 0.2416, 0.7945,\n",
       "         0.6911, 0.9012, 0.1353, 0.3581, 0.5988, 0.7102, 0.2075, 0.4768, 0.8888,\n",
       "         0.6946, 0.2749, 0.9901, 0.1315, 0.0421, 0.9275, 0.4415, 0.5226, 0.7741,\n",
       "         0.2958, 0.8511, 0.5449, 0.1016, 0.9740, 0.8527, 0.6974, 0.5873, 0.8519,\n",
       "         0.8447, 0.4741, 0.3348, 0.4769, 0.5474, 0.2011, 0.9643, 0.2547, 0.0579,\n",
       "         0.0075, 0.4437, 0.6142, 0.5347, 0.3944, 0.4643, 0.7953, 0.9161, 0.8028,\n",
       "         0.1881, 0.4184, 0.3995, 0.6607, 0.3232, 0.1333, 0.5600, 0.2140, 0.0729,\n",
       "         0.4927, 0.7465, 0.1822, 0.3706, 0.7261, 0.1022, 0.2025, 0.5405, 0.4577,\n",
       "         0.8611, 0.3068, 0.3282, 0.0632, 0.3103, 0.9604, 0.0860, 0.2970, 0.6147,\n",
       "         0.7913, 0.0350, 0.8667, 0.1118, 0.3584, 0.7046, 0.6515, 0.5568, 0.4609,\n",
       "         0.6155, 0.3755, 0.4789, 0.4520, 0.8015, 0.6142, 0.7431, 0.5426, 0.4410,\n",
       "         0.1625],\n",
       "        [0.8244, 0.2094, 0.6966, 0.8752, 0.4029, 0.0281, 0.9981, 0.3214, 0.7341,\n",
       "         0.8028, 0.6649, 0.0318, 0.2730, 0.4204, 0.9330, 0.1081, 0.5387, 0.4771,\n",
       "         0.4961, 0.0473, 0.8781, 0.4584, 0.2020, 0.0194, 0.9706, 0.0676, 0.8043,\n",
       "         0.8591, 0.4995, 0.0186, 0.1282, 0.3850, 0.4974, 0.5504, 0.6138, 0.2818,\n",
       "         0.9867, 0.8253, 0.8439, 0.8305, 0.1676, 0.7028, 0.7696, 0.2786, 0.7750,\n",
       "         0.4888, 0.4153, 0.1619, 0.2174, 0.7166, 0.1652, 0.3772, 0.1728, 0.2340,\n",
       "         0.8633, 0.5760, 0.8823, 0.9117, 0.3275, 0.1335, 0.0164, 0.3312, 0.7884,\n",
       "         0.0699, 0.6538, 0.7473, 0.9310, 0.8739, 0.4366, 0.9983, 0.3773, 0.9447,\n",
       "         0.3127, 0.8932, 0.7282, 0.7927, 0.4612, 0.3162, 0.2912, 0.5490, 0.1144,\n",
       "         0.8446, 0.0398, 0.6361, 0.8155, 0.0490, 0.4093, 0.2305, 0.2291, 0.2538,\n",
       "         0.5133, 0.4654, 0.7980, 0.9869, 0.3154, 0.9132, 0.9423, 0.0147, 0.6589,\n",
       "         0.0937],\n",
       "        [0.7295, 0.1498, 0.7034, 0.1917, 0.7334, 0.6287, 0.8070, 0.1003, 0.0715,\n",
       "         0.3938, 0.2762, 0.0600, 0.2389, 0.7394, 0.0214, 0.6612, 0.6545, 0.6763,\n",
       "         0.4432, 0.5924, 0.9913, 0.2064, 0.6202, 0.1155, 0.8597, 0.5710, 0.3217,\n",
       "         0.6981, 0.1924, 0.7217, 0.7097, 0.1487, 0.4583, 0.1837, 0.7068, 0.8853,\n",
       "         0.4168, 0.3081, 0.8213, 0.2464, 0.9859, 0.3036, 0.3032, 0.8624, 0.0704,\n",
       "         0.9640, 0.4086, 0.8067, 0.5172, 0.1509, 0.8336, 0.9428, 0.0160, 0.9428,\n",
       "         0.6512, 0.6924, 0.2367, 0.2650, 0.9632, 0.1971, 0.9130, 0.9903, 0.7353,\n",
       "         0.7164, 0.7403, 0.7214, 0.7499, 0.8812, 0.9223, 0.4551, 0.8455, 0.9535,\n",
       "         0.9504, 0.4936, 0.6099, 0.0111, 0.6655, 0.1191, 0.7465, 0.8884, 0.4572,\n",
       "         0.4575, 0.4640, 0.7506, 0.9249, 0.9947, 0.0098, 0.7303, 0.8533, 0.3584,\n",
       "         0.7772, 0.4637, 0.7058, 0.1596, 0.3281, 0.6551, 0.1469, 0.6521, 0.9039,\n",
       "         0.2854]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_some_noise(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator class\n",
    "\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(800,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining discriminator class\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(200,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(ratings.shape[1], 1)\n",
    "gen = generator(100, ratings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=3706, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=1000, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=800, out_features=3706, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps = 300\n",
    "g_steps = 300\n",
    "\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# printing_steps = 200\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]\n",
    "    \n",
    "get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1. MSE distance between random real and fake samples 2893811.75\n",
      "Epoch number 2. MSE distance between random real and fake samples 2904193.25\n",
      "Epoch number 3. MSE distance between random real and fake samples 2883128.25\n",
      "Epoch number 4. MSE distance between random real and fake samples 2872851.0\n",
      "Epoch number 5. MSE distance between random real and fake samples 2825715.0\n",
      "Epoch number 6. MSE distance between random real and fake samples 2770513.25\n",
      "Epoch number 7. MSE distance between random real and fake samples 2773615.0\n",
      "Epoch number 8. MSE distance between random real and fake samples 2653903.75\n",
      "Epoch number 9. MSE distance between random real and fake samples 2446864.25\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "eval_losses = []\n",
    "for epoch in range(10):\n",
    "#     print (epoch)\n",
    "\n",
    "    # training discriminator\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()\n",
    "        \n",
    "        # training discriminator on real data\n",
    "        real_rows = get_random_batch(train, batch_size)\n",
    "        discriminator_real_outputs = dis(real_rows)\n",
    "   \n",
    "        dis_real_loss = criteriond1(discriminator_real_outputs, Variable(torch.ones(batch_size,1)))\n",
    "    \n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # training discriminator on data produced by generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        #output from generator is generated        \n",
    "        fake_rows = gen(z_vector).detach()\n",
    "#         print(fake_rows[:20])\n",
    "        dis_fake_out = dis(fake_rows)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out, Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()\n",
    "        \n",
    "    # training generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()\n",
    "        \n",
    "        #generating data for input for generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        \n",
    "        fake_rows = gen(z_vector)\n",
    "#         print(fake_rows.shape, z_vector.shape)\n",
    "#         print(fake_rows[:20])\n",
    "        dis_out_gen_training = dis(fake_rows)\n",
    "        gen_loss = criteriond2(dis_out_gen_training, Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()\n",
    "\n",
    "    # evaluation\n",
    "    if epoch % 10: # todo- to change\n",
    "        gen.eval()\n",
    "        z_vector_eval = make_some_noise(128)\n",
    "        fake_rows_eval = gen(z_vector_eval)\n",
    "        real_rows_eval = get_random_batch(train, 128)\n",
    "#         print(fake_rows[0][:10]) enable to see some results\n",
    "        eval_loss = F.mse_loss(fake_rows_eval, real_rows_eval, reduction='sum')\n",
    "        eval_losses.append(eval_loss)\n",
    "        print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "#         print('Epoch number {}. L1 distance between random real and fake samples {}'.format(epoch, torch.sum(torch.abs(fake_rows_eval - real_rows_eval))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vector = make_some_noise(16)\n",
    "fake_rows = gen(z_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.6511, 4.2755, 2.7115, 0.7549, 1.8516, 0.6033, 0.6420, 1.6807, 3.6191],\n",
       "        [4.6528, 4.2870, 2.7053, 0.7457, 1.8506, 0.5937, 0.6369, 1.6598, 3.6164],\n",
       "        [4.6545, 4.2763, 2.7013, 0.7442, 1.8631, 0.6002, 0.6373, 1.6572, 3.6064],\n",
       "        [4.6484, 4.2832, 2.6962, 0.7472, 1.8718, 0.5926, 0.6345, 1.6791, 3.6103],\n",
       "        [4.6478, 4.2756, 2.7035, 0.7621, 1.8524, 0.6144, 0.6445, 1.6834, 3.6022],\n",
       "        [4.6547, 4.2902, 2.7132, 0.7494, 1.8627, 0.6001, 0.6414, 1.6638, 3.6042],\n",
       "        [4.6526, 4.2719, 2.6932, 0.7530, 1.8585, 0.5987, 0.6402, 1.6524, 3.5992],\n",
       "        [4.6449, 4.2646, 2.6821, 0.7780, 1.8683, 0.6082, 0.6467, 1.6726, 3.6014],\n",
       "        [4.6538, 4.2756, 2.6974, 0.7569, 1.8696, 0.5970, 0.6503, 1.6632, 3.5958],\n",
       "        [4.6538, 4.2808, 2.6982, 0.7612, 1.8632, 0.5965, 0.6382, 1.6535, 3.5909],\n",
       "        [4.6539, 4.2770, 2.7092, 0.7517, 1.8648, 0.6000, 0.6444, 1.6683, 3.5927],\n",
       "        [4.6489, 4.2609, 2.6964, 0.7596, 1.8547, 0.6096, 0.6439, 1.6800, 3.6145],\n",
       "        [4.6543, 4.2821, 2.6910, 0.7535, 1.8480, 0.5953, 0.6365, 1.6641, 3.6135],\n",
       "        [4.6580, 4.2936, 2.7277, 0.7377, 1.8571, 0.5919, 0.6288, 1.6612, 3.6152],\n",
       "        [4.6525, 4.2802, 2.6994, 0.7568, 1.8569, 0.6016, 0.6398, 1.6594, 3.5954],\n",
       "        [4.6499, 4.2789, 2.6991, 0.7475, 1.8595, 0.5978, 0.6409, 1.6560, 3.6050]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we see generator produces very similar vectors \n",
    "fake_rows[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os\n",
    "# from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrD = 5e-4\n",
    "# lrG = 5e-4\n",
    "# batch_size = 100\n",
    "# cuda = True\n",
    "# epochs = 1000\n",
    "# device = 5\n",
    "# seed = 42\n",
    "# nz = 100\n",
    "# d_iter = 5\n",
    "# g_iter = 1\n",
    "# lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "# name = \"mnist-experiment\"\n",
    "# # configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "# torch.manual_seed(seed)\n",
    "# # if cuda:\n",
    "# # #     torch.cuda.set_device('cuda')\n",
    "# #     torch.cuda.manual_seed(seed)\n",
    "# # data_loader = torch.utils.data.DataLoader(\n",
    "# # datasets.MNIST('../data', train=True, download=True,\n",
    "# # transform=transforms.Compose([transforms.ToTensor(),])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 100\n",
    "cuda = True\n",
    "epochs = 60 #change\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "name = \"mnist-experiment\"\n",
    "# configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length=6\n",
    "# batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(features_length, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(features_length, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, features_length)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "        x = filt * x\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, features_length),\n",
    "#     torch.nn.Sigmoid()*5\n",
    "#     )\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(nz,1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024,features_length),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]\n",
    "    \n",
    "# networks\n",
    "netD = NetD(use_cuda=False)\n",
    "netG = NetG()\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "cuda = False\n",
    "if cuda is True:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(length=6):\n",
    "     return Variable(torch.IntTensor(np.random.choice([0, 1], size=(batch_size, length))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3706])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_batch(train, batch_size=batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 5. MSE distance between random real and fake samples 0.7038925290107727\n",
      "Epoch number 11. MSE distance between random real and fake samples 0.7613562345504761\n",
      "Epoch number 17. MSE distance between random real and fake samples 0.6658684611320496\n",
      "Epoch number 23. MSE distance between random real and fake samples 0.5122649669647217\n",
      "Epoch number 29. MSE distance between random real and fake samples 0.5298185348510742\n",
      "Epoch number 35. MSE distance between random real and fake samples 0.4854387640953064\n",
      "Epoch number 41. MSE distance between random real and fake samples 0.6897281408309937\n",
      "Epoch number 47. MSE distance between random real and fake samples 0.6259452700614929\n",
      "Epoch number 52. MSE distance between random real and fake samples 0.5456494688987732\n",
      "Epoch number 58. MSE distance between random real and fake samples 0.5298698544502258\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "gen_iterations = 0\n",
    "eval_losses = []\n",
    "for epoch in range(epochs):\n",
    "#     data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < steps_per_epoch:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter and i < len(data_loader):\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "#             X, _ = data_iter.next()\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             print(X >= 0.5)\n",
    "# #             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "#             print(real.shape, fake.shape)\n",
    "    \n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real)\n",
    "#             print('fake', fake[:,0].sum())\n",
    "            out = netD(real, fake)\n",
    "            \n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "#             print(out.shape)\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter and i < len(data_loader):\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "#             print('output_D', outputD.item(), gen_iterations)\n",
    "#             print('output_G', outputG.item(), gen_iterations)\n",
    "#             print('std_D', stdD.item(), gen_iterations)\n",
    "#             print('std_G', stdG.item(), gen_iterations)\n",
    "            \n",
    "            # evaluation\n",
    "            if gen_iterations % 100 == 0: # todo- to change\n",
    "#                 gen.eval()\n",
    "#                 z_vector_eval = make_some_noise(128)\n",
    "#                 fake_rows_eval = gen(z_vector_eval)\n",
    "#                 real_rows_eval = get_random_batch(train, 128)\n",
    "        #         print(fake_rows[0][:10]) enable to see some results\n",
    "                eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "                eval_losses.append(eval_loss)\n",
    "                print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "\n",
    "#     #         print(gen_iterations)\n",
    "#             if gen_iterations % 100 == 0:\n",
    "#                 if not isdir('./images/{0}'.format(name)):\n",
    "#                     os.makedirs('./images/{0}'.format(name))\n",
    "#                 real = real.data[0:100,:]\n",
    "#                 real = real.view(real.size(0), 1, 28, 28)\n",
    "#                 vutils.save_image(real, './images/{0}/real_samples.png'.format(name, gen_iterations))\n",
    "#                 noise = torch.randn(min(100, batch_size), nz)\n",
    "#                 if cuda: \n",
    "#                     noise = noise.cuda()\n",
    "#                 fake = netG(Variable(noise, volatile=True))\n",
    "# #                 print('real', real)\n",
    "# #                 print('fake', fake)\n",
    "#                 # fake = (fake.data >= 0.5).float()\n",
    "#                 R = torch.rand(fake.size())\n",
    "#                 fake = (fake.data.cpu() >= R).float()\n",
    "#                 fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "#                 vutils.save_image(fake, './images/{0}/fake_samples_{1}.png'.format(name, gen_iterations))\n",
    "#     # do checkpointing\n",
    "# #     if not isdir('./checkpoint/{0}'.format(name)):\n",
    "# #         os.makedirs('./checkpoint/{0}'.format(name))\n",
    "#     torch.save(netG.state_dict(), './checkpoint/{0}/netG_epoch_{1}.pth'.format(name, epoch))\n",
    "#     torch.save(netD.state_dict(), './checkpoint/{0}/netD_epoch_{1}.pth'.format(name, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, nz)\n",
    "if cuda: \n",
    "    noise = noise.cuda()\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(359863)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(170)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(638)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1153)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1924)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6852)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226310"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348971"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_row(n=10):\n",
    "    elements = [0, 1, 2, 3, 4, 5]\n",
    "    probabilities = [0.5, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "    return np.random.choice(elements, 10, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 5, 0, 0, 2, 0, 0, 5])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_row(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_dwgan(x_r, x_g):\n",
    "    return sum(x_r != x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g, alpha=1, normalize=True):\n",
    "    n = x_r.shape[0]\n",
    "    sum_ = 0.\n",
    "    for i in (range(x_r.shape[0])):\n",
    "#         print(x_r[i], x_g[i])\n",
    "        if x_r[i] == x_g[i] == 0:\n",
    "#             print(x_r[i], x_g[i])\n",
    "            sum_ += alpha\n",
    "        elif x_r[i] != 0 and x_g[i] != 0 and x_r[i] != x_g[i]:\n",
    "            sum_ += abs(x_r[i] - x_g[i])\n",
    "    if normalize:\n",
    "        return sum_/n\n",
    "    return sum_\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g, alpha=1, normalize=True):\n",
    "    sum_ = 0.\n",
    "    n = 0\n",
    "    for i in (range(x_r.shape[0])):\n",
    "#         print(x_r[i], x_g[i])\n",
    "        if x_r[i] == x_g[i] == 0:\n",
    "#             print(x_r[i], x_g[i])\n",
    "            sum_ += alpha\n",
    "        elif x_r[i] != 0 and x_g[i] != 0 and x_r[i] != x_g[i]:\n",
    "            n += 1\n",
    "            sum_ += abs(x_r[i] - x_g[i])\n",
    "    if normalize:\n",
    "        return sum_/n\n",
    "    return sum_\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_1 = np.array([0, 0, 3, 0, 4, 0, 0, 0, 0, 0])\n",
    "\n",
    "x_r_2 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_2 = np.array([0, 5, 3, 0, 4, 4, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0]), array([0, 0, 3, 0, 4, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r_1, x_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0]), array([0, 5, 3, 0, 4, 4, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r_2, x_g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dwgan(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dwgan(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_my(x_r_1, x_g_1, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_my(x_r_2, x_g_2, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x real [0 0 0 0 0 0 3 1 4 0]\n",
      "x gen  [0 0 5 2 0 1 0 4 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_r = random_row(n=10)\n",
    "x_g = random_row(n=10)\n",
    "\n",
    "print('x real', x_r)\n",
    "print('x gen ', x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dwgan(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_my(x_r, x_g, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
