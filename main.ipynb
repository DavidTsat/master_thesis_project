{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from matrix_factorization.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter \n",
    "import matrix_factorization\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  1 5778k    1  106k    0     0   123k      0  0:00:46 --:--:--  0:00:46  123k\n",
      " 41 5778k   41 2424k    0     0  1283k      0  0:00:04  0:00:01  0:00:03 1283k\n",
      " 90 5778k   90 5200k    0     0  1895k      0  0:00:03  0:00:02  0:00:01 1895k\n",
      "100 5778k  100 5778k    0     0  1982k      0  0:00:02  0:00:02 --:--:-- 1982k\n"
     ]
    }
   ],
   "source": [
    "# Downloading Movielens-1m\n",
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip ml-1m.zip\n",
    "!cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_list = [i.strip().split(\"::\") for i in open('./ml-1m/ratings.dat', 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open('./ml-1m/users.dat', 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open('./ml-1m/movies.dat', 'r').readlines()]\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1 10 100 1000 1002 1003 1004 1005 1006 1007  ... 99 990 991 992 993  \\\n",
       "UserID                                                ...                      \n",
       "1        5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "10       5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "100      0  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1000     5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1001     4  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "\n",
       "MovieID 994 996 997 998 999  \n",
       "UserID                       \n",
       "1         0   0   0   0   0  \n",
       "10        0   0   0   0   0  \n",
       "100       0   0   0   0   0  \n",
       "1000      0   0   0   0   0  \n",
       "1001      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "R_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(R_df.values, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users = df.user_id.unique().shape[0]\n",
    "# n_items = df.item_id.unique().shape[0]\n",
    "# ratings = np.zeros((n_users, n_items))\n",
    "# for row in df.itertuples():\n",
    "#     ratings[row[1]-1, row[2]-1] = row[3]\n",
    "# ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(R_df.values, dtype=int)\n",
    "n_users = ratings.shape[0]\n",
    "n_items = ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    print (str(n_users) + ' users')\n",
    "    print (str(n_items) + ' items')\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n",
      "Sparsity: 4.47%\n"
     ]
    }
   ],
   "source": [
    "print ('Sparsity: {:4.2f}%'.format(get_sparsity(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int (ratings[0, :].nonzero()[0].shape[0]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=int(ratings[user, :].nonzero()[0].shape[0]/2), replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    \n",
    "#     print(test)\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2407997769859507"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2275627852453335"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.8532462610144752\n",
      "Test mse: 0.8691835267261647\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####################################### GANS ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise(batch_size):\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0080, 0.0088, 0.8007, 0.8592, 0.6602, 0.4515, 0.8915, 0.0429, 0.8312,\n",
       "         0.4188, 0.6801, 0.5021, 0.9637, 0.0058, 0.4368, 0.8136, 0.4594, 0.4532,\n",
       "         0.0615, 0.4736, 0.6504, 0.3369, 0.0715, 0.2190, 0.8242, 0.3530, 0.7670,\n",
       "         0.2834, 0.2509, 0.1536, 0.8561, 0.2245, 0.7334, 0.0161, 0.8779, 0.9475,\n",
       "         0.7132, 0.7689, 0.4481, 0.2984, 0.8675, 0.3806, 0.5205, 0.9522, 0.4347,\n",
       "         0.1454, 0.4548, 0.1360, 0.5694, 0.8879, 0.6022, 0.8760, 0.1171, 0.2503,\n",
       "         0.9667, 0.7449, 0.9239, 0.2666, 0.0667, 0.1908, 0.4295, 0.4922, 0.9110,\n",
       "         0.7471, 0.8889, 0.6243, 0.1829, 0.3725, 0.5854, 0.6944, 0.9155, 0.7188,\n",
       "         0.2018, 0.0676, 0.4509, 0.0596, 0.0982, 0.2642, 0.1760, 0.5313, 0.0818,\n",
       "         0.4274, 0.2216, 0.6468, 0.8941, 0.2236, 0.4838, 0.3752, 0.8575, 0.4792,\n",
       "         0.1910, 0.2123, 0.4289, 0.2576, 0.5830, 0.8031, 0.8417, 0.8034, 0.6292,\n",
       "         0.7370],\n",
       "        [0.2387, 0.0677, 0.6953, 0.0592, 0.6877, 0.8006, 0.8035, 0.0380, 0.2590,\n",
       "         0.4348, 0.9950, 0.2792, 0.8365, 0.4826, 0.4520, 0.1567, 0.1134, 0.4356,\n",
       "         0.4540, 0.2949, 0.3140, 0.4947, 0.1317, 0.1099, 0.6581, 0.4619, 0.3265,\n",
       "         0.0587, 0.3598, 0.9496, 0.5569, 0.6104, 0.4766, 0.4970, 0.7833, 0.1949,\n",
       "         0.3028, 0.9121, 0.0193, 0.4971, 0.6051, 0.9748, 0.4697, 0.1849, 0.0834,\n",
       "         0.2476, 0.6926, 0.2077, 0.4068, 0.0152, 0.1828, 0.3124, 0.5804, 0.0869,\n",
       "         0.8293, 0.9373, 0.5583, 0.9318, 0.3267, 0.5118, 0.9014, 0.4796, 0.6995,\n",
       "         0.3374, 0.3833, 0.9703, 0.7919, 0.4627, 0.2236, 0.1798, 0.9316, 0.7507,\n",
       "         0.1899, 0.0988, 0.4182, 0.1748, 0.0767, 0.7513, 0.7513, 0.5507, 0.3094,\n",
       "         0.2835, 0.4810, 0.9768, 0.0461, 0.4732, 0.8362, 0.3739, 0.0534, 0.0159,\n",
       "         0.2007, 0.8402, 0.3999, 0.7526, 0.7322, 0.2290, 0.5615, 0.8175, 0.3493,\n",
       "         0.3319],\n",
       "        [0.6798, 0.0180, 0.7044, 0.1394, 0.2835, 0.7097, 0.8652, 0.8034, 0.2382,\n",
       "         0.4550, 0.1127, 0.8669, 0.9677, 0.5419, 0.4758, 0.0339, 0.8929, 0.7232,\n",
       "         0.7729, 0.9419, 0.6285, 0.6649, 0.7027, 0.4867, 0.6281, 0.2556, 0.2845,\n",
       "         0.2317, 0.4103, 0.9712, 0.1615, 0.1912, 0.7184, 0.0111, 0.5730, 0.0963,\n",
       "         0.0320, 0.7900, 0.0590, 0.4509, 0.8447, 0.7439, 0.2504, 0.7357, 0.6990,\n",
       "         0.1596, 0.4747, 0.6122, 0.1563, 0.5273, 0.9679, 0.1721, 0.4640, 0.6416,\n",
       "         0.6382, 0.8033, 0.5711, 0.6864, 0.4217, 0.5292, 0.4246, 0.3535, 0.0248,\n",
       "         0.6966, 0.2735, 0.1676, 0.4997, 0.1187, 0.3067, 0.8735, 0.5506, 0.1111,\n",
       "         0.7638, 0.4881, 0.7814, 0.7379, 0.7779, 0.1101, 0.7083, 0.9616, 0.7169,\n",
       "         0.4177, 0.6637, 0.2572, 0.6334, 0.4482, 0.9538, 0.1678, 0.4902, 0.8976,\n",
       "         0.5585, 0.1351, 0.3884, 0.4171, 0.8955, 0.9069, 0.4201, 0.6047, 0.8807,\n",
       "         0.7099],\n",
       "        [0.3338, 0.0383, 0.8174, 0.3646, 0.2722, 0.2393, 0.8372, 0.7550, 0.7542,\n",
       "         0.0474, 0.8851, 0.7298, 0.1150, 0.5863, 0.5881, 0.0754, 0.3589, 0.3923,\n",
       "         0.8426, 0.5533, 0.3365, 0.6620, 0.3026, 0.6548, 0.3462, 0.9756, 0.8036,\n",
       "         0.4301, 0.5991, 0.3675, 0.9164, 0.2264, 0.2867, 0.3713, 0.6772, 0.2331,\n",
       "         0.9309, 0.4601, 0.9321, 0.7050, 0.3684, 0.4877, 0.0213, 0.0603, 0.9332,\n",
       "         0.8490, 0.6843, 0.2087, 0.8669, 0.4293, 0.2232, 0.2780, 0.9295, 0.5121,\n",
       "         0.4014, 0.8963, 0.7097, 0.2609, 0.6014, 0.9301, 0.1748, 0.0235, 0.4602,\n",
       "         0.1374, 0.9280, 0.6952, 0.2521, 0.6895, 0.1392, 0.0610, 0.5071, 0.8486,\n",
       "         0.0959, 0.6516, 0.1140, 0.3632, 0.4106, 0.9972, 0.0695, 0.0925, 0.7768,\n",
       "         0.8183, 0.2542, 0.7539, 0.5134, 0.9765, 0.8548, 0.6460, 0.9420, 0.3716,\n",
       "         0.8753, 0.8157, 0.9332, 0.7200, 0.1186, 0.2759, 0.9202, 0.4598, 0.9137,\n",
       "         0.3063],\n",
       "        [0.8442, 0.6215, 0.9879, 0.8489, 0.3091, 0.7779, 0.0768, 0.9113, 0.5584,\n",
       "         0.9581, 0.7960, 0.5330, 0.4017, 0.8968, 0.7694, 0.9481, 0.5033, 0.9427,\n",
       "         0.6329, 0.0976, 0.8898, 0.6061, 0.6697, 0.1762, 0.8854, 0.7559, 0.1697,\n",
       "         0.8644, 0.5204, 0.4841, 0.1759, 0.2402, 0.6792, 0.3204, 0.0434, 0.4192,\n",
       "         0.2632, 0.9319, 0.6021, 0.8193, 0.9975, 0.5494, 0.6743, 0.0985, 0.4839,\n",
       "         0.4456, 0.9299, 0.9081, 0.6838, 0.7606, 0.9704, 0.2810, 0.6170, 0.3840,\n",
       "         0.7801, 0.6948, 0.4559, 0.8737, 0.2260, 0.0713, 0.0027, 0.4748, 0.2190,\n",
       "         0.0972, 0.4097, 0.4333, 0.0875, 0.7865, 0.2426, 0.7492, 0.1079, 0.3840,\n",
       "         0.5139, 0.1100, 0.7813, 0.1429, 0.7336, 0.3020, 0.5991, 0.2926, 0.5258,\n",
       "         0.8611, 0.9442, 0.8855, 0.9034, 0.3181, 0.5698, 0.4076, 0.8338, 0.2857,\n",
       "         0.6075, 0.9381, 0.1208, 0.9815, 0.1257, 0.8485, 0.2890, 0.9851, 0.8100,\n",
       "         0.7325]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_some_noise(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator class\n",
    "\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(800,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining discriminator class\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(200,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(ratings.shape[1], 1)\n",
    "gen = generator(100, ratings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=3706, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=1000, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=800, out_features=3706, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps = 300\n",
    "g_steps = 300\n",
    "\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# printing_steps = 200\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 4, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]\n",
    "    \n",
    "get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g):\n",
    "    return torch.sum(torch.abs((x_r != 0).float() * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "eval_losses = []\n",
    "for epoch in range(1):\n",
    "#     print (epoch)\n",
    "\n",
    "    # training discriminator\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()\n",
    "        \n",
    "        # training discriminator on real data\n",
    "        real_rows = get_random_batch(train, batch_size)\n",
    "        discriminator_real_outputs = dis(real_rows)\n",
    "   \n",
    "        dis_real_loss = criteriond1(discriminator_real_outputs, Variable(torch.ones(batch_size,1)))\n",
    "    \n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # training discriminator on data produced by generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        #output from generator is generated        \n",
    "        fake_rows = gen(z_vector).detach()\n",
    "#         print(fake_rows[:20])\n",
    "        dis_fake_out = dis(fake_rows)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out, Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()\n",
    "        \n",
    "    # training generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()\n",
    "        \n",
    "        #generating data for input for generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        \n",
    "        fake_rows = gen(z_vector)\n",
    "#         print(fake_rows.shape, z_vector.shape)\n",
    "#         print(fake_rows[:20])\n",
    "        dis_out_gen_training = dis(fake_rows)\n",
    "        gen_loss = criteriond2(dis_out_gen_training, Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()\n",
    "\n",
    "    # evaluation\n",
    "    if epoch % 10: # todo- to change\n",
    "        gen.eval()\n",
    "        z_vector_eval = make_some_noise(128)\n",
    "        fake_rows_eval = gen(z_vector_eval)\n",
    "        real_rows_eval = get_random_batch(train, 128)\n",
    "#         print(fake_rows[0][:10]) enable to see some results\n",
    "        eval_loss = F.mse_loss(fake_rows_eval, real_rows_eval, reduction='mean')\n",
    "        eval_losses.append(eval_loss)\n",
    "#         print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "        print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real_rows_eval, fake_rows_eval)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vector = make_some_noise(16)\n",
    "fake_rows = gen(z_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4751, 2.4087, 2.4651, 2.5381, 2.7173, 2.5297, 2.4656, 2.4949, 2.4942],\n",
       "        [2.4714, 2.4538, 2.5122, 2.4905, 2.6927, 2.4939, 2.3742, 2.5208, 2.5684],\n",
       "        [2.5454, 2.4035, 2.4043, 2.4755, 2.7313, 2.5006, 2.3750, 2.5469, 2.5062],\n",
       "        [2.4431, 2.4554, 2.5726, 2.5137, 2.7266, 2.5344, 2.4014, 2.5202, 2.5535],\n",
       "        [2.5323, 2.4005, 2.4857, 2.5244, 2.6772, 2.4893, 2.3810, 2.5227, 2.5475],\n",
       "        [2.4187, 2.4144, 2.4973, 2.5270, 2.6431, 2.5131, 2.4053, 2.5367, 2.6005],\n",
       "        [2.5015, 2.3917, 2.5099, 2.5015, 2.6882, 2.5187, 2.4056, 2.5455, 2.5832],\n",
       "        [2.4392, 2.4226, 2.4881, 2.4967, 2.7093, 2.5174, 2.4019, 2.5444, 2.5315],\n",
       "        [2.4604, 2.3985, 2.4569, 2.4569, 2.7117, 2.5341, 2.4232, 2.5336, 2.5792],\n",
       "        [2.4299, 2.4070, 2.5278, 2.4842, 2.6824, 2.5384, 2.4188, 2.5678, 2.4962],\n",
       "        [2.4650, 2.3520, 2.4993, 2.5331, 2.7134, 2.5217, 2.4013, 2.4753, 2.4910],\n",
       "        [2.5011, 2.3684, 2.5433, 2.5250, 2.6673, 2.5448, 2.4476, 2.4401, 2.5672],\n",
       "        [2.4849, 2.3485, 2.5126, 2.5149, 2.7495, 2.4996, 2.4097, 2.5429, 2.5498],\n",
       "        [2.5489, 2.3900, 2.4760, 2.4628, 2.6949, 2.5258, 2.3977, 2.5269, 2.5260],\n",
       "        [2.4885, 2.4313, 2.4836, 2.5601, 2.6654, 2.5491, 2.4116, 2.4797, 2.5359],\n",
       "        [2.5403, 2.3772, 2.5258, 2.4563, 2.7065, 2.5271, 2.4359, 2.5398, 2.5383]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we see generator produces very similar vectors \n",
    "fake_rows[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os\n",
    "# from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x226202b1c50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 100\n",
    "cuda = True\n",
    "epochs = 100 #change\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "name = \"mnist-experiment\"\n",
    "# configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#     transform=transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length=6\n",
    "# batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Dropout(p=0.5)\n",
      "  )\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(features_length, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(features_length, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, features_length)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        filt = (torch.abs((real != 0).float() * fake - real))/real.shape[0]\n",
    "#         filt = torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda())\n",
    "#         filt = torch.abs((xr != 0).int() * xf - xr)\n",
    "#         filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "#         print(filt.type(), x.type())\n",
    "        x = filt * x\n",
    "\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, features_length),\n",
    "#     torch.nn.Sigmoid()*5\n",
    "#     )\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(nz,1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024,features_length),\n",
    "                                 nn.Sigmoid(),\n",
    "                                 nn.Dropout(0.5)\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]\n",
    "    \n",
    "# networks\n",
    "netD = NetD(use_cuda=False)\n",
    "netG = NetG()\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "cuda = False\n",
    "if cuda is True:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(length=6):\n",
    "     return Variable(torch.IntTensor(np.random.choice([0, 1], size=(batch_size, length))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3706])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_batch(train, batch_size=batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 5. my distance between random real and fake samples 23961.705078125\n",
      "Epoch number 11. my distance between random real and fake samples 14855.115234375\n",
      "Epoch number 17. my distance between random real and fake samples 19585.462890625\n",
      "Epoch number 23. my distance between random real and fake samples 18289.197265625\n",
      "Epoch number 29. my distance between random real and fake samples 22368.3984375\n",
      "Epoch number 35. my distance between random real and fake samples 18190.97265625\n",
      "Epoch number 41. my distance between random real and fake samples 18577.69140625\n",
      "Epoch number 47. my distance between random real and fake samples 19709.3828125\n",
      "Epoch number 52. my distance between random real and fake samples 18464.466796875\n",
      "Epoch number 58. my distance between random real and fake samples 19180.181640625\n",
      "Epoch number 64. my distance between random real and fake samples 20401.185546875\n",
      "Epoch number 70. my distance between random real and fake samples 19513.240234375\n",
      "Epoch number 76. my distance between random real and fake samples 21285.7265625\n",
      "Epoch number 82. my distance between random real and fake samples 15770.1435546875\n",
      "Epoch number 88. my distance between random real and fake samples 18645.48828125\n",
      "Epoch number 94. my distance between random real and fake samples 18219.068359375\n",
      "Epoch number 99. my distance between random real and fake samples 19071.09375\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "gen_iterations = 0\n",
    "eval_losses = []\n",
    "for epoch in range(epochs):\n",
    "#     data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < steps_per_epoch:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter:\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "#             X, _ = data_iter.next()\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             print(X >= 0.5)\n",
    "# #             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "#             print(real.shape, fake.shape)\n",
    "    \n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real)\n",
    "#             print('fake', fake[:,0].sum())\n",
    "            out = netD(real, fake)\n",
    "            \n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "#             print(out.shape)\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter:\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "#             print('output_D', outputD.item(), gen_iterations)\n",
    "#             print('output_G', outputG.item(), gen_iterations)\n",
    "#             print('std_D', stdD.item(), gen_iterations)\n",
    "#             print('std_G', stdG.item(), gen_iterations)\n",
    "            \n",
    "            # evaluation\n",
    "            if gen_iterations % 100 == 0: # todo- to change\n",
    "#                 gen.eval()\n",
    "#                 z_vector_eval = make_some_noise(128)\n",
    "#                 fake_rows_eval = gen(z_vector_eval)\n",
    "#                 real_rows_eval = get_random_batch(train, 128)\n",
    "        #         print(fake_rows[0][:10]) enable to see some results\n",
    "                eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "                eval_losses.append(eval_loss)\n",
    "                print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real, fake)))\n",
    "                print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda()).cuda().type()\n",
    "torch.abs((real != 0).float() * fake - real).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = ratings.shape[0]\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, nz)\n",
    "if cuda: \n",
    "    noise = noise.cuda()\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 tensor(1166747) 226310\n",
      "4 tensor(4349346) 348971\n",
      "3 tensor(3490518) 261197\n",
      "2 tensor(1083305) 107557\n",
      "1 tensor(186574) 56174\n",
      "0 tensor(11198835) 21384031\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == ratings.round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == ratings.round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == ratings.round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == ratings.round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == ratings.round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == ratings.round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11191494 > 21384031\n",
    "fake_ratings = fake.detach().int().numpy().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 5, ..., 3, 0, 0],\n",
       "       [3, 0, 5, ..., 0, 0, 3],\n",
       "       [3, 0, 0, ..., 3, 3, 3],\n",
       "       ...,\n",
       "       [4, 0, 6, ..., 0, 2, 3],\n",
       "       [3, 0, 0, ..., 3, 0, 3],\n",
       "       [3, 3, 5, ..., 0, 2, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040, 3706), (6040, 3706))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11191494 > 21384031\n",
    "fake_ratings.shape, ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.81731789866441"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(fake_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(fake_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030342203061957868"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_ratings > 5).sum()/(fake_ratings <= 5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "select() missing 1 required positional argument: 'choicelist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-16c61f84abbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfake_ratings\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: select() missing 1 required positional argument: 'choicelist'"
     ]
    }
   ],
   "source": [
    "np.select([fake_ratings > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21725054"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_ratings <= 5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = fake_ratings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3706), dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fake_ratings[np.all((fake_ratings <= 5) & np.ones_like(fake_ratings), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(fake_ratings[1, :] > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_fake = fake_ratings[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 3, 3, 0, 3, 4, 3, 0, 0,\n",
       "       0, 0, 0, 4, 0, 4, 0, 3, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0,\n",
       "       4, 3, 4, 3, 3, 3, 3, 3, 0, 0, 3, 4, 0, 4, 3, 4, 0, 3, 0, 0, 0, 3,\n",
       "       0, 3, 0, 0, 4, 3, 4, 0, 0, 0, 4, 0, 3, 3, 0, 0, 3, 3, 4, 0, 4, 0,\n",
       "       0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 4, 3, 4, 3, 3, 0, 0, 3, 4, 4, 3,\n",
       "       4, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 3, 0, 0, 0,\n",
       "       3, 0, 4, 3, 4, 3, 3, 3, 3, 4, 3, 0, 0, 0, 0, 0, 3, 3, 0, 3, 3, 4,\n",
       "       0, 4, 0, 0, 4, 3, 3, 0, 0, 3, 0, 0, 0, 4, 3, 0, 0, 3, 0, 0, 4, 3,\n",
       "       0, 4, 3, 3, 0, 3, 0, 0, 3, 3, 0, 4, 3, 0, 3, 3, 3, 4, 0, 3, 4, 4,\n",
       "       4, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 4, 3, 4, 4, 3, 0, 0, 0, 0, 0,\n",
       "       0, 0, 3, 3, 4, 0, 3, 0, 0, 0, 4, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0,\n",
       "       4, 3, 0, 4, 3, 0, 3, 3, 0, 0, 0, 4, 4, 0, 3, 3, 0, 3, 3, 0, 3, 0,\n",
       "       3, 4, 3, 3, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 0, 0, 0, 3, 3, 0, 0, 0,\n",
       "       0, 4, 0, 0, 0, 3, 0, 0, 0, 3, 0, 4, 4, 0])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adding_fake[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 0, 3, 0, 5, 4, 4, 4, 3, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 4,\n",
       "       0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 3, 3, 0, 0, 6, 4, 0, 4, 0, 0, 5, 6,\n",
       "       0, 0, 5, 4, 0, 4, 0, 5, 5, 4, 0, 5, 4, 5, 0, 5, 0, 3, 0, 5, 5, 5,\n",
       "       0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 3, 4, 0, 0, 0,\n",
       "       0, 4, 0, 5, 0, 4, 0, 5, 5, 5, 0, 5, 0, 0, 6, 4, 0, 0, 0, 4, 3, 0,\n",
       "       5, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 0, 0, 3, 7, 5, 0, 0, 4, 0, 0,\n",
       "       0, 5, 0, 0, 3, 6, 0, 0, 6, 5, 0, 0, 4, 5, 0, 4, 4, 3, 0, 4, 5, 4,\n",
       "       0, 0, 5, 6, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0,\n",
       "       6, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 4, 0,\n",
       "       0, 0, 4, 0, 0, 6, 3, 4, 5, 0, 0, 0, 5, 0, 0, 5, 0, 5, 6, 0, 3, 0,\n",
       "       4, 5, 0, 0, 0, 0, 4, 4, 4, 0, 5, 0, 0, 0, 4, 0, 0, 5, 4, 4, 3, 0,\n",
       "       4, 0, 0, 0, 0, 0, 0, 4, 5, 4, 0, 0, 4, 0, 5, 0, 4, 0, 5, 0, 4, 5,\n",
       "       0, 4, 5, 3, 4, 5, 0, 0, 4, 5, 0, 0, 5, 5, 3, 5, 0, 0, 4, 0, 0, 5,\n",
       "       0, 0, 0, 0, 0, 0, 4, 0, 4, 3, 5, 0, 0, 5])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adding_fake[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040, 3706), (300, 3706))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape, adding_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat = np.append(ratings, adding_fake, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6340, 3706)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.611658815698306"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 3, 4, ..., 3, 2, 0],\n",
       "       [4, 3, 5, ..., 0, 2, 0],\n",
       "       [0, 3, 0, ..., 3, 3, 3]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip(new_mat, 0,5, out=new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.6570253470597726\n",
      "Test mse: 0.8631349847185379\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(new_mat, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.8532536876504951\n",
      "Test mse: 0.8692032685094621\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train.numpy(), 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 8.051797954664277\n",
      "Test mse: 9.87048559826192\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train.numpy(), 40, learning='als', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 4.4125864966591655\n",
      "Test mse: 5.26301574081926\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(new_mat, 40, learning='als', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/lorenzMuller/kernelNet_MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fake[0] < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ratings[0] < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_row(n=10):\n",
    "    elements = [0, 1, 2, 3, 4, 5]\n",
    "    probabilities = [0.5, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "    return np.random.choice(elements, 10, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_dwgan(x_r, x_g):\n",
    "    return sum(x_r != x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g):\n",
    "    return np.sum(np.abs((x_r != 0).astype(int) * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_1 = np.array([0, 0, 3, 0, 4, 0, 0, 0, 0, 0])\n",
    "\n",
    "x_r_2 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_2 = np.array([0, 5, 3, 0, 4, 4, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1, x_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_2, x_g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r = random_row(n=10)\n",
    "x_g = random_row(n=10)\n",
    "\n",
    "print('x real', x_r)\n",
    "print('x gen ', x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
