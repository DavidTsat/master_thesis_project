{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in c:\\users\\davidt\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from matrix_factorization.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter \n",
    "import matrix_factorization\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading Movielens-1m\n",
    "# !curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "# !unzip ml-1m.zip\n",
    "# !cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_list = [i.strip().split(\"::\") for i in open('./ml-1m/ratings.dat', 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open('./ml-1m/users.dat', 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open('./ml-1m/movies.dat', 'r').readlines()]\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1 10 100 1000 1002 1003 1004 1005 1006 1007  ... 99 990 991 992 993  \\\n",
       "UserID                                                ...                      \n",
       "1        5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "10       5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "100      0  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1000     5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1001     4  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "\n",
       "MovieID 994 996 997 998 999  \n",
       "UserID                       \n",
       "1         0   0   0   0   0  \n",
       "10        0   0   0   0   0  \n",
       "100       0   0   0   0   0  \n",
       "1000      0   0   0   0   0  \n",
       "1001      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "R_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(R_df.values, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users = df.user_id.unique().shape[0]\n",
    "# n_items = df.item_id.unique().shape[0]\n",
    "# ratings = np.zeros((n_users, n_items))\n",
    "# for row in df.itertuples():\n",
    "#     ratings[row[1]-1, row[2]-1] = row[3]\n",
    "# ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(R_df.values, dtype=int)\n",
    "n_users = ratings.shape[0]\n",
    "n_items = ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    print (str(n_users) + ' users')\n",
    "    print (str(n_items) + ' items')\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n",
      "Sparsity: 4.47%\n"
     ]
    }
   ],
   "source": [
    "print ('Sparsity: {:4.2f}%'.format(get_sparsity(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=20, replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    \n",
    "#     print(test)\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.9286971547839014"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5396654074473827"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.8264795643096374\n",
      "Test mse: 0.9051574489352089\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####################################### GANS ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise(batch_size):\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7625, 0.1728, 0.5198, 0.2536, 0.5703, 0.1123, 0.5864, 0.2964, 0.5765,\n",
       "         0.5678, 0.3190, 0.0168, 0.5628, 0.2964, 0.7120, 0.6516, 0.1561, 0.1581,\n",
       "         0.1430, 0.5408, 0.7167, 0.8522, 0.7496, 0.1457, 0.1643, 0.3462, 0.1672,\n",
       "         0.1529, 0.7724, 0.8978, 0.7157, 0.0759, 0.7106, 0.3377, 0.8316, 0.6486,\n",
       "         0.8990, 0.8260, 0.0354, 0.2440, 0.6804, 0.7187, 0.3672, 0.7916, 0.9771,\n",
       "         0.2149, 0.9690, 0.9870, 0.9461, 0.6408, 0.6066, 0.9943, 0.2232, 0.4713,\n",
       "         0.2750, 0.6469, 0.6781, 0.0957, 0.0476, 0.2910, 0.7323, 0.3469, 0.6753,\n",
       "         0.5613, 0.3905, 0.1641, 0.1252, 0.0561, 0.2455, 0.2001, 0.4353, 0.4058,\n",
       "         0.5756, 0.0975, 0.0558, 0.3199, 0.3514, 0.4859, 0.1917, 0.2617, 0.8328,\n",
       "         0.6326, 0.3923, 0.9680, 0.3678, 0.9468, 0.6237, 0.0905, 0.8775, 0.0710,\n",
       "         0.5678, 0.4296, 0.8645, 0.6162, 0.8823, 0.3285, 0.7937, 0.5693, 0.0924,\n",
       "         0.0465],\n",
       "        [0.0447, 0.5283, 0.4420, 0.3223, 0.2854, 0.6733, 0.2482, 0.4958, 0.0752,\n",
       "         0.6636, 0.2023, 0.4405, 0.3017, 0.1364, 0.6371, 0.7280, 0.6664, 0.3964,\n",
       "         0.4000, 0.2212, 0.8012, 0.3633, 0.2497, 0.4781, 0.2742, 0.9532, 0.2004,\n",
       "         0.6699, 0.7708, 0.4248, 0.1053, 0.4775, 0.9633, 0.7723, 0.1655, 0.2588,\n",
       "         0.8168, 0.3108, 0.1395, 0.0731, 0.7936, 0.5030, 0.6062, 0.4856, 0.9154,\n",
       "         0.3225, 0.8993, 0.7678, 0.0653, 0.1204, 0.6754, 0.2220, 0.5078, 0.2434,\n",
       "         0.2769, 0.0125, 0.5476, 0.9344, 0.7395, 0.2597, 0.5881, 0.5692, 0.6208,\n",
       "         0.5276, 0.5764, 0.2997, 0.4218, 0.5901, 0.0689, 0.5185, 0.2960, 0.4729,\n",
       "         0.2420, 0.9284, 0.1078, 0.1882, 0.8319, 0.9179, 0.0716, 0.7841, 0.6191,\n",
       "         0.5443, 0.1505, 0.8886, 0.4042, 0.8847, 0.1934, 0.0598, 0.9104, 0.3725,\n",
       "         0.9669, 0.7342, 0.7109, 0.4690, 0.5197, 0.6671, 0.0568, 0.2688, 0.8710,\n",
       "         0.2539],\n",
       "        [0.2930, 0.1457, 0.9455, 0.0230, 0.6584, 0.7544, 0.1793, 0.5205, 0.1407,\n",
       "         0.2322, 0.2121, 0.5920, 0.0286, 0.6174, 0.3703, 0.9548, 0.4771, 0.7755,\n",
       "         0.3993, 0.4727, 0.5700, 0.1385, 0.7256, 0.1331, 0.6650, 0.8397, 0.3068,\n",
       "         0.8614, 0.7548, 0.0112, 0.8558, 0.8045, 0.8888, 0.5039, 0.3411, 0.6917,\n",
       "         0.2797, 0.3812, 0.4664, 0.0774, 0.4993, 0.9374, 0.9952, 0.9570, 0.9053,\n",
       "         0.7436, 0.0698, 0.1291, 0.8004, 0.5606, 0.7831, 0.5181, 0.5746, 0.7587,\n",
       "         0.2547, 0.2090, 0.9253, 0.5089, 0.2300, 0.4561, 0.9990, 0.0570, 0.7529,\n",
       "         0.0069, 0.8358, 0.2720, 0.6602, 0.4451, 0.8456, 0.8469, 0.2200, 0.3320,\n",
       "         0.9822, 0.1292, 0.7457, 0.1322, 0.8725, 0.5947, 0.5407, 0.4602, 0.6251,\n",
       "         0.6759, 0.3346, 0.6970, 0.0404, 0.6397, 0.8107, 0.9465, 0.6781, 0.4576,\n",
       "         0.0909, 0.8095, 0.0816, 0.0199, 0.4279, 0.6582, 0.2663, 0.3500, 0.3299,\n",
       "         0.1172],\n",
       "        [0.7752, 0.8116, 0.6144, 0.5760, 0.3274, 0.2787, 0.8056, 0.5749, 0.7924,\n",
       "         0.7807, 0.7978, 0.9528, 0.8718, 0.8901, 0.2485, 0.3969, 0.5019, 0.6266,\n",
       "         0.4417, 0.6093, 0.0982, 0.1829, 0.3155, 0.5640, 0.4135, 0.1287, 0.1000,\n",
       "         0.7841, 0.0477, 0.2932, 0.9027, 0.7842, 0.4119, 0.7746, 0.8903, 0.7699,\n",
       "         0.0302, 0.5027, 0.6594, 0.2491, 0.6398, 0.2337, 0.2426, 0.1526, 0.6781,\n",
       "         0.1286, 0.9405, 0.5319, 0.8217, 0.1496, 0.1719, 0.0562, 0.3548, 0.2209,\n",
       "         0.8524, 0.0953, 0.9121, 0.3312, 0.1318, 0.9239, 0.1398, 0.9216, 0.6452,\n",
       "         0.4598, 0.0815, 0.9013, 0.2787, 0.6070, 0.6783, 0.2854, 0.6400, 0.0223,\n",
       "         0.9335, 0.9547, 0.2845, 0.9522, 0.8672, 0.6888, 0.5194, 0.3298, 0.7309,\n",
       "         0.4383, 0.7184, 0.4706, 0.1284, 0.5822, 0.0273, 0.4723, 0.7509, 0.6755,\n",
       "         0.4131, 0.9714, 0.9640, 0.6634, 0.2491, 0.1110, 0.4837, 0.2926, 0.3487,\n",
       "         0.3726],\n",
       "        [0.6642, 0.2944, 0.0834, 0.1266, 0.9583, 0.0663, 0.0025, 0.1642, 0.4663,\n",
       "         0.0169, 0.1655, 0.0863, 0.5892, 0.2308, 0.2268, 0.3513, 0.1158, 0.8035,\n",
       "         0.5369, 0.9859, 0.2920, 0.1908, 0.7068, 0.2898, 0.1410, 0.6392, 0.0567,\n",
       "         0.1224, 0.6675, 0.4369, 0.5509, 0.5785, 0.2504, 0.8668, 0.3605, 0.0459,\n",
       "         0.7969, 0.2419, 0.5862, 0.8755, 0.2764, 0.4587, 0.1325, 0.5645, 0.4491,\n",
       "         0.5173, 0.2900, 0.6080, 0.7300, 0.8986, 0.8243, 0.4634, 0.9448, 0.7538,\n",
       "         0.1155, 0.9974, 0.4258, 0.0529, 0.7582, 0.1183, 0.8398, 0.1862, 0.7924,\n",
       "         0.2030, 0.2285, 0.0034, 0.7582, 0.5424, 0.9832, 0.7877, 0.9914, 0.1364,\n",
       "         0.1212, 0.4084, 0.9178, 0.1966, 0.0826, 0.0362, 0.3347, 0.8685, 0.6221,\n",
       "         0.6786, 0.5461, 0.4920, 0.7316, 0.7890, 0.2972, 0.2979, 0.1090, 0.5410,\n",
       "         0.6437, 0.4214, 0.4230, 0.2558, 0.4633, 0.1159, 0.8489, 0.5455, 0.3017,\n",
       "         0.9798]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_some_noise(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator class\n",
    "\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(800,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining discriminator class\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(200,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(ratings.shape[1], 1)\n",
    "gen = generator(100, ratings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=3706, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=1000, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=800, out_features=3706, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps = 300\n",
    "g_steps = 300\n",
    "\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# printing_steps = 200\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]\n",
    "    \n",
    "get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g):\n",
    "    return torch.sum(torch.abs((x_r != 0).float() * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1. my distance between random real and fake samples 23167.462890625\n",
      "Epoch number 2. my distance between random real and fake samples 18493.703125\n",
      "Epoch number 3. my distance between random real and fake samples 26188.58203125\n",
      "Epoch number 4. my distance between random real and fake samples 22557.82421875\n",
      "Epoch number 5. my distance between random real and fake samples 22734.708984375\n",
      "Epoch number 6. my distance between random real and fake samples 24120.15625\n",
      "Epoch number 7. my distance between random real and fake samples 17089.607421875\n",
      "Epoch number 8. my distance between random real and fake samples 21990.671875\n",
      "Epoch number 9. my distance between random real and fake samples 26925.314453125\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "eval_losses = []\n",
    "for epoch in range(10):\n",
    "#     print (epoch)\n",
    "\n",
    "    # training discriminator\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()\n",
    "        \n",
    "        # training discriminator on real data\n",
    "        real_rows = get_random_batch(train, batch_size)\n",
    "        discriminator_real_outputs = dis(real_rows)\n",
    "   \n",
    "        dis_real_loss = criteriond1(discriminator_real_outputs, Variable(torch.ones(batch_size,1)))\n",
    "    \n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # training discriminator on data produced by generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        #output from generator is generated        \n",
    "        fake_rows = gen(z_vector).detach()\n",
    "#         print(fake_rows[:20])\n",
    "        dis_fake_out = dis(fake_rows)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out, Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()\n",
    "        \n",
    "    # training generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()\n",
    "        \n",
    "        #generating data for input for generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        \n",
    "        fake_rows = gen(z_vector)\n",
    "#         print(fake_rows.shape, z_vector.shape)\n",
    "#         print(fake_rows[:20])\n",
    "        dis_out_gen_training = dis(fake_rows)\n",
    "        gen_loss = criteriond2(dis_out_gen_training, Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()\n",
    "\n",
    "    # evaluation\n",
    "    if epoch % 10: # todo- to change\n",
    "        gen.eval()\n",
    "        z_vector_eval = make_some_noise(128)\n",
    "        fake_rows_eval = gen(z_vector_eval)\n",
    "        real_rows_eval = get_random_batch(train, 128)\n",
    "#         print(fake_rows[0][:10]) enable to see some results\n",
    "        eval_loss = F.mse_loss(fake_rows_eval, real_rows_eval, reduction='mean')\n",
    "        eval_losses.append(eval_loss)\n",
    "#         print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "        print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real_rows_eval, fake_rows_eval)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vector = make_some_noise(16)\n",
    "fake_rows = gen(z_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.7990, 3.6840, 0.7094, 0.6472, 0.3511, 1.0600, 0.7167, 2.1722, 1.4093],\n",
       "        [4.7957, 3.6802, 0.7133, 0.6472, 0.3497, 1.0695, 0.7174, 2.1712, 1.4215],\n",
       "        [4.7958, 3.6809, 0.7289, 0.6544, 0.3574, 1.0771, 0.7265, 2.1694, 1.4288],\n",
       "        [4.7960, 3.6804, 0.7241, 0.6444, 0.3541, 1.0682, 0.7122, 2.1563, 1.4252],\n",
       "        [4.8008, 3.6861, 0.7100, 0.6382, 0.3458, 1.0679, 0.7160, 2.1668, 1.4069],\n",
       "        [4.8032, 3.6976, 0.6979, 0.6479, 0.3518, 1.0778, 0.7018, 2.1516, 1.4134],\n",
       "        [4.7908, 3.6764, 0.7249, 0.6693, 0.3563, 1.0733, 0.7187, 2.1691, 1.4247],\n",
       "        [4.8045, 3.6900, 0.7027, 0.6412, 0.3451, 1.0591, 0.7006, 2.1560, 1.4143],\n",
       "        [4.7969, 3.6891, 0.7268, 0.6549, 0.3506, 1.0812, 0.7221, 2.1583, 1.4261],\n",
       "        [4.7981, 3.6710, 0.7056, 0.6555, 0.3526, 1.0665, 0.7167, 2.1757, 1.4048],\n",
       "        [4.7966, 3.6752, 0.7220, 0.6483, 0.3501, 1.0708, 0.7163, 2.1745, 1.4115],\n",
       "        [4.8032, 3.6874, 0.7064, 0.6414, 0.3494, 1.0646, 0.7089, 2.1691, 1.4238],\n",
       "        [4.7901, 3.6603, 0.7259, 0.6502, 0.3565, 1.0802, 0.7341, 2.1924, 1.4254],\n",
       "        [4.7986, 3.6896, 0.7076, 0.6477, 0.3475, 1.0737, 0.7156, 2.1567, 1.4199],\n",
       "        [4.7980, 3.6823, 0.7316, 0.6538, 0.3558, 1.0739, 0.7150, 2.1749, 1.4080],\n",
       "        [4.7975, 3.6804, 0.7189, 0.6508, 0.3563, 1.0687, 0.7239, 2.1707, 1.4154]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we see generator produces very similar vectors \n",
    "fake_rows[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os\n",
    "# from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x162d2578750>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 100\n",
    "cuda = True\n",
    "epochs = 60 #change\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "name = \"mnist-experiment\"\n",
    "# configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#     transform=transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length=6\n",
    "# batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-346e466c3bc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'features_length' is not defined"
     ]
    }
   ],
   "source": [
    "features_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Dropout(p=0.5)\n",
      "  )\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(features_length, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(features_length, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, features_length)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        filt = (torch.abs((real != 0).float() * fake - real))/real.shape[0]\n",
    "#         filt = torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda())\n",
    "#         filt = torch.abs((xr != 0).int() * xf - xr)\n",
    "#         filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "#         print(filt.type(), x.type())\n",
    "        x = filt * x\n",
    "\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, features_length),\n",
    "#     torch.nn.Sigmoid()*5\n",
    "#     )\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(nz,1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024,features_length),\n",
    "                                 nn.Sigmoid(),\n",
    "                                 nn.Dropout(0.5)\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]\n",
    "    \n",
    "# networks\n",
    "netD = NetD(use_cuda=False)\n",
    "netG = NetG()\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "cuda = False\n",
    "if cuda is True:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(length=6):\n",
    "     return Variable(torch.IntTensor(np.random.choice([0, 1], size=(batch_size, length))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3706])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_batch(train, batch_size=batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 5. my distance between random real and fake samples 30489.251953125\n",
      "Epoch number 11. my distance between random real and fake samples 39576.18359375\n",
      "Epoch number 17. my distance between random real and fake samples 36241.203125\n",
      "Epoch number 23. my distance between random real and fake samples 27993.5\n",
      "Epoch number 29. my distance between random real and fake samples 28787.44921875\n",
      "Epoch number 35. my distance between random real and fake samples 24984.685546875\n",
      "Epoch number 41. my distance between random real and fake samples 40185.18359375\n",
      "Epoch number 47. my distance between random real and fake samples 35311.5546875\n",
      "Epoch number 52. my distance between random real and fake samples 27436.328125\n",
      "Epoch number 58. my distance between random real and fake samples 28843.56640625\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "gen_iterations = 0\n",
    "eval_losses = []\n",
    "for epoch in range(epochs):\n",
    "#     data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < steps_per_epoch:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter:\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "#             X, _ = data_iter.next()\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             print(X >= 0.5)\n",
    "# #             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "#             print(real.shape, fake.shape)\n",
    "    \n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real)\n",
    "#             print('fake', fake[:,0].sum())\n",
    "            out = netD(real, fake)\n",
    "            \n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "#             print(out.shape)\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter:\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "#             print('output_D', outputD.item(), gen_iterations)\n",
    "#             print('output_G', outputG.item(), gen_iterations)\n",
    "#             print('std_D', stdD.item(), gen_iterations)\n",
    "#             print('std_G', stdG.item(), gen_iterations)\n",
    "            \n",
    "            # evaluation\n",
    "            if gen_iterations % 100 == 0: # todo- to change\n",
    "#                 gen.eval()\n",
    "#                 z_vector_eval = make_some_noise(128)\n",
    "#                 fake_rows_eval = gen(z_vector_eval)\n",
    "#                 real_rows_eval = get_random_batch(train, 128)\n",
    "        #         print(fake_rows[0][:10]) enable to see some results\n",
    "                eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "                eval_losses.append(eval_loss)\n",
    "                print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real, fake)))\n",
    "#                 print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda()).cuda().type()\n",
    "torch.abs((real != 0).float() * fake - real).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = ratings.shape[0]\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, nz)\n",
    "if cuda: \n",
    "    noise = noise.cuda()\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 tensor(595764) 226310\n",
      "4 tensor(4591106) 348971\n",
      "3 tensor(4145607) 261197\n",
      "2 tensor(1370664) 107557\n",
      "1 tensor(263981) 56174\n",
      "0 tensor(11196406) 21384031\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == ratings.round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == ratings.round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == ratings.round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == ratings.round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == ratings.round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == ratings.round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 4.1023, 3.5381],\n",
       "        [0.0000, 3.8251, 2.9407,  ..., 0.0000, 0.0000, 4.0841],\n",
       "        [3.9226, 0.0000, 2.8741,  ..., 4.0445, 4.2880, 3.7894],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 3.7522, 0.0000, 3.6466],\n",
       "        [3.8065, 3.7947, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [4.1363, 0.0000, 3.2282,  ..., 4.0445, 3.9376, 3.3084]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake[:10,:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1854)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake[0] < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3653"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ratings[0] < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6040, 3706])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_row(n=10):\n",
    "    elements = [0, 1, 2, 3, 4, 5]\n",
    "    probabilities = [0.5, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "    return np.random.choice(elements, 10, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_dwgan(x_r, x_g):\n",
    "    return sum(x_r != x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g):\n",
    "    return np.sum(np.abs((x_r != 0).astype(int) * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_1 = np.array([0, 0, 3, 0, 4, 0, 0, 0, 0, 0])\n",
    "\n",
    "x_r_2 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_2 = np.array([0, 5, 3, 0, 4, 4, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1, x_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_2, x_g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r = random_row(n=10)\n",
    "x_g = random_row(n=10)\n",
    "\n",
    "print('x real', x_r)\n",
    "print('x gen ', x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
