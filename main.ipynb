{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter \n",
    "import matrix_factorization\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Movielens-100k\n",
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip ml-100k.zip\n",
    "!cd ml-100k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('ml-100k.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    print (str(n_users) + ' users')\n",
    "    print (str(n_items) + ' items')\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Sparsity: 6.30%\n"
     ]
    }
   ],
   "source": [
    "print ('Sparsity: {:4.2f}%'.format(get_sparsity(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=10, replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.9179628673300955\n",
      "Test mse: 1.0113053267188021\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.304669364224531"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.710139043178159"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5945303210463734"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####################################### GANS ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise(batch_size):\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4625, 0.8899, 0.1385, 0.0472, 0.5384, 0.6960, 0.9908, 0.9145, 0.5137,\n",
       "         0.6804, 0.8615, 0.4312, 0.6037, 0.9117, 0.4875, 0.6603, 0.7794, 0.3952,\n",
       "         0.4483, 0.1756, 0.2478, 0.1236, 0.5203, 0.9911, 0.0862, 0.7621, 0.7322,\n",
       "         0.2437, 0.9434, 0.2282, 0.7428, 0.1790, 0.4105, 0.3193, 0.7175, 0.1299,\n",
       "         0.0746, 0.1848, 0.7205, 0.9461, 0.6725, 0.6661, 0.1551, 0.5163, 0.9645,\n",
       "         0.6228, 0.6040, 0.0699, 0.2416, 0.7396, 0.7768, 0.7044, 0.6805, 0.9212,\n",
       "         0.3998, 0.4781, 0.7919, 0.1231, 0.0625, 0.3906, 0.3922, 0.2182, 0.4140,\n",
       "         0.5691, 0.3555, 0.2843, 0.9089, 0.5347, 0.3190, 0.8424, 0.1724, 0.9083,\n",
       "         0.5839, 0.5719, 0.1140, 0.8031, 0.0887, 0.0116, 0.7744, 0.4654, 0.6525,\n",
       "         0.8710, 0.9873, 0.5563, 0.8061, 0.2056, 0.1669, 0.8843, 0.9240, 0.0941,\n",
       "         0.0692, 0.3054, 0.9895, 0.8850, 0.4217, 0.8719, 0.8767, 0.7187, 0.7997,\n",
       "         0.0846],\n",
       "        [0.7759, 0.3813, 0.0787, 0.3424, 0.7061, 0.4004, 0.9523, 0.9829, 0.7490,\n",
       "         0.7930, 0.3726, 0.8759, 0.0842, 0.0940, 0.1474, 0.8525, 0.0543, 0.2447,\n",
       "         0.8190, 0.4676, 0.6791, 0.2262, 0.6551, 0.2604, 0.9143, 0.9481, 0.4696,\n",
       "         0.1588, 0.6281, 0.9175, 0.1020, 0.6477, 0.0568, 0.5892, 0.8259, 0.5325,\n",
       "         0.5267, 0.5477, 0.9650, 0.4105, 0.7091, 0.7539, 0.1089, 0.9349, 0.5272,\n",
       "         0.3715, 0.0148, 0.2250, 0.8894, 0.9693, 0.0393, 0.3827, 0.0541, 0.2601,\n",
       "         0.4873, 0.7126, 0.2585, 0.4199, 0.7197, 0.6009, 0.7862, 0.7044, 0.3833,\n",
       "         0.4704, 0.3446, 0.0612, 0.9623, 0.7322, 0.5240, 0.0766, 0.1092, 0.2289,\n",
       "         0.4378, 0.1611, 0.6597, 0.4906, 0.3302, 0.6429, 0.9837, 0.2566, 0.1427,\n",
       "         0.9081, 0.0367, 0.1326, 0.9372, 0.4922, 0.2484, 0.8045, 0.0747, 0.9349,\n",
       "         0.0403, 0.2180, 0.1327, 0.3089, 0.6710, 0.5173, 0.7765, 0.3507, 0.7772,\n",
       "         0.4174],\n",
       "        [0.8933, 0.4190, 0.6681, 0.8710, 0.7352, 0.8089, 0.7582, 0.8797, 0.5696,\n",
       "         0.4129, 0.4720, 0.3494, 0.3527, 0.2968, 0.1784, 0.3895, 0.5543, 0.4736,\n",
       "         0.4291, 0.0226, 0.6117, 0.9319, 0.1009, 0.8157, 0.8066, 0.8535, 0.2042,\n",
       "         0.8900, 0.4611, 0.4039, 0.8842, 0.7482, 0.8040, 0.0015, 0.0556, 0.6521,\n",
       "         0.1802, 0.2967, 0.8726, 0.6233, 0.6132, 0.8241, 0.2317, 0.5308, 0.6909,\n",
       "         0.5802, 0.8059, 0.6866, 0.4646, 0.0392, 0.8144, 0.7795, 0.0149, 0.6981,\n",
       "         0.1307, 0.0496, 0.0553, 0.8627, 0.5344, 0.6697, 0.9965, 0.8607, 0.8070,\n",
       "         0.8899, 0.9352, 0.3395, 0.5816, 0.7271, 0.2205, 0.3196, 0.6971, 0.5954,\n",
       "         0.7680, 0.3761, 0.8360, 0.4402, 0.7562, 0.8389, 0.8744, 0.8861, 0.0463,\n",
       "         0.6742, 0.6429, 0.4727, 0.0852, 0.6364, 0.4591, 0.7694, 0.2233, 0.2872,\n",
       "         0.0498, 0.2447, 0.2086, 0.0231, 0.2694, 0.0702, 0.4243, 0.3150, 0.1464,\n",
       "         0.5990],\n",
       "        [0.7946, 0.8068, 0.7178, 0.4141, 0.2425, 0.3094, 0.4020, 0.3907, 0.1490,\n",
       "         0.8363, 0.7785, 0.9704, 0.3539, 0.7087, 0.0979, 0.6503, 0.8813, 0.0745,\n",
       "         0.8893, 0.0085, 0.3152, 0.0197, 0.7384, 0.1479, 0.1268, 0.8363, 0.9485,\n",
       "         0.2510, 0.3937, 0.5549, 0.2857, 0.4098, 0.5229, 0.1445, 0.7895, 0.4493,\n",
       "         0.1874, 0.3459, 0.0086, 0.3558, 0.6377, 0.0886, 0.5456, 0.0586, 0.2201,\n",
       "         0.0722, 0.5872, 0.9673, 0.6305, 0.0780, 0.0728, 0.1033, 0.8491, 0.9160,\n",
       "         0.2869, 0.2770, 0.3864, 0.6716, 0.9123, 0.9923, 0.8790, 0.0291, 0.2880,\n",
       "         0.4664, 0.8292, 0.1194, 0.0236, 0.9683, 0.1619, 0.9509, 0.6925, 0.6791,\n",
       "         0.7737, 0.0300, 0.3164, 0.3829, 0.6643, 0.0130, 0.3594, 0.6543, 0.5110,\n",
       "         0.2079, 0.0184, 0.2720, 0.1732, 0.6890, 0.3926, 0.1363, 0.3712, 0.4972,\n",
       "         0.9099, 0.8689, 0.4880, 0.4565, 0.6998, 0.1136, 0.6328, 0.5422, 0.9201,\n",
       "         0.8696],\n",
       "        [0.1482, 0.1976, 0.4870, 0.8031, 0.6934, 0.6237, 0.1736, 0.2657, 0.9302,\n",
       "         0.2268, 0.0204, 0.9938, 0.4396, 0.4528, 0.1477, 0.2736, 0.6060, 0.9152,\n",
       "         0.5112, 0.9910, 0.6457, 0.2762, 0.0675, 0.9782, 0.5061, 0.8434, 0.2684,\n",
       "         0.8008, 0.8064, 0.2911, 0.6972, 0.6441, 0.3086, 0.1944, 0.8039, 0.0079,\n",
       "         0.4791, 0.5474, 0.0683, 0.0750, 0.1469, 0.8898, 0.8440, 0.6618, 0.8433,\n",
       "         0.0644, 0.2696, 0.8769, 0.9549, 0.1172, 0.7799, 0.2059, 0.3203, 0.1838,\n",
       "         0.6380, 0.5082, 0.8636, 0.8823, 0.2408, 0.3657, 0.8581, 0.9427, 0.4931,\n",
       "         0.2350, 0.1424, 0.7951, 0.7374, 0.6474, 0.6148, 0.4771, 0.8763, 0.1604,\n",
       "         0.4354, 0.7953, 0.3053, 0.5515, 0.3373, 0.6450, 0.7340, 0.7281, 0.9476,\n",
       "         0.2281, 0.9588, 0.3811, 0.5362, 0.6484, 0.9849, 0.2414, 0.5663, 0.1563,\n",
       "         0.7299, 0.7561, 0.8694, 0.2356, 0.6635, 0.8279, 0.0012, 0.8972, 0.1676,\n",
       "         0.0366]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_some_noise(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator class\n",
    "\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(800,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining discriminator class\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(200,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(ratings.shape[1], 1)\n",
    "gen = generator(100, ratings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=1682, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=1000, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=800, out_features=1682, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps = 300\n",
    "g_steps = 300\n",
    "\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# printing_steps = 200\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [3., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]\n",
    "    \n",
    "get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1. MSE distance between random real and fake samples 1298359.125\n",
      "Epoch number 2. MSE distance between random real and fake samples 1268023.75\n",
      "Epoch number 3. MSE distance between random real and fake samples 1268135.5\n",
      "Epoch number 4. MSE distance between random real and fake samples 1233828.5\n",
      "Epoch number 5. MSE distance between random real and fake samples 1125817.75\n",
      "Epoch number 6. MSE distance between random real and fake samples 995061.8125\n",
      "Epoch number 7. MSE distance between random real and fake samples 831373.25\n",
      "Epoch number 8. MSE distance between random real and fake samples 670957.875\n",
      "Epoch number 9. MSE distance between random real and fake samples 550445.125\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "eval_losses = []\n",
    "for epoch in range(10):\n",
    "#     print (epoch)\n",
    "\n",
    "    # training discriminator\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()\n",
    "        \n",
    "        # training discriminator on real data\n",
    "        real_rows = get_random_batch(train, batch_size)\n",
    "        discriminator_real_outputs = dis(real_rows)\n",
    "   \n",
    "        dis_real_loss = criteriond1(discriminator_real_outputs, Variable(torch.ones(batch_size,1)))\n",
    "    \n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # training discriminator on data produced by generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        #output from generator is generated        \n",
    "        fake_rows = gen(z_vector).detach()\n",
    "#         print(fake_rows[:20])\n",
    "        dis_fake_out = dis(fake_rows)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out, Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()\n",
    "        \n",
    "    # training generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()\n",
    "        \n",
    "        #generating data for input for generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        \n",
    "        fake_rows = gen(z_vector)\n",
    "#         print(fake_rows.shape, z_vector.shape)\n",
    "#         print(fake_rows[:20])\n",
    "        dis_out_gen_training = dis(fake_rows)\n",
    "        gen_loss = criteriond2(dis_out_gen_training, Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()\n",
    "\n",
    "    # evaluation\n",
    "    if epoch % 10: # todo- to change\n",
    "        gen.eval()\n",
    "        z_vector_eval = make_some_noise(128)\n",
    "        fake_rows_eval = gen(z_vector_eval)\n",
    "        real_rows_eval = get_random_batch(train, 128)\n",
    "#         print(fake_rows[0][:10]) enable to see some results\n",
    "        eval_loss = F.mse_loss(fake_rows_eval, real_rows_eval, reduction='sum')\n",
    "        eval_losses.append(eval_loss)\n",
    "        print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "#         print('Epoch number {}. L1 distance between random real and fake samples {}'.format(epoch, torch.sum(torch.abs(fake_rows_eval - real_rows_eval))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vector = make_some_noise(16)\n",
    "fake_rows = gen(z_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9296, 1.1387, 1.5669, 4.4206, 0.4383, 0.2694, 4.9433, 4.7220, 4.8977],\n",
       "        [4.9277, 1.1527, 1.5739, 4.4191, 0.4444, 0.2746, 4.9425, 4.7164, 4.8955],\n",
       "        [4.9312, 1.1420, 1.5630, 4.4317, 0.4344, 0.2639, 4.9453, 4.7252, 4.8993],\n",
       "        [4.9308, 1.1444, 1.5674, 4.4309, 0.4359, 0.2632, 4.9453, 4.7279, 4.9002],\n",
       "        [4.9317, 1.1397, 1.5696, 4.4296, 0.4315, 0.2638, 4.9450, 4.7237, 4.8992],\n",
       "        [4.9310, 1.1437, 1.5655, 4.4315, 0.4401, 0.2631, 4.9450, 4.7255, 4.8991],\n",
       "        [4.9325, 1.1276, 1.5595, 4.4367, 0.4300, 0.2606, 4.9464, 4.7292, 4.9007],\n",
       "        [4.9297, 1.1481, 1.5686, 4.4245, 0.4381, 0.2660, 4.9439, 4.7202, 4.8971],\n",
       "        [4.9299, 1.1483, 1.5665, 4.4282, 0.4392, 0.2659, 4.9437, 4.7233, 4.8975],\n",
       "        [4.9301, 1.1490, 1.5645, 4.4264, 0.4349, 0.2656, 4.9448, 4.7249, 4.8983],\n",
       "        [4.9315, 1.1431, 1.5661, 4.4319, 0.4339, 0.2620, 4.9456, 4.7275, 4.8996],\n",
       "        [4.9292, 1.1445, 1.5628, 4.4257, 0.4406, 0.2674, 4.9435, 4.7210, 4.8979],\n",
       "        [4.9312, 1.1416, 1.5671, 4.4320, 0.4351, 0.2638, 4.9448, 4.7282, 4.8990],\n",
       "        [4.9294, 1.1467, 1.5673, 4.4256, 0.4388, 0.2665, 4.9446, 4.7207, 4.8984],\n",
       "        [4.9290, 1.1445, 1.5668, 4.4238, 0.4386, 0.2691, 4.9433, 4.7205, 4.8969],\n",
       "        [4.9295, 1.1496, 1.5724, 4.4223, 0.4402, 0.2676, 4.9440, 4.7211, 4.8972]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we see generator produces very similar vectors \n",
    "fake_rows[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os\n",
    "# from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrD = 5e-4\n",
    "# lrG = 5e-4\n",
    "# batch_size = 100\n",
    "# cuda = True\n",
    "# epochs = 1000\n",
    "# device = 5\n",
    "# seed = 42\n",
    "# nz = 100\n",
    "# d_iter = 5\n",
    "# g_iter = 1\n",
    "# lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "# name = \"mnist-experiment\"\n",
    "# # configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "# torch.manual_seed(seed)\n",
    "# # if cuda:\n",
    "# # #     torch.cuda.set_device('cuda')\n",
    "# #     torch.cuda.manual_seed(seed)\n",
    "# # data_loader = torch.utils.data.DataLoader(\n",
    "# # datasets.MNIST('../data', train=True, download=True,\n",
    "# # transform=transforms.Compose([transforms.ToTensor(),])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 100\n",
    "cuda = True\n",
    "epochs = 1000\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "name = \"mnist-experiment\"\n",
    "# configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length=6\n",
    "# batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1682, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=1682, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=1682, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=1682, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(features_length, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(features_length, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, features_length)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "        x = filt * x\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, features_length),\n",
    "#     torch.nn.Sigmoid()*5\n",
    "#     )\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(nz,1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024,features_length),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]\n",
    "    \n",
    "# networks\n",
    "netD = NetD(use_cuda=False)\n",
    "netG = NetG()\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NetD(torch.nn.Module):\n",
    "#     def __init__(self, use_cuda=True):\n",
    "#         super(NetD, self).__init__()\n",
    "#         self.use_cuda = use_cuda\n",
    "#         # top\n",
    "#         self.t1 = torch.nn.Linear(length, 1024)\n",
    "#         # bottom\n",
    "#         self.b1 = torch.nn.Linear(length, 1024)\n",
    "#         # combined\n",
    "#         self.fc = torch.nn.Linear(2 * 1024, length)\n",
    "#     def forward(self, xr, xf):\n",
    "#         # get filt\n",
    "# #         print(\"##########\"*40)\n",
    "#         filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "# #         if (filt == xr * xf).all():\n",
    "# #             print('AAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
    "            \n",
    "# #         print('xr & xf', xr * xf)\n",
    "# #         print('filt', filt)\n",
    "# #         print('xr.shape, xf.shape', xr.shape, xf.shape)\n",
    "# #         print('filt.shape', filt.shape)\n",
    "# #         print('xr', xr)\n",
    "# #         print('xf', xf)\n",
    "# #         print('filt', filt)\n",
    "# # #         return filt\n",
    "# #         # random swap\n",
    "#         idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "# #         print(idr.shape)\n",
    "# #         print('idr', idr)\n",
    "#         idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "# #         print('idrx', idrx)\n",
    "# #         print('idrx.shape', idrx.shape)\n",
    "# #         print('idrx', idrx[10:20, 100:200])\n",
    "#         if self.use_cuda: \n",
    "#             idrx = idrx.cuda()\n",
    "#         idrx = Variable(idrx)\n",
    "# #         print('xr.shape', xr.shape)\n",
    "# #         print('xr', xr[10:20, 100:200])\n",
    "# #         print('xr*idrx.shape', (xr*idrx).shape)\n",
    "# #         print('xr*idrx', (xr*idrx)[10:20, 100:200])\n",
    "# #         print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA', xr * idrx == xr)\n",
    "# #         for c in xr * idrx == xr:\n",
    "# #             print(c)\n",
    "#         xt = xr * idrx + xf * (1 - idrx)\n",
    "#         xb = xr * (1 - idrx) + xf * idrx\n",
    "# #         print('xt', xt)\n",
    "# #         print('xb', xb)\n",
    "#         # top : real\n",
    "#         xt = F.relu(self.t1(xt))\n",
    "#         # bottom : fake\n",
    "#         xb = F.relu(self.b1(xb))\n",
    "#         # combined\n",
    "# #         print(xt.shape, xb.shape)\n",
    "#         x = torch.cat((xt, xb), 1)\n",
    "# #         print('x', x)\n",
    "#         x = torch.tanh(self.fc(x))\n",
    "# #         print('xxxx', x.shape)\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('filt', filt[:10, :10])\n",
    "#         # apply filter, aggregate\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('filt', filt[:10, :10])\n",
    "#         x = filt * x\n",
    "# #         print('x', x)\n",
    "# #         print('x[:, :10]', x[:10, :10])\n",
    "# #         print('xxxx', x.shape)\n",
    "# #         print('x', x[:10, :10])\n",
    "# #         print(x.mean(dim = 1).shape, x.mean(dim = 1))\n",
    "#         x = x.mean(dim = 1).squeeze()\n",
    "# #         print('x', x)\n",
    "# #         print('xxxx', x.shape)\n",
    "#         # use sign, because of swapping\n",
    "#         sgn = idr * 2 - 1\n",
    "#         if self.use_cuda: \n",
    "#             sgn = sgn.cuda()\n",
    "#         sgn = Variable(sgn.float())\n",
    "#         x = sgn * x\n",
    "# #         print('x', x)\n",
    "# #         print(\"##########\"*40)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # latent_vec_size = 100\n",
    "# # vec_size = 1000\n",
    "\n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, length),\n",
    "#     torch.nn.Sigmoid()\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # networks\n",
    "# netD = NetD(False)\n",
    "# print(netG)\n",
    "# print(netD)\n",
    "# optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "# optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "# one = torch.FloatTensor([1])\n",
    "# mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "cuda = False\n",
    "if cuda is True:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(length=6):\n",
    "     return Variable(torch.IntTensor(np.random.choice([0, 1], size=(batch_size, length))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1682])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_batch(train, batch_size=batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 5. MSE distance between random real and fake samples 1.604702353477478\n",
      "Epoch number 11. MSE distance between random real and fake samples 0.9594227075576782\n",
      "Epoch number 17. MSE distance between random real and fake samples 0.774270236492157\n",
      "Epoch number 23. MSE distance between random real and fake samples 0.7350497245788574\n",
      "Epoch number 29. MSE distance between random real and fake samples 0.9030481576919556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-203-3f0c5c80ab05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m#             print('real', real)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#             print('fake', fake[:,0].sum())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0moutputD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlamba\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-193-87d074315905>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xr, xf)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0midrx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midrx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0midrx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mxf\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0midrx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mxb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0midrx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mxf\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0midrx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;31m# top : real\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "gen_iterations = 0\n",
    "eval_loss = []\n",
    "for epoch in range(epochs):\n",
    "#     data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < steps_per_epoch:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter and i < len(data_loader):\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "#             X, _ = data_iter.next()\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             print(X >= 0.5)\n",
    "# #             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "#             print(real.shape, fake.shape)\n",
    "    \n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real)\n",
    "#             print('fake', fake[:,0].sum())\n",
    "            out = netD(real, fake)\n",
    "            \n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "#             print(out.shape)\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter and i < len(data_loader):\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "#             print('output_D', outputD.item(), gen_iterations)\n",
    "#             print('output_G', outputG.item(), gen_iterations)\n",
    "#             print('std_D', stdD.item(), gen_iterations)\n",
    "#             print('std_G', stdG.item(), gen_iterations)\n",
    "            \n",
    "            # evaluation\n",
    "            if gen_iterations % 100 == 0: # todo- to change\n",
    "#                 gen.eval()\n",
    "#                 z_vector_eval = make_some_noise(128)\n",
    "#                 fake_rows_eval = gen(z_vector_eval)\n",
    "#                 real_rows_eval = get_random_batch(train, 128)\n",
    "        #         print(fake_rows[0][:10]) enable to see some results\n",
    "                eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "                eval_losses.append(eval_loss)\n",
    "                print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "\n",
    "#     #         print(gen_iterations)\n",
    "#             if gen_iterations % 100 == 0:\n",
    "#                 if not isdir('./images/{0}'.format(name)):\n",
    "#                     os.makedirs('./images/{0}'.format(name))\n",
    "#                 real = real.data[0:100,:]\n",
    "#                 real = real.view(real.size(0), 1, 28, 28)\n",
    "#                 vutils.save_image(real, './images/{0}/real_samples.png'.format(name, gen_iterations))\n",
    "#                 noise = torch.randn(min(100, batch_size), nz)\n",
    "#                 if cuda: \n",
    "#                     noise = noise.cuda()\n",
    "#                 fake = netG(Variable(noise, volatile=True))\n",
    "# #                 print('real', real)\n",
    "# #                 print('fake', fake)\n",
    "#                 # fake = (fake.data >= 0.5).float()\n",
    "#                 R = torch.rand(fake.size())\n",
    "#                 fake = (fake.data.cpu() >= R).float()\n",
    "#                 fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "#                 vutils.save_image(fake, './images/{0}/fake_samples_{1}.png'.format(name, gen_iterations))\n",
    "#     # do checkpointing\n",
    "# #     if not isdir('./checkpoint/{0}'.format(name)):\n",
    "# #         os.makedirs('./checkpoint/{0}'.format(name))\n",
    "#     torch.save(netG.state_dict(), './checkpoint/{0}/netG_epoch_{1}.pth'.format(name, epoch))\n",
    "#     torch.save(netD.state_dict(), './checkpoint/{0}/netD_epoch_{1}.pth'.format(name, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    " noise = torch.randn(batch_size, nz)\n",
    "if cuda: \n",
    "    noise = noise.cuda()\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(165671)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gen_iterations = 0\n",
    "# for epoch in range(epochs):\n",
    "# #     data_iter = iter(data_loader)\n",
    "#     i = 0\n",
    "#     while i < 10:\n",
    "#         ############################\n",
    "#         # (1) Update D network\n",
    "#         ###########################\n",
    "#         for p in netD.parameters(): # reset requires_grad\n",
    "#             p.requires_grad = True # they are set to False below in netG update\n",
    "#         d_iter = d_iter\n",
    "#         j = 0\n",
    "#         while j < d_iter and i < 10:\n",
    "#             j += 1\n",
    "#             # load real data\n",
    "#             i += 1\n",
    "#             X = getRealSample()\n",
    "#             X = X.view(X.size(0), -1).float()\n",
    "# #             X = (X >= 0.5).float()\n",
    "#             if cuda: \n",
    "#                 X = X.cuda()\n",
    "#             real = Variable(X, requires_grad=True)\n",
    "#             # generate fake data\n",
    "#             noise = torch.randn(batch_size, nz)\n",
    "#             if cuda: \n",
    "#                 noise = noise.cuda()\n",
    "#             with torch.no_grad():\n",
    "#                 noisev = Variable(noise) # totally freeze netG\n",
    "#             fake = (Variable(netG(noisev).data, requires_grad=True) > 0.5).float()\n",
    "#             # compute gradient, take step\n",
    "#             netD.zero_grad()\n",
    "#             print(real, fake)\n",
    "#             out = netD(real, fake)\n",
    "# #             print(real.shape, fake.shape, out.shape)\n",
    "#             outputD = torch.mean(out) + lamba * out.norm()\n",
    "#             stdD = torch.std(out)\n",
    "# #             print('outputD.shape', outputD)\n",
    "#             outputD.backward(mone)\n",
    "#             optimizerD.step()\n",
    "# #             break\n",
    "# #         break\n",
    "# #     break\n",
    "\n",
    "#             g_iter = g_iter\n",
    "#             j = 0\n",
    "#             while j < g_iter and i < 10:\n",
    "#                 j += 1\n",
    "#                 for p in netD.parameters():\n",
    "#                     p.requires_grad = False # to avoid computation\n",
    "#                 netG.zero_grad()\n",
    "#                 # load real data\n",
    "#                 i += 1\n",
    "#                 X = getRealSample()\n",
    "#                 X = X.view(X.size(0), -1)\n",
    "# #                 X = (X >= 0.5).float()\n",
    "#                 if cuda: \n",
    "#                     X = X.cuda()\n",
    "#                 real = Variable(X.float(), requires_grad=True)\n",
    "#                 # update generator\n",
    "#                 noise = torch.randn(batch_size, nz)\n",
    "#                 if cuda: \n",
    "#                     noise = noise.cuda()\n",
    "#                 noisev = Variable(noise)\n",
    "#                 fake = Variable((netG(noisev) >=0.5).float(), requires_grad=True)\n",
    "#                 print(\"####\"*40)\n",
    "#                 print('REEEEAL', real)\n",
    "#                 print('FAAAKE', fake)\n",
    "#                 print(\"####\"*40)\n",
    "# #                 print(real.shape, fake.shape)\n",
    "#                 out = netD(real, fake)\n",
    "#                 outputG = torch.mean(out) + lamba * out.norm()\n",
    "#                 stdG = torch.std(out)\n",
    "#                 outputG.backward(one)\n",
    "#                 optimizerG.step()\n",
    "#                 gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f ' % (epoch, epochs, i, 10, gen_iterations, outputD.data.item(), outputG.data.item()))\n",
    "#             print('output_D', outputD.data.item(), gen_iterations)\n",
    "#             print('output_G', outputG.data.item(), gen_iterations)\n",
    "#             print('std_D', stdD.data.item(), gen_iterations)\n",
    "#             print('std_G', stdG.data.item(), gen_iterations)\n",
    "# #             if gen_iterations % 100 == 0:\n",
    "# #                 if not isdir('./images/{0}'.format(name)):\n",
    "# #                     os.mkdir('./images/{0}'.format(name))\n",
    "# #                 real = real.data[0:100,:]\n",
    "# #                 real = real.view(real.size(0), 1, 28, 28)\n",
    "# #                 vutils.save_image(real, './images/{0}/real_samples.png'.format(name, gen_iterations))\n",
    "# #                 noise = torch.randn(min(100, batch_size), nz)\n",
    "# #                 if cuda: \n",
    "# #                     noise = noise.cuda()\n",
    "# #                 fake = netG(Variable(noise, volatile=True))\n",
    "# #                 # fake = (fake.data >= 0.5).float()\n",
    "# #                 R = torch.rand(fake.size())\n",
    "# #                 fake = (fake.data.cpu() >= R).float()\n",
    "# #                 fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "# #                 vutils.save_image(fake, './images/{0}/fake_samples_{1}.png'.format(name, gen_iterations))\n",
    "\n",
    "# #             # do checkpointing\n",
    "# #             if not isdir('./checkpoint/{0}'.format(name)):\n",
    "# #                 os.mkdir('./checkpoint/{0}'.format(name))\n",
    "# #             torch.save(netG.state_dict(), './checkpoint/{0}/netG_epoch_{1}.pth'.format(name, epoch))\n",
    "# #             torch.save(netD.state_dict(), './checkpoint/{0}/netD_epoch_{1}.pth'.format(name, epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
