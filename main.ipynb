{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from matrix_factorization.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter \n",
    "import matrix_factorization\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading Movielens-1m\n",
    "# !curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "# !unzip ml-1m.zip\n",
    "# !cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_list = [i.strip().split(\"::\") for i in open('./ml-1m/ratings.dat', 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open('./ml-1m/users.dat', 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open('./ml-1m/movies.dat', 'r').readlines()]\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1 10 100 1000 1002 1003 1004 1005 1006 1007  ... 99 990 991 992 993  \\\n",
       "UserID                                                ...                      \n",
       "1        5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "10       5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "100      0  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1000     5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1001     4  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "\n",
       "MovieID 994 996 997 998 999  \n",
       "UserID                       \n",
       "1         0   0   0   0   0  \n",
       "10        0   0   0   0   0  \n",
       "100       0   0   0   0   0  \n",
       "1000      0   0   0   0   0  \n",
       "1001      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "R_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(R_df.values, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users = df.user_id.unique().shape[0]\n",
    "# n_items = df.item_id.unique().shape[0]\n",
    "# ratings = np.zeros((n_users, n_items))\n",
    "# for row in df.itertuples():\n",
    "#     ratings[row[1]-1, row[2]-1] = row[3]\n",
    "# ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(R_df.values, dtype=int)\n",
    "n_users = ratings.shape[0]\n",
    "n_items = ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    print (str(n_users) + ' users')\n",
    "    print (str(n_items) + ' items')\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n",
      "Sparsity: 4.47%\n"
     ]
    }
   ],
   "source": [
    "print ('Sparsity: {:4.2f}%'.format(get_sparsity(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=20, replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    \n",
    "#     print(test)\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.9286971547839014"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5396654074473827"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 0.8264795643096374\n",
      "Test mse: 0.9051574489352089\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "iter_array = [10]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####################################### GANS ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise(batch_size):\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.9087e-01, 4.7166e-01, 7.6108e-01, 2.7818e-01, 9.5874e-01, 2.7619e-01,\n",
       "         8.3122e-01, 9.0605e-01, 4.2493e-01, 4.0727e-01, 5.2870e-01, 1.4785e-01,\n",
       "         1.5160e-01, 2.6766e-02, 3.1058e-02, 3.3942e-01, 1.9594e-01, 7.4117e-01,\n",
       "         7.2004e-01, 1.9824e-01, 4.1355e-01, 4.4217e-01, 8.7193e-01, 8.2988e-01,\n",
       "         2.2405e-01, 3.7741e-01, 3.7660e-01, 4.4117e-01, 4.7020e-01, 9.1860e-02,\n",
       "         8.5103e-01, 5.4650e-01, 8.2742e-01, 3.1776e-01, 2.5469e-01, 8.1883e-01,\n",
       "         9.1414e-01, 6.6872e-01, 5.9061e-01, 4.4882e-01, 5.3474e-01, 5.7775e-01,\n",
       "         3.8003e-01, 5.5922e-01, 1.6179e-01, 5.0391e-01, 2.1573e-02, 1.0553e-01,\n",
       "         7.2259e-01, 2.0022e-01, 7.4842e-01, 6.6126e-01, 3.1551e-01, 7.3413e-01,\n",
       "         3.5438e-01, 4.7352e-01, 2.5282e-01, 2.2805e-03, 1.7384e-01, 3.2439e-01,\n",
       "         7.3955e-03, 2.6023e-01, 7.0651e-01, 8.8252e-01, 2.5503e-01, 7.3282e-01,\n",
       "         5.6168e-02, 3.2593e-01, 7.4102e-01, 6.9155e-01, 9.0352e-01, 7.7082e-01,\n",
       "         6.9165e-01, 8.0436e-01, 4.6477e-02, 6.9535e-02, 3.9772e-01, 3.2841e-01,\n",
       "         9.3021e-01, 5.5619e-01, 8.0038e-01, 7.0930e-01, 4.6882e-01, 2.8602e-01,\n",
       "         2.8262e-02, 7.2822e-01, 8.2031e-01, 9.3697e-01, 2.6392e-01, 7.5714e-01,\n",
       "         3.9537e-01, 9.8528e-02, 8.2068e-01, 7.1779e-01, 5.8123e-01, 9.9258e-01,\n",
       "         5.0719e-01, 9.3715e-03, 3.1059e-01, 1.9582e-01],\n",
       "        [4.5603e-01, 4.4059e-01, 1.3257e-01, 2.1449e-01, 2.7675e-01, 4.0060e-01,\n",
       "         5.9426e-01, 4.1409e-01, 2.2185e-01, 8.5188e-01, 7.5981e-01, 4.1670e-01,\n",
       "         5.8729e-02, 1.2002e-01, 6.8294e-01, 7.3015e-02, 1.0128e-01, 5.0454e-01,\n",
       "         2.9343e-01, 6.7433e-01, 7.8408e-01, 4.7579e-01, 6.8841e-01, 2.7263e-01,\n",
       "         2.0737e-01, 9.4758e-01, 6.3934e-01, 9.8403e-01, 7.7811e-01, 9.2589e-01,\n",
       "         9.1965e-02, 2.1043e-01, 8.6199e-01, 9.9470e-01, 3.5912e-01, 3.8841e-01,\n",
       "         6.2285e-02, 2.3586e-01, 3.9007e-01, 5.4870e-02, 2.6999e-01, 8.9009e-01,\n",
       "         4.0224e-01, 2.8819e-02, 9.8359e-01, 7.0778e-01, 4.2612e-01, 3.5103e-01,\n",
       "         9.2330e-01, 6.3978e-01, 5.5197e-01, 5.9493e-01, 9.6142e-01, 7.0851e-01,\n",
       "         4.8250e-01, 6.2462e-01, 3.8196e-01, 3.7133e-03, 6.5281e-01, 5.3264e-01,\n",
       "         5.1582e-01, 6.2954e-01, 9.2982e-02, 6.1012e-01, 3.0707e-01, 6.0629e-01,\n",
       "         2.1707e-01, 5.5856e-01, 4.3100e-01, 5.3781e-01, 2.9018e-01, 5.0322e-01,\n",
       "         4.1787e-01, 9.4353e-01, 7.5312e-01, 3.8876e-01, 9.6582e-01, 6.0739e-01,\n",
       "         2.9232e-01, 6.4900e-01, 2.4837e-01, 9.5175e-01, 8.7363e-01, 9.4434e-01,\n",
       "         9.0766e-01, 5.3588e-01, 2.4300e-01, 7.2983e-01, 9.8254e-01, 6.5348e-01,\n",
       "         7.0729e-01, 7.5876e-02, 1.6777e-01, 8.4883e-01, 4.2089e-01, 5.5966e-01,\n",
       "         5.8115e-02, 2.0696e-01, 7.7771e-01, 7.4970e-02],\n",
       "        [5.7574e-01, 7.6969e-01, 4.6203e-01, 7.3716e-01, 8.8305e-02, 8.4994e-01,\n",
       "         7.5364e-01, 4.2447e-02, 1.5723e-01, 6.3454e-01, 7.2778e-01, 4.4707e-01,\n",
       "         7.6735e-01, 9.1827e-01, 2.1239e-02, 8.2567e-01, 9.1496e-01, 3.6030e-01,\n",
       "         1.9277e-01, 8.4555e-01, 9.0741e-01, 7.0040e-01, 7.3324e-01, 6.9621e-01,\n",
       "         9.3742e-01, 1.5464e-01, 3.2404e-01, 7.7118e-01, 5.7589e-01, 8.6275e-01,\n",
       "         3.1938e-01, 9.7953e-01, 8.5793e-01, 6.0029e-01, 4.5892e-01, 1.9321e-01,\n",
       "         8.8266e-01, 5.7284e-01, 5.7693e-01, 4.1642e-01, 5.5069e-01, 9.1009e-01,\n",
       "         4.3141e-01, 3.4264e-01, 5.2092e-01, 2.7443e-01, 8.5804e-01, 6.7446e-01,\n",
       "         1.4401e-01, 3.5470e-01, 5.6298e-01, 8.0318e-01, 8.0812e-01, 4.7493e-01,\n",
       "         3.2433e-01, 3.9131e-02, 8.0230e-01, 1.7857e-01, 6.4314e-01, 6.1689e-02,\n",
       "         3.4603e-02, 8.0279e-01, 6.6976e-01, 7.3792e-01, 6.5281e-01, 5.3425e-01,\n",
       "         8.7788e-01, 2.7730e-01, 4.0789e-01, 8.5892e-01, 1.0590e-01, 2.7147e-01,\n",
       "         2.1162e-01, 3.2432e-01, 7.2351e-01, 6.3412e-01, 1.7215e-01, 9.8317e-01,\n",
       "         6.7327e-01, 9.0481e-01, 4.1524e-02, 3.4897e-01, 9.6506e-01, 7.4064e-01,\n",
       "         5.3076e-01, 3.9177e-01, 6.0569e-01, 4.9309e-01, 6.4493e-01, 2.8164e-01,\n",
       "         6.7727e-01, 1.6420e-01, 8.9878e-01, 7.1052e-01, 8.0969e-01, 1.6342e-01,\n",
       "         8.7838e-01, 1.0847e-01, 8.2159e-01, 9.5224e-01],\n",
       "        [4.0637e-01, 6.9774e-02, 2.7488e-01, 7.8498e-01, 4.4901e-01, 8.9884e-04,\n",
       "         7.7224e-01, 8.1313e-01, 7.3203e-01, 4.0392e-01, 3.7242e-01, 5.8892e-01,\n",
       "         5.4650e-02, 4.8195e-01, 7.5096e-01, 2.0419e-02, 4.4030e-01, 2.8836e-02,\n",
       "         5.8778e-01, 9.3965e-01, 6.9269e-01, 5.9133e-01, 5.5590e-01, 1.6480e-01,\n",
       "         4.4390e-01, 3.4926e-01, 9.1932e-01, 9.8443e-01, 8.8910e-01, 5.9352e-01,\n",
       "         2.8050e-01, 2.0145e-01, 9.2938e-01, 9.6515e-01, 6.2197e-01, 1.0540e-01,\n",
       "         5.8734e-01, 1.0168e-01, 4.6208e-01, 7.4890e-01, 2.9285e-01, 3.8374e-01,\n",
       "         4.9099e-01, 5.2664e-01, 3.6518e-01, 8.4046e-02, 5.9651e-01, 6.6324e-01,\n",
       "         3.7879e-01, 1.0828e-02, 3.1396e-01, 7.6683e-01, 2.1401e-01, 6.7893e-01,\n",
       "         3.8942e-01, 3.8130e-01, 3.3931e-01, 8.9351e-01, 3.5441e-01, 7.0339e-01,\n",
       "         8.2273e-01, 1.3833e-01, 4.8323e-01, 8.7335e-01, 5.4855e-01, 2.1421e-01,\n",
       "         1.1807e-01, 3.9695e-01, 9.4058e-01, 1.3335e-01, 6.5741e-01, 3.1164e-01,\n",
       "         7.9342e-01, 7.8973e-01, 5.0522e-01, 1.0733e-02, 9.0095e-01, 2.7675e-01,\n",
       "         3.8374e-01, 8.8321e-01, 1.0189e-01, 2.6590e-01, 1.2687e-01, 8.9056e-01,\n",
       "         6.1597e-01, 3.1341e-01, 9.6614e-01, 4.7151e-01, 4.5665e-01, 7.4571e-01,\n",
       "         6.8417e-01, 3.2121e-01, 8.6801e-01, 3.1110e-01, 3.9683e-01, 8.7903e-01,\n",
       "         9.7222e-01, 5.4637e-01, 7.5502e-01, 2.8078e-01],\n",
       "        [2.0280e-03, 6.3606e-01, 5.2879e-01, 5.9796e-01, 8.4140e-01, 9.9183e-01,\n",
       "         2.7764e-01, 4.8509e-01, 1.2775e-01, 5.8362e-01, 3.7390e-01, 8.0610e-02,\n",
       "         8.8844e-01, 6.7970e-01, 6.3985e-01, 2.4550e-01, 3.4510e-01, 3.4702e-01,\n",
       "         6.5995e-01, 5.7150e-01, 5.8072e-01, 7.3564e-01, 6.1739e-01, 5.1921e-02,\n",
       "         2.3109e-01, 7.3608e-01, 8.6165e-01, 2.1416e-01, 4.5331e-01, 1.3849e-02,\n",
       "         3.2948e-01, 2.4363e-01, 2.0339e-01, 4.1468e-01, 8.4208e-01, 1.9656e-01,\n",
       "         1.2512e-01, 5.5842e-01, 4.6127e-01, 6.3279e-01, 4.5586e-01, 4.8761e-01,\n",
       "         2.8438e-01, 1.3862e-01, 3.0616e-01, 3.0719e-01, 8.6389e-01, 9.4456e-01,\n",
       "         4.4520e-01, 8.5870e-02, 8.0512e-01, 9.8901e-01, 3.6303e-01, 1.5089e-01,\n",
       "         5.7699e-01, 4.9942e-01, 8.9012e-01, 5.9930e-01, 6.1743e-01, 8.5792e-01,\n",
       "         7.4176e-01, 6.0984e-01, 7.5671e-01, 2.8793e-01, 8.7780e-01, 6.0356e-01,\n",
       "         5.6511e-01, 7.0510e-01, 8.2713e-01, 7.4421e-01, 7.8438e-01, 2.3704e-01,\n",
       "         2.8797e-01, 8.0298e-01, 9.6330e-01, 5.6915e-01, 9.3882e-02, 2.6092e-01,\n",
       "         4.7509e-01, 3.0220e-02, 1.5364e-01, 9.9683e-01, 5.0253e-01, 5.6453e-01,\n",
       "         9.4829e-01, 3.1578e-01, 8.5781e-01, 7.7947e-01, 8.5155e-01, 2.7782e-01,\n",
       "         6.5856e-01, 5.2656e-01, 2.6894e-01, 3.8657e-01, 6.7730e-01, 7.0895e-01,\n",
       "         9.5540e-01, 7.5213e-01, 1.7001e-01, 4.6329e-02]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_some_noise(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator class\n",
    "\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(800,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining discriminator class\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(inp,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(200,out),\n",
    "                                 nn.Sigmoid()\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(ratings.shape[1], 1)\n",
    "gen = generator(100, ratings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=3706, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=300, out_features=1000, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=800, out_features=3706, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_steps = 300\n",
    "g_steps = 300\n",
    "\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# printing_steps = 200\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]\n",
    "    \n",
    "get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g):\n",
    "    return torch.sum(torch.abs((x_r != 0).float() * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1. my distance between random real and fake samples 23078.8125\n",
      "Epoch number 2. my distance between random real and fake samples 18446.626953125\n",
      "Epoch number 3. my distance between random real and fake samples 26139.904296875\n",
      "Epoch number 4. my distance between random real and fake samples 23025.72265625\n",
      "Epoch number 5. my distance between random real and fake samples 22489.875\n",
      "Epoch number 6. my distance between random real and fake samples 23995.0390625\n",
      "Epoch number 7. my distance between random real and fake samples 16837.49609375\n",
      "Epoch number 8. my distance between random real and fake samples 21242.859375\n",
      "Epoch number 9. my distance between random real and fake samples 25866.9296875\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "eval_losses = []\n",
    "for epoch in range(10):\n",
    "#     print (epoch)\n",
    "\n",
    "    # training discriminator\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()\n",
    "        \n",
    "        # training discriminator on real data\n",
    "        real_rows = get_random_batch(train, batch_size)\n",
    "        discriminator_real_outputs = dis(real_rows)\n",
    "   \n",
    "        dis_real_loss = criteriond1(discriminator_real_outputs, Variable(torch.ones(batch_size,1)))\n",
    "    \n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # training discriminator on data produced by generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        #output from generator is generated        \n",
    "        fake_rows = gen(z_vector).detach()\n",
    "#         print(fake_rows[:20])\n",
    "        dis_fake_out = dis(fake_rows)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out, Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()\n",
    "        \n",
    "    # training generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()\n",
    "        \n",
    "        #generating data for input for generator\n",
    "        z_vector = make_some_noise(batch_size)\n",
    "        \n",
    "        fake_rows = gen(z_vector)\n",
    "#         print(fake_rows.shape, z_vector.shape)\n",
    "#         print(fake_rows[:20])\n",
    "        dis_out_gen_training = dis(fake_rows)\n",
    "        gen_loss = criteriond2(dis_out_gen_training, Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()\n",
    "\n",
    "    # evaluation\n",
    "    if epoch % 10: # todo- to change\n",
    "        gen.eval()\n",
    "        z_vector_eval = make_some_noise(128)\n",
    "        fake_rows_eval = gen(z_vector_eval)\n",
    "        real_rows_eval = get_random_batch(train, 128)\n",
    "#         print(fake_rows[0][:10]) enable to see some results\n",
    "        eval_loss = F.mse_loss(fake_rows_eval, real_rows_eval, reduction='mean')\n",
    "        eval_losses.append(eval_loss)\n",
    "#         print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))\n",
    "        print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real_rows_eval, fake_rows_eval)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vector = make_some_noise(16)\n",
    "fake_rows = gen(z_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.7839, 1.3372, 1.5696, 0.3010, 3.4508, 2.9964, 1.8445, 0.5438, 2.5319],\n",
       "        [4.7814, 1.3440, 1.5614, 0.3005, 3.4848, 2.9974, 1.8390, 0.5465, 2.5136],\n",
       "        [4.7851, 1.3195, 1.5691, 0.2962, 3.4672, 3.0037, 1.8446, 0.5386, 2.5608],\n",
       "        [4.7865, 1.3228, 1.5674, 0.2956, 3.4987, 3.0116, 1.8382, 0.5415, 2.5436],\n",
       "        [4.7728, 1.3346, 1.5653, 0.3049, 3.4598, 2.9856, 1.8475, 0.5580, 2.5524],\n",
       "        [4.7883, 1.3013, 1.5608, 0.2855, 3.4821, 3.0073, 1.8286, 0.5240, 2.5446],\n",
       "        [4.7800, 1.3553, 1.5673, 0.3034, 3.4711, 3.0002, 1.8441, 0.5500, 2.5217],\n",
       "        [4.7758, 1.3597, 1.5698, 0.3123, 3.4438, 2.9835, 1.8499, 0.5577, 2.5273],\n",
       "        [4.7905, 1.3076, 1.5613, 0.2919, 3.4790, 3.0230, 1.8180, 0.5317, 2.5509],\n",
       "        [4.7840, 1.3282, 1.5661, 0.2939, 3.4696, 2.9958, 1.8501, 0.5365, 2.5545],\n",
       "        [4.7814, 1.3119, 1.5574, 0.2974, 3.4828, 3.0047, 1.8491, 0.5453, 2.5302],\n",
       "        [4.7870, 1.3177, 1.5767, 0.2928, 3.4848, 2.9970, 1.8488, 0.5350, 2.5593],\n",
       "        [4.7873, 1.3214, 1.5557, 0.2891, 3.4867, 3.0116, 1.8451, 0.5346, 2.5404],\n",
       "        [4.7777, 1.3228, 1.5700, 0.3045, 3.4645, 2.9844, 1.8492, 0.5577, 2.5506],\n",
       "        [4.7807, 1.3363, 1.5675, 0.2931, 3.4829, 3.0027, 1.8476, 0.5395, 2.5561],\n",
       "        [4.7765, 1.3367, 1.5636, 0.3055, 3.4688, 3.0075, 1.8417, 0.5485, 2.5267]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we see generator produces very similar vectors \n",
    "fake_rows[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os\n",
    "# from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c6b58b6db0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 100\n",
    "cuda = True\n",
    "epochs = 300 #change\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-2 # constant for L2 penalty (diversity)\n",
    "name = \"mnist-experiment\"\n",
    "# configure(\"runs/run-\" + args.name, flush_secs=5)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#     transform=transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length=6\n",
    "# batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-346e466c3bc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'features_length' is not defined"
     ]
    }
   ],
   "source": [
    "features_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Dropout(p=0.5)\n",
      "  )\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(features_length, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(features_length, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, features_length)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        filt = (torch.abs((real != 0).float() * fake - real))/real.shape[0]\n",
    "#         filt = torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda())\n",
    "#         filt = torch.abs((xr != 0).int() * xf - xr)\n",
    "#         filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "#         print(filt.type(), x.type())\n",
    "        x = filt * x\n",
    "\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, features_length),\n",
    "#     torch.nn.Sigmoid()*5\n",
    "#     )\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(nz,1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024,features_length),\n",
    "                                 nn.Sigmoid(),\n",
    "                                 nn.Dropout(0.5)\n",
    "                                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x*5 # to get values in range [0,5]\n",
    "    \n",
    "# networks\n",
    "netD = NetD(use_cuda=False)\n",
    "netG = NetG()\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "cuda = False\n",
    "if cuda is True:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(length=6):\n",
    "     return Variable(torch.IntTensor(np.random.choice([0, 1], size=(batch_size, length))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3706])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_batch(train, batch_size=batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 5. my distance between random real and fake samples 30489.251953125\n",
      "Epoch number 11. my distance between random real and fake samples 39576.18359375\n",
      "Epoch number 17. my distance between random real and fake samples 36241.203125\n",
      "Epoch number 23. my distance between random real and fake samples 27993.5\n",
      "Epoch number 29. my distance between random real and fake samples 28787.44921875\n",
      "Epoch number 35. my distance between random real and fake samples 24984.685546875\n",
      "Epoch number 41. my distance between random real and fake samples 40185.18359375\n",
      "Epoch number 47. my distance between random real and fake samples 35311.5546875\n",
      "Epoch number 52. my distance between random real and fake samples 27436.328125\n",
      "Epoch number 58. my distance between random real and fake samples 28843.56640625\n",
      "Epoch number 64. my distance between random real and fake samples 28300.921875\n",
      "Epoch number 70. my distance between random real and fake samples 27582.216796875\n",
      "Epoch number 76. my distance between random real and fake samples 27650.404296875\n",
      "Epoch number 82. my distance between random real and fake samples 31584.421875\n",
      "Epoch number 88. my distance between random real and fake samples 32087.50390625\n",
      "Epoch number 94. my distance between random real and fake samples 30407.861328125\n",
      "Epoch number 99. my distance between random real and fake samples 31035.06640625\n",
      "Epoch number 105. my distance between random real and fake samples 27257.513671875\n",
      "Epoch number 111. my distance between random real and fake samples 38657.578125\n",
      "Epoch number 117. my distance between random real and fake samples 33206.68359375\n",
      "Epoch number 123. my distance between random real and fake samples 26788.51953125\n",
      "Epoch number 129. my distance between random real and fake samples 23870.572265625\n",
      "Epoch number 135. my distance between random real and fake samples 33048.71484375\n",
      "Epoch number 141. my distance between random real and fake samples 32545.708984375\n",
      "Epoch number 147. my distance between random real and fake samples 29579.95703125\n",
      "Epoch number 152. my distance between random real and fake samples 36504.578125\n",
      "Epoch number 158. my distance between random real and fake samples 33535.796875\n",
      "Epoch number 164. my distance between random real and fake samples 25450.138671875\n",
      "Epoch number 170. my distance between random real and fake samples 34874.0546875\n",
      "Epoch number 176. my distance between random real and fake samples 41279.29296875\n",
      "Epoch number 182. my distance between random real and fake samples 32056.283203125\n",
      "Epoch number 188. my distance between random real and fake samples 28893.962890625\n",
      "Epoch number 194. my distance between random real and fake samples 32975.33203125\n",
      "Epoch number 199. my distance between random real and fake samples 31420.701171875\n",
      "Epoch number 205. my distance between random real and fake samples 36088.26953125\n",
      "Epoch number 211. my distance between random real and fake samples 29691.4140625\n",
      "Epoch number 217. my distance between random real and fake samples 31565.84765625\n",
      "Epoch number 223. my distance between random real and fake samples 28345.87109375\n",
      "Epoch number 229. my distance between random real and fake samples 30140.97265625\n",
      "Epoch number 235. my distance between random real and fake samples 31079.31640625\n",
      "Epoch number 241. my distance between random real and fake samples 32521.4765625\n",
      "Epoch number 247. my distance between random real and fake samples 34961.77734375\n",
      "Epoch number 252. my distance between random real and fake samples 36526.84375\n",
      "Epoch number 258. my distance between random real and fake samples 23903.0546875\n",
      "Epoch number 264. my distance between random real and fake samples 29689.0234375\n",
      "Epoch number 270. my distance between random real and fake samples 36104.54296875\n",
      "Epoch number 276. my distance between random real and fake samples 38535.2734375\n",
      "Epoch number 282. my distance between random real and fake samples 32332.603515625\n",
      "Epoch number 288. my distance between random real and fake samples 33229.99609375\n",
      "Epoch number 294. my distance between random real and fake samples 28286.24609375\n",
      "Epoch number 299. my distance between random real and fake samples 46204.890625\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "gen_iterations = 0\n",
    "eval_losses = []\n",
    "for epoch in range(epochs):\n",
    "#     data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < steps_per_epoch:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter:\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "#             X, _ = data_iter.next()\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             print(X >= 0.5)\n",
    "# #             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "#             print(real.shape, fake.shape)\n",
    "    \n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real)\n",
    "#             print('fake', fake[:,0].sum())\n",
    "            out = netD(real, fake)\n",
    "            \n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "#             print(out.shape)\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter:\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "#             print('output_D', outputD.item(), gen_iterations)\n",
    "#             print('output_G', outputG.item(), gen_iterations)\n",
    "#             print('std_D', stdD.item(), gen_iterations)\n",
    "#             print('std_G', stdG.item(), gen_iterations)\n",
    "            \n",
    "            # evaluation\n",
    "            if gen_iterations % 100 == 0: # todo- to change\n",
    "#                 gen.eval()\n",
    "#                 z_vector_eval = make_some_noise(128)\n",
    "#                 fake_rows_eval = gen(z_vector_eval)\n",
    "#                 real_rows_eval = get_random_batch(train, 128)\n",
    "        #         print(fake_rows[0][:10]) enable to see some results\n",
    "                eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "                eval_losses.append(eval_loss)\n",
    "                print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real, fake)))\n",
    "#                 print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda()).cuda().type()\n",
    "torch.abs((real != 0).float() * fake - real).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = ratings.shape[0]\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, nz)\n",
    "if cuda: \n",
    "    noise = noise.cuda()\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 tensor(435426) 226310\n",
      "4 tensor(4807224) 348971\n",
      "3 tensor(4499286) 261197\n",
      "2 tensor(1158403) 107557\n",
      "1 tensor(193166) 56174\n",
      "0 tensor(11191494) 21384031\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == ratings.round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == ratings.round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == ratings.round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == ratings.round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == ratings.round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == ratings.round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11191494 > 21384031\n",
    "fake_ratings = fake.detach().int().numpy().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 0, ..., 3, 0, 3],\n",
       "       [4, 3, 0, ..., 3, 3, 3],\n",
       "       [3, 3, 2, ..., 3, 0, 0],\n",
       "       ...,\n",
       "       [4, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 2, ..., 3, 3, 3],\n",
       "       [0, 0, 2, ..., 0, 3, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040, 3706), (6040, 3706))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11191494 > 21384031\n",
    "fake_ratings.shape, ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.93718795009346"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(fake_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468362562231285"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(ratings.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_fake = fake_ratings[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, 0, 4, 3, 4, 0, 0, 0, 4, 4, 4, 3, 0, 4, 4, 4, 4, 4, 0, 0,\n",
       "       4, 0, 4, 0, 4, 0, 0, 0, 0, 4, 4, 4, 4, 3, 4, 3, 4, 3, 3, 0, 0, 0,\n",
       "       4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4, 3, 4, 4, 0, 4, 4, 4, 4, 4,\n",
       "       0, 4, 4, 3, 4, 0, 3, 4, 0, 4, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 4, 4,\n",
       "       4, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 4, 3,\n",
       "       3, 4, 0, 0, 3, 3, 3, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0,\n",
       "       4, 0, 0, 3, 4, 3, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 0, 0, 0, 0, 4, 0,\n",
       "       0, 0, 0, 0, 3, 4, 4, 0, 4, 0, 0, 0, 4, 3, 4, 4, 4, 0, 0, 4, 3, 4,\n",
       "       4, 0, 0, 0, 0, 4, 0, 4, 4, 3, 4, 4, 0, 4, 0, 4, 0, 0, 0, 4, 4, 0,\n",
       "       3, 0, 0, 4, 4, 4, 3, 0, 4, 4, 0, 3, 0, 4, 4, 0, 0, 0, 4, 4, 4, 4,\n",
       "       4, 0, 4, 0, 0, 0, 4, 4, 3, 0, 0, 0, 0, 4, 4, 0, 3, 0, 0, 4, 0, 0,\n",
       "       0, 0, 4, 3, 0, 0, 4, 4, 0, 0, 4, 4, 4, 3, 3, 0, 0, 0, 0, 4, 0, 4,\n",
       "       0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 4, 3,\n",
       "       4, 0, 0, 0, 3, 0, 0, 4, 4, 4, 0, 0, 4, 0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adding_fake[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3, 2, 3, 0, 3, 0, 0, 3, 3, 3,\n",
       "       0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0,\n",
       "       3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 0, 3, 3, 0, 0, 2, 0,\n",
       "       2, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 0, 3, 0,\n",
       "       0, 3, 2, 3, 2, 3, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 2, 3, 3, 3, 3, 2,\n",
       "       0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 3, 2, 0, 3, 3, 0, 0, 0, 3, 0, 0, 3,\n",
       "       3, 3, 0, 2, 0, 0, 3, 3, 2, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3,\n",
       "       3, 0, 3, 3, 2, 3, 2, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 2, 0,\n",
       "       3, 0, 0, 3, 3, 0, 3, 3, 0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 3, 0,\n",
       "       2, 3, 0, 3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3,\n",
       "       3, 3, 2, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 3, 3, 0, 0,\n",
       "       0, 2, 3, 0, 0, 0, 3, 3, 3, 2, 0, 0, 3, 0, 2, 3, 2, 3, 3, 0, 3, 3,\n",
       "       3, 3, 0, 3, 0, 0, 2, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2,\n",
       "       0, 3, 0, 3, 3, 3, 0, 3, 0, 0, 2, 2, 3, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adding_fake[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040, 3706), (300, 3706))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape, adding_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat = np.append(ratings, adding_fake, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6340, 3706)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3706 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.622056312467974"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1890)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake[0] < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3653"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ratings[0] < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 == fake.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 == ratings.round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_row(n=10):\n",
    "    elements = [0, 1, 2, 3, 4, 5]\n",
    "    probabilities = [0.5, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "    return np.random.choice(elements, 10, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_dwgan(x_r, x_g):\n",
    "    return sum(x_r != x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g):\n",
    "    return np.sum(np.abs((x_r != 0).astype(int) * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_1 = np.array([0, 0, 3, 0, 4, 0, 0, 0, 0, 0])\n",
    "\n",
    "x_r_2 = np.array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0])\n",
    "x_g_2 = np.array([0, 5, 3, 0, 4, 4, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_1, x_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_2, x_g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_1, x_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r_2, x_g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r = random_row(n=10)\n",
    "x_g = random_row(n=10)\n",
    "\n",
    "print('x real', x_r)\n",
    "print('x gen ', x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dwgan(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_my(x_r, x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
