{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from dataLoader import loadData\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading Movielens-1m\n",
    "# !curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "# #     http://www.grouplens.org/system/files/ml-1m.zip\n",
    "# !unzip ml-1m.zip\n",
    "# !cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data...\n",
      "data read in 5.629438877105713 seconds\n",
      "loaded dense data matrix\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "tr, vr = loadData('./ml-1m/ratings.dat', delimiter='::', seed=seed, transpose=False, valfrac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./tr_movielens_1m', tr)\n",
    "np.save('./vr_movielens_1m', vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [3., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.021525859265269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44683670296601535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "############## Pytorch model doesn't converge - to do - check #################\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "def autoEncoder(X):\n",
    "    '''\n",
    "    Autoencoder for Collaborative Filter Model\n",
    "    '''\n",
    "\n",
    "    # Input\n",
    "    input_layer = Input(shape=(X.shape[1],), name='UserScore')\n",
    "    \n",
    "    # Encoder\n",
    "    # -----------------------------\n",
    "    enc = Dense(512, activation='selu', name='EncLayer1', kernel_regularizer=regularizers.l2(0.000001))(input_layer)\n",
    "\n",
    "    # Latent Space\n",
    "    # -----------------------------\n",
    "    lat_space = Dense(512, activation='selu', name='LatentSpace', kernel_regularizer=regularizers.l2(0.000001))(enc)\n",
    "    lat_space = Dropout(0.5, name='Dropout')(lat_space) # Dropout\n",
    "\n",
    "    # Decoder\n",
    "    # -----------------------------\n",
    "    dec = Dense(512, activation='selu', name='DecLayer1', kernel_regularizer=regularizers.l2(0.000001))(lat_space)\n",
    "\n",
    "    # Output\n",
    "    output_layer = Dense(X.shape[1], activation='linear', name='UserScorePred', kernel_regularizer=regularizers.l2(0.000001))(dec)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    model = Model(input_layer, output_layer)    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mask = (train == 0)\n",
    "positive_feedback_mask = (train > 3)\n",
    "negative_feedback_mask = ((train < 4) * (1 - zero_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (positive_feedback_mask + negative_feedback_mask != zero_mask).all()\n",
    "assert (positive_feedback_mask + negative_feedback_mask == 1 - zero_mask).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95.97847414073473, 2.3124349989099473, 1.7090908603553212)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(zero_mask), get_sparsity(positive_feedback_mask), get_sparsity(negative_feedback_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.021525859265267, 2.3124349989099473, 1.7090908603553212, 4.021525859265268)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 - get_sparsity(zero_mask), get_sparsity(positive_feedback_mask), get_sparsity(negative_feedback_mask), get_sparsity(positive_feedback_mask) + get_sparsity(negative_feedback_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.4\n",
    "mask_arr_neg = (np.random.rand(negative_feedback_mask.shape[0], negative_feedback_mask.shape[1]) > P)\n",
    "y_neg = negative_feedback_mask\n",
    "X_neg = negative_feedback_mask*mask_arr_neg # corrupting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr_pos = (np.random.rand(positive_feedback_mask.shape[0], positive_feedback_mask.shape[1]) > P)\n",
    "y_pos = positive_feedback_mask\n",
    "X_pos = positive_feedback_mask*mask_arr_pos # corrupting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.026195215919772, 1.7090908603553212, 1.3870741200058612, 2.3124349989099473)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(X_neg), get_sparsity(y_neg), get_sparsity(X_pos), get_sparsity(y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neg = autoEncoder(X_neg)\n",
    "model_neg.compile(optimizer = Adam(lr=0.0001), loss='mse')\n",
    "\n",
    "model_pos = autoEncoder(X_pos)\n",
    "model_pos.compile(optimizer = Adam(lr=0.0001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neg = keras.models.load_model('./model_neg')\n",
    "model_pos = keras.models.load_model('./model_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "UserScore (InputLayer)       [(None, 3706)]            0         \n",
      "_________________________________________________________________\n",
      "EncLayer1 (Dense)            (None, 512)               1897984   \n",
      "_________________________________________________________________\n",
      "LatentSpace (Dense)          (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "DecLayer1 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "UserScorePred (Dense)        (None, 3706)              1901178   \n",
      "=================================================================\n",
      "Total params: 4,324,474\n",
      "Trainable params: 4,324,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_neg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_tr = np.load('predicted_tr.npy')\n",
    "# augmented_train = np.load('augmented_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_neg = model_neg.fit(x=X_neg, y=y_neg,\n",
    "                  epochs=300,\n",
    "                  batch_size=128,\n",
    "                  shuffle=True,\n",
    "# augmented_train = np.load('augmented_train.npy')\n",
    "                  validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_pos = model_pos.fit(x=X_pos, y=y_pos,\n",
    "                  epochs=300,\n",
    "                  batch_size=128,\n",
    "                  shuffle=True,\n",
    "                  validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_hist(hist):\n",
    "    # summarize history for loss\n",
    "    fig, ax = plt.subplots()  # create figure & 1 axis\n",
    "\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    plt.plot(hist.history['loss'])\n",
    "    #plt.plot(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neg.save('./model_neg')\n",
    "model_pos.save('./model_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "predicted_neg = model_neg.predict(X_neg)\n",
    "predicted_pos = model_pos.predict(X_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170143, 382567)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_neg > 0.4).sum(), (y_neg == 1).sum() # predicted vs real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115775, 214496)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_neg>0.5).sum(), (predicted_pos>0.5).sum() # trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9528337927508037\n",
      "0.9187441580985445\n"
     ]
    }
   ],
   "source": [
    "print((y_neg * (predicted_neg>0.4)).sum()/(predicted_neg>0.4).sum()) # accuracy on actual \n",
    "print((y_pos * (predicted_pos>0.4)).sum()/(predicted_pos>0.4).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004936043939484681\n",
      "0.016499070751005707\n"
     ]
    }
   ],
   "source": [
    "print((y_pos * (predicted_neg>0.4)).sum()/(y_pos>0.4).sum()) # just to see that it's a low number\n",
    "print((y_neg * (predicted_pos>0.4)).sum()/(y_neg>0.4).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9862405527963722"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_neg * (predicted_neg>0.5)).sum()/((predicted_neg>0.5).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698642398925854"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pos * (predicted_pos>0.5)).sum()/((predicted_pos>0.5).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39637"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((predicted_neg>0.5)  * (X_neg<0.5)).sum() # predicted values which were not in the train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69892"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((predicted_pos>0.5)  * (X_pos<0.5)).sum() # predicted values which were not in the train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598102782753488"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_neg * (((predicted_neg>0.5)  * (X_neg<0.5)))) == 1).sum()/(((predicted_neg>0.5)  * (X_neg<0.5))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075144508670521"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_pos * (((predicted_pos>0.5)  * (X_pos<0.5)))) == 1).sum()/(((predicted_pos>0.5)  * (X_pos<0.5))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add_negative = model_neg.predict(y_neg)\n",
    "to_add_positive = model_neg.predict(y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207742, 234140)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(to_add_negative>0.5).sum(), (to_add_positive>0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9874735206891682, 0.9078462031914041)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_neg* (to_add_negative>0.8)).sum()/(((to_add_negative>0.8)).sum()), (y_pos* (to_add_positive>0.8)).sum()/(((to_add_positive>0.8)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep the balance\n",
    "threshold_neg = 0.2\n",
    "threshold_pos = 0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345157, 240626)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((to_add_negative > threshold_neg) * (tr==0)).sum(), ((to_add_positive > threshold_pos) * (tr==0)).sum() # new values # new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13207882540835983, 0.25313474502505445, 0.6147864295665857]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_probs_neg = [(tr == 1).sum()/((tr > 0) & (tr < 4)).sum(), (tr == 2).sum()/(((tr > 0) & (tr < 4))).sum(), (tr == 3).sum()/((tr > 0) & (tr < 4)).sum()]\n",
    "p_probs_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6064147320143503, 0.39358526798564974]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_probs_pos = [(tr == 4).sum()/((tr > 3) & (tr <= 5)).sum(), (tr == 5).sum()/((tr > 3) & (tr <= 5)).sum()]\n",
    "p_probs_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train = tr + (to_add_negative > threshold_neg) * (tr == 0) * np.random.choice(np.arange(1, 4), tr.shape, p=p_probs_neg) + (to_add_positive > threshold_pos) * (tr == 0) * np.random.choice(np.arange(4, 6), tr.shape, p=p_probs_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.021525859265269, 6.412851184583439)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(tr), get_sparsity(augmented_train) # reduced sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.isin(tr, augmented_train)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 203728\n",
      "4 313893\n",
      "3 235197\n",
      "2 96841\n",
      "1 50529\n",
      "0 21484052\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == tr).sum())\n",
    "print(4, (4 == tr).sum())\n",
    "print(3, (3 == tr).sum())\n",
    "print(2, (2 == tr).sum())\n",
    "print(1, (1 == tr).sum())\n",
    "print(0, (0 == tr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 282704\n",
      "4 429003\n",
      "3 416147\n",
      "2 171461\n",
      "1 89613\n",
      "0 20948772\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == augmented_train).sum())\n",
    "print(4, (4 == augmented_train).sum())\n",
    "print(3, (3 == augmented_train).sum())\n",
    "print(2, (2 == augmented_train).sum())\n",
    "print(1, (1 == augmented_train).sum())\n",
    "print(0, (0 == augmented_train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535280"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((tr == 0) * (augmented_train > 0)).sum() # new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('predicted_tr', predicted_tr)\n",
    "np.save('augmented_train', augmented_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, feat_size):\n",
    "        super(NetD, self).__init__()\n",
    "        self.feat_size = feat_size\n",
    "#         self.use_cuda = True\n",
    "#         self.feat_size = feat_size\n",
    "        # top\n",
    "#         print(self.feat_size*2)\n",
    "        self.t1 = torch.nn.Linear(self.feat_size, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(self.feat_size, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, self.feat_size)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        \n",
    "        filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "#         if self.use_cuda: \n",
    "        idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = F.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "        x = filt * x\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self, feat_size):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "        self.feat_size = feat_size\n",
    "        self.netGen = torch.nn.Sequential( \n",
    "                                torch.nn.Linear(nz + self.feat_size, 1024), \n",
    "#                                 torch.nn.BatchNorm1d(1024),\n",
    "                                torch.nn.ReLU(), \n",
    "#                                 nn.Dropout(0.5),\n",
    "#                                 torch.nn.Linear(1024, 1024),\n",
    "# #                                 torch.nn.BatchNorm1d(1024),\n",
    "#                                 torch.nn.ReLU(), \n",
    "#                                 nn.Dropout(0.6),\n",
    "                                torch.nn.Linear(1024, features_length), \n",
    "                                torch.nn.Sigmoid()\n",
    "#                                 torch.nn.BatchNorm1d(features_length),\n",
    "#                                 nn.Dropout(0.7),\n",
    "#                                 torch.nn.Sigmoid()\n",
    "                                )\n",
    "\n",
    "        \n",
    "    def forward(self, e_mask, x):\n",
    "        x = self.netGen(x)\n",
    "        x = x * e_mask\n",
    "        return x\n",
    "#         return F.dropout(x, 0.7)\n",
    "#         return 5 * self.netGen(x)\n",
    "#         return torch.sigmoid(x) \n",
    "#         return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch(mat, batch_size=64):\n",
    "    '''\n",
    "    returns random rows of size batch_size\n",
    "    '''\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))\n",
    "augmented_train = torch.autograd.Variable(torch.Tensor(augmented_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(train.cpu().numpy()), get_sparsity(augmented_train.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = get_random_batch(train)\n",
    "# xy = get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_my(xx, xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sum(torch.abs(torch.abs(xx != 0).float()*xy - xy), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx > xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def d_my(x_r, x_g): # custom loss -todo\n",
    "# #     return torch.sum(torch.abs((x_r != 0).float() * x_g - x_r), 1)/x_r.shape[1]\n",
    "\n",
    "# def d_my(x_r, x_g): # custom loss -todo\n",
    "#     return torch.sum(torch.abs(x_g - x_r), 1)/x_r.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(corrupted, original, batch_size=64):\n",
    "    rand_rows = np.random.randint(corrupted.shape[0], size=batch_size)\n",
    "    return torch.Tensor(corrupted[rand_rows]).cuda().float(), torch.Tensor(original[rand_rows]).cuda().float()\n",
    "#     return torch.from_numpy(corrupted[rand_rows]).float(), torch.from_numpy(original[rand_rows]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.026195215919772, 1.7090908603553212)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(X_neg), get_sparsity(y_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = batch_generator(X_neg, y_neg)\n",
    "\n",
    "# get_sparsity(a.numpy()), get_sparsity(b.numpy()), a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_losses = []\n",
    "disc_losses = []\n",
    "def train_GAN(netD, netG, negative, steps_per_epoch = 100, epochs = 100):\n",
    "    d_iter = 5\n",
    "    g_iter = 1\n",
    "    gen_iterations = 0\n",
    "#     gen_losses = []\n",
    "#     disc_losses = []\n",
    "#     train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for c in range(steps_per_epoch):\n",
    "            data_iter = 100\n",
    "            i = 0\n",
    "            while i < 100:\n",
    "                ############################\n",
    "                # (1) Update D network\n",
    "                ###########################\n",
    "                for p in netD.parameters(): # reset requires_grad\n",
    "                    p.requires_grad = True # they are set to False below in netG update\n",
    "    #             d_iter = d_iter\n",
    "                j = 0\n",
    "                while j < d_iter*5:\n",
    "                    j += 1\n",
    "                    # load real data\n",
    "                    i += 1\n",
    "                    if negative:\n",
    "                        condition, X = batch_generator(X_neg, y_neg)\n",
    "    #                 X, _ = data_iter.next()\n",
    "    #                 X = X.view(X.size(0), -1)\n",
    "    #                 X = (X >= 0.5).float()\n",
    "                    if cuda: \n",
    "                        X = X.cuda()\n",
    "                        condition = condition.cuda()\n",
    "    #                 print(condition.shape, X_neg.shape, y_neg.shape)\n",
    "                    real = Variable(X)\n",
    "\n",
    "                    # generate fake data\n",
    "                    noise = torch.randn(batch_size, nz)\n",
    "                    if cuda: \n",
    "                        noise = noise.cuda()\n",
    "                    noisev = Variable(noise, volatile = True) # totally freeze netG\n",
    "                    concated = torch.cat((noisev, condition), 1)\n",
    "    #                 print(condition.shape, condition.shape, X.shape, noisev.shape, )\n",
    "                    e_mask = (real == 1).float()\n",
    "                    fake = Variable(netG(e_mask, concated).data)\n",
    "\n",
    "                    # compute gradient, take step\n",
    "                    netD.zero_grad()\n",
    "    #                 concated_real = torch.cat((real, condition), 1)\n",
    "    #                 print(concated_real)\n",
    "                    out = netD(real, fake)\n",
    "                    outputD = torch.mean(out) + lamba * out.norm()\n",
    "                    stdD = torch.std(out)\n",
    "                    outputD.backward(mone)\n",
    "                    optimizerD.step()\n",
    "#                     print('AAAAAAAAA mse:=WWWWWWWWWWWWWWWWWWWWWW')\n",
    "            ############################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "\n",
    "    #         g_iter = g_iter\n",
    "            j = 0\n",
    "            while j < g_iter*5:\n",
    "                j += 1\n",
    "                for p in netD.parameters():\n",
    "                    p.requires_grad = False # to avoid computation\n",
    "                netG.zero_grad()\n",
    "                # load real data\n",
    "\n",
    "                i += 1\n",
    "        #         X, _ = data_iter.next()\n",
    "        #         X = X.view(X.size(0), -1)\n",
    "        #         X = (X >= 0.5).float()\n",
    "                if negative:\n",
    "                    condition, X = batch_generator(X_neg, y_neg)\n",
    "    #             if cuda: \n",
    "                X = X.cuda()\n",
    "                condition = condition.cuda()\n",
    "                real = Variable(X)\n",
    "\n",
    "                # update generator\n",
    "                noise = torch.randn(batch_size, nz)\n",
    "    #             if args.cuda: \n",
    "                noise = noise.cuda()\n",
    "                noisev = Variable(noise)\n",
    "    #             print(condition.shape, X_neg.shape, y_neg.shape, noisev.shape)\n",
    "                concated_ = torch.cat((noisev, condition), 1)\n",
    "    #                 print(condition.shape, condition.shape, X.shape, noisev.shape, )\n",
    "    #             e_mask = Variable((real == 1)).float()\n",
    "    #             e_mask.requires_grad = True\n",
    "    #             fake = Variable(netG(concated, X).data)\n",
    "                e_mask_ = real.clone()\n",
    "    #             concated_.requires_grad = True\n",
    "    #             e_mask_.requires_grad = True\n",
    "#                 real.requires_grad = True\n",
    "#                 fake.requires_grad = True\n",
    "#                 fake = Variable(netG(e_mask_, concated_).data)\n",
    "    #             print((fake > 0).float().sum() == real.float().sum())\n",
    "    #             print(fake)\n",
    "    #             print(real)\n",
    "    #             fake = netG(concated)\n",
    "    #             concated_real = torch.cat((real, condition), 1)\n",
    "                fake = netG(e_mask_, concated_)\n",
    "                out = netD(real, fake)\n",
    "                outputG = torch.mean(out) + lamba * out.norm()\n",
    "                stdG = torch.std(out)\n",
    "                outputG.backward(one)\n",
    "                optimizerG.step()\n",
    "                gen_iterations += 1\n",
    "#             print('AAAAAA')\n",
    "            eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "#             eval_losses.append(eval_loss)\n",
    "#             print('mse:', eval_loss)\n",
    "#             print(outputG.item(), outputD.item())\n",
    "            gen_losses.append(outputG.item())\n",
    "            disc_losses.append(outputD.item())\n",
    "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, 100, gen_iterations, outputD.item(), outputG.item()))\n",
    "    return gen_losses, disc_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.026195215919772, 1.7090908603553212)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(X_neg), get_sparsity(y_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrD = 5e-4\n",
    "# lrG = 5e-4\n",
    "# batch_size = 128\n",
    "# cuda = True\n",
    "# epochs = 1000 #change\n",
    "# seed = 1\n",
    "# nz = 16\n",
    "# d_iter = 5\n",
    "# g_iter = 1\n",
    "# lamba = 2e-4\n",
    "\n",
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 64\n",
    "cuda = True\n",
    "epochs = 100\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 10\n",
    "lamba = 1e-4 \n",
    "# lamba = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_feedback_mask.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n",
      "NetG(\n",
      "  (netGen): Sequential(\n",
      "    (0): Linear(in_features=3716, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# networks\n",
    "netD_neg = NetD(negative_feedback_mask.shape[1]).cuda()\n",
    "netG_neg = NetG(negative_feedback_mask.shape[1]).cuda()\n",
    "print(netD_neg)\n",
    "print(netG_neg)\n",
    "optimizerG = optim.Adam(netG_neg.parameters(), lr=lrG)\n",
    "optimizerD = optim.Adam(netD_neg.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1]).cuda()\n",
    "mone = (-1 * one).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][105/100][5] Loss_D: 0.005486 Loss_G: 0.007582 \n",
      "[0/100][105/100][10] Loss_D: 0.006755 Loss_G: 0.004073 \n",
      "[0/100][105/100][15] Loss_D: 0.004913 Loss_G: 0.002638 \n",
      "[0/100][105/100][20] Loss_D: 0.004872 Loss_G: 0.002772 \n",
      "[0/100][105/100][25] Loss_D: 0.005744 Loss_G: 0.004148 \n",
      "[0/100][105/100][30] Loss_D: 0.003082 Loss_G: 0.002939 \n",
      "[0/100][105/100][35] Loss_D: 0.002823 Loss_G: 0.002135 \n",
      "[0/100][105/100][40] Loss_D: 0.002200 Loss_G: 0.001906 \n",
      "[0/100][105/100][45] Loss_D: 0.002246 Loss_G: 0.002155 \n",
      "[0/100][105/100][50] Loss_D: 0.002869 Loss_G: 0.001899 \n",
      "[0/100][105/100][55] Loss_D: 0.002243 Loss_G: 0.001348 \n",
      "[0/100][105/100][60] Loss_D: 0.002005 Loss_G: 0.002687 \n",
      "[0/100][105/100][65] Loss_D: 0.002238 Loss_G: 0.002617 \n",
      "[0/100][105/100][70] Loss_D: 0.002210 Loss_G: 0.001385 \n",
      "[0/100][105/100][75] Loss_D: 0.002757 Loss_G: 0.002120 \n",
      "[0/100][105/100][80] Loss_D: 0.001869 Loss_G: 0.001889 \n",
      "[0/100][105/100][85] Loss_D: 0.001593 Loss_G: 0.001400 \n",
      "[0/100][105/100][90] Loss_D: 0.002377 Loss_G: 0.000989 \n",
      "[0/100][105/100][95] Loss_D: 0.001585 Loss_G: 0.001708 \n",
      "[0/100][105/100][100] Loss_D: 0.001631 Loss_G: 0.001826 \n",
      "[0/100][105/100][105] Loss_D: 0.001507 Loss_G: 0.001705 \n",
      "[0/100][105/100][110] Loss_D: 0.001790 Loss_G: 0.001214 \n",
      "[0/100][105/100][115] Loss_D: 0.001637 Loss_G: 0.001991 \n",
      "[0/100][105/100][120] Loss_D: 0.001185 Loss_G: 0.001352 \n",
      "[0/100][105/100][125] Loss_D: 0.001194 Loss_G: 0.001769 \n",
      "[0/100][105/100][130] Loss_D: 0.001231 Loss_G: 0.001470 \n",
      "[0/100][105/100][135] Loss_D: 0.001931 Loss_G: 0.002154 \n",
      "[0/100][105/100][140] Loss_D: 0.001445 Loss_G: 0.002522 \n",
      "[0/100][105/100][145] Loss_D: 0.001848 Loss_G: 0.001848 \n",
      "[0/100][105/100][150] Loss_D: 0.002034 Loss_G: 0.002021 \n",
      "[0/100][105/100][155] Loss_D: 0.000913 Loss_G: 0.001848 \n",
      "[0/100][105/100][160] Loss_D: 0.001337 Loss_G: 0.001752 \n",
      "[0/100][105/100][165] Loss_D: 0.001423 Loss_G: 0.001356 \n",
      "[0/100][105/100][170] Loss_D: 0.001062 Loss_G: 0.001465 \n",
      "[0/100][105/100][175] Loss_D: 0.001362 Loss_G: 0.000917 \n",
      "[0/100][105/100][180] Loss_D: 0.001225 Loss_G: 0.001169 \n",
      "[0/100][105/100][185] Loss_D: 0.001124 Loss_G: 0.001041 \n",
      "[0/100][105/100][190] Loss_D: 0.001735 Loss_G: 0.001239 \n",
      "[0/100][105/100][195] Loss_D: 0.001328 Loss_G: 0.001428 \n",
      "[0/100][105/100][200] Loss_D: 0.001301 Loss_G: 0.001122 \n",
      "[0/100][105/100][205] Loss_D: 0.001111 Loss_G: 0.000940 \n",
      "[0/100][105/100][210] Loss_D: 0.001142 Loss_G: 0.001739 \n",
      "[0/100][105/100][215] Loss_D: 0.000998 Loss_G: 0.001330 \n",
      "[0/100][105/100][220] Loss_D: 0.000978 Loss_G: 0.001603 \n",
      "[0/100][105/100][225] Loss_D: 0.001029 Loss_G: 0.001152 \n",
      "[0/100][105/100][230] Loss_D: 0.001802 Loss_G: 0.001089 \n",
      "[0/100][105/100][235] Loss_D: 0.001067 Loss_G: 0.000770 \n",
      "[0/100][105/100][240] Loss_D: 0.000882 Loss_G: 0.001309 \n",
      "[0/100][105/100][245] Loss_D: 0.001372 Loss_G: 0.001338 \n",
      "[0/100][105/100][250] Loss_D: 0.000995 Loss_G: 0.001888 \n",
      "[0/100][105/100][255] Loss_D: 0.001381 Loss_G: 0.000783 \n",
      "[0/100][105/100][260] Loss_D: 0.001081 Loss_G: 0.000857 \n",
      "[0/100][105/100][265] Loss_D: 0.001026 Loss_G: 0.001207 \n",
      "[0/100][105/100][270] Loss_D: 0.000629 Loss_G: 0.000899 \n",
      "[0/100][105/100][275] Loss_D: 0.000936 Loss_G: 0.001168 \n",
      "[0/100][105/100][280] Loss_D: 0.000512 Loss_G: 0.000557 \n",
      "[0/100][105/100][285] Loss_D: 0.000519 Loss_G: 0.000764 \n",
      "[0/100][105/100][290] Loss_D: 0.000535 Loss_G: 0.001073 \n",
      "[0/100][105/100][295] Loss_D: 0.001005 Loss_G: 0.000759 \n",
      "[0/100][105/100][300] Loss_D: 0.000287 Loss_G: 0.000601 \n",
      "[0/100][105/100][305] Loss_D: 0.000488 Loss_G: 0.000342 \n",
      "[0/100][105/100][310] Loss_D: 0.000375 Loss_G: 0.000539 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-249-1201038fbbae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnetG_neg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# gen_losses, disc_losses = train_GAN(netD_neg, netG_neg, negative=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_GAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetD_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetG_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-244-f8a462dc91d8>\u001b[0m in \u001b[0;36mtrain_GAN\u001b[1;34m(netD, netG, negative, steps_per_epoch, epochs)\u001b[0m\n\u001b[0;32m     53\u001b[0m                     \u001b[0mstdD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                     \u001b[0moutputD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                     \u001b[0moptimizerD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;31m#                     print('AAAAAAAAA mse:=WWWWWWWWWWWWWWWWWWWWWW')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;31m############################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "netD_neg.train()\n",
    "netG_neg.train()\n",
    "# gen_losses, disc_losses = train_GAN(netD_neg, netG_neg, negative=True)\n",
    "train_GAN(netD_neg, netG_neg, negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(gen_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(disc_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netD_neg.state_dict(), './netD_neg-1m')\n",
    "torch.save(netG_neg.state_dict(), './netG_neg-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetD(\n",
       "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
       "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
       "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD_neg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5450"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetG(\n",
       "  (netGen): Sequential(\n",
       "    (0): Linear(in_features=3716, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# networks\n",
    "netD_neg_test = NetD(negative_feedback_mask.shape[1]).cuda()\n",
    "netG_neg_test = NetG(negative_feedback_mask.shape[1]).cuda()\n",
    "\n",
    "netD_neg_test.eval()\n",
    "netG_neg_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition, X = batch_generator(X_neg, y_neg, batch_size=128)\n",
    "\n",
    "X = X.cuda()\n",
    "condition = condition.cuda()\n",
    "# real = Variable(X)\n",
    "\n",
    "noise = torch.randn(128, nz).cuda()\n",
    "# noise = noise.cuda()\n",
    "# noisev = Variable(noise)\n",
    "\n",
    "concated = torch.cat((noise, condition), 1)\n",
    "fake = netG_neg(X, concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test = netG_neg_test(X, concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7139, device='cuda:0'),\n",
       " tensor(2873, device='cuda:0'),\n",
       " tensor(4424., device='cuda:0'),\n",
       " tensor(7427., device='cuda:0'))"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake >= 0.5).sum(), ((fake >= 0.5) * (condition==0)).sum(), condition.sum(), X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3689, device='cuda:0'),\n",
       " tensor(1453, device='cuda:0'),\n",
       " tensor(4424., device='cuda:0'),\n",
       " tensor(7427., device='cuda:0'))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_test >= 0.5).sum(), ((fake_test >= 0.5) * (condition==0)).sum(), condition.sum(), X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7139, device='cuda:0'),\n",
       " tensor(2993, device='cuda:0'),\n",
       " tensor(4424., device='cuda:0'),\n",
       " tensor(7427., device='cuda:0'))"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake >= 0.5).sum(), ((fake >= 0.4) * (condition==0)).sum(), condition.sum(), X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7139, device='cuda:0')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3689, device='cuda:0')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_test > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3706])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7269, device='cuda:0'),\n",
       " tensor(2933, device='cuda:0'),\n",
       " tensor(4424., device='cuda:0'))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake > 0.48).sum(), ((fake > 0.48) * (condition==0)).sum(), condition.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(condition.cpu().numpy(), X.cpu().numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23., device='cuda:0')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake > 0.4).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9., device='cuda:0'),)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.4).float() * (condition==0).float() * X).sum(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9567, device='cuda:0')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float() * (condition==0).float() * X).sum()/(X * (1 - condition)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4838, device='cuda:0')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake_test > 0.5).float() * (condition==0).float() * X).sum()/(X * (1 - condition)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5005, device='cuda:0')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float() ).sum()/X.sum() # whole accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5121, device='cuda:0')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake_test > 0.5).float() ).sum()/X.sum() # whole accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ((fake > 0.5).float() * (condition==0).float() * X).sum()/(X * (1 - fake)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses_tr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = torch.randn(train.shape[0], nz).to(device)\n",
    "# noisev = Variable(noise)\n",
    "# fake = netG_tr(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.around(fake.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = fake * (fake <= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == (tr + vr)[:fake.shape[0], :].round()).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there is a significant bias towards higher ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networks\n",
    "netD_augm = NetD().to(device)\n",
    "netG_augm = NetG().to(device)\n",
    "print(netD_augm)\n",
    "print(netG_augm)\n",
    "optimizerG = optim.RMSprop(netG_augm.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD_augm.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1]).to(device)\n",
    "mone = (-1 * one).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(train.shape[0], nz).to(device)\n",
    "noisev = Variable(noise)\n",
    "fake = netG_augm(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.around(fake.detach().cpu().numpy())\n",
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without train\n",
    "print(5, (5 == fake.round()).sum(), (5 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == (tr + vr)[:fake.shape[0], :].round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netD_augm.load_state_dict(torch.load('./netG_augm-1m'))\n",
    "# netD_augm.load_state_dict(torch.load('./netD_augm-1m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD_augm.train()\n",
    "netG_augm.train()\n",
    "eval_losses_aug = train_GAN(netD_augm, netG_augm, augmented_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses_aug)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netG_tr.eval()\n",
    "netG_augm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(train.shape[0], nz).to(device)\n",
    "noisev = Variable(noise)\n",
    "fake = netG_augm(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.around(fake.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake = fake * (fake <= 5).astype(int)\n",
    "\n",
    "fake = fake.clip(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == (tr + vr)[:fake.shape[0], :].round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(train.shape[0], nz).to(device)\n",
    "noisev = Variable(noise)\n",
    "\n",
    "fake_tr = netG_tr(noisev)\n",
    "fake_aug = netG_augm(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(fake_tr.round()), torch.unique(fake_aug.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tr = fake_tr.clamp(0,5).detach().cpu().numpy().round()\n",
    "fake_aug = fake_aug.clamp(0,5).detach().cpu().numpy().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5, (5 == fake_tr).sum(), (5 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(4, (4 == fake_tr).sum(), (4 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(3, (3 == fake_tr).sum(), (3 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(2, (2 == fake_tr).sum(), (2 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(1, (1 == fake_tr).sum(), (1 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(0, (0 == fake_tr).sum(), (0 == (tr + vr)[:fake.shape[0], :]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5, (5 == fake_aug).sum(), (5 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(4, (4 == fake_aug).sum(), (4 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(3, (3 == fake_aug).sum(), (3 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(2, (2 == fake_aug).sum(), (2 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(1, (1 == fake_aug).sum(), (1 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(0, (0 == fake_aug).sum(), (0 == (tr + vr)[:fake.shape[0], :]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(tr), get_sparsity(fake_tr), get_sparsity(fake_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_orig, vr_1 = loadData('./ml-1m/ratings.dat', delimiter='::', seed=seed,  transpose=False, valfrac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter \n",
    "import matrix_factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ix = np.random.randint(0, fake.shape[0], 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding_fake_autoenc = fake_tr[rand_ix,:]\n",
    "adding_fake_autoenc_lus_gan = fake_aug[rand_ix,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fake_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(adding_fake_autoenc_lus_gan[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adding_fake_autoenc == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adding_fake_autoenc_lus_gan == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(adding_fake_autoenc_lus_gan[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_fake[0,0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_fake_autoenc_lus_gan[0,0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_auto_enc = np.append(tr, adding_fake_autoenc, axis=0)\n",
    "tr_auto_enc_plus_gan = np.append(tr, adding_fake_autoenc_lus_gan, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD = matrix_factorization.ExplicitMF(tr, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(augmented_train.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD = matrix_factorization.ExplicitMF(augmented_train.cpu().numpy(), 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD = matrix_factorization.ExplicitMF(tr, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([50], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD = matrix_factorization.ExplicitMF(augmented_train.cpu().numpy(), 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([50], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.shape, augmented_train.cpu().numpy().shape, tr_auto_enc.shape, tr_auto_enc_plus_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(tr_auto_enc), get_sparsity(tr_auto_enc_plus_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25, 40]\n",
    "\n",
    "MF_SGD = matrix_factorization.ExplicitMF(tr_auto_enc, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25, 40]\n",
    "\n",
    "MF_SGD = matrix_factorization.ExplicitMF(tr_auto_enc_plus_gan, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(tr_auto_enc_plus_gan), tr_auto_enc_plus_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(tr_auto_enc_plus_gan, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(tr_auto_enc_plus_gan, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(fake_aug, 40, learning='sgd', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_tr = augmented_train.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(augmented_tr, 40, learning='sgd', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(tr, 40, learning='sgd', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(tr, 40, learning='als', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(augmented_tr, 40, learning='als', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
