{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from dataLoader import loadData\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading Movielens-1m\n",
    "# !curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "# #     http://www.grouplens.org/system/files/ml-1m.zip\n",
    "# !unzip ml-1m.zip\n",
    "# !cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data...\n",
      "data read in 5.028218030929565 seconds\n",
      "loaded dense data matrix\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "tr, vr = loadData('./ml-1m/ratings.dat', delimiter='::', seed=seed, transpose=False, valfrac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./tr_movielens_1m', tr)\n",
    "np.save('./vr_movielens_1m', vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [3., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.021525859265269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44683670296601535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "############## Pytorch model doesn't converge - to do - check #################\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "def autoEncoder(X):\n",
    "    '''\n",
    "    Autoencoder for Collaborative Filter Model\n",
    "    '''\n",
    "\n",
    "    # Input\n",
    "    input_layer = Input(shape=(X.shape[1],), name='UserScore')\n",
    "    \n",
    "    # Encoder\n",
    "    # -----------------------------\n",
    "    enc = Dense(512, activation='selu', name='EncLayer1', kernel_regularizer=regularizers.l2(0.000001))(input_layer)\n",
    "\n",
    "    # Latent Space\n",
    "    # -----------------------------\n",
    "    lat_space = Dense(512, activation='selu', name='LatentSpace', kernel_regularizer=regularizers.l2(0.000001))(enc)\n",
    "    lat_space = Dropout(0.5, name='Dropout')(lat_space) # Dropout\n",
    "\n",
    "    # Decoder\n",
    "    # -----------------------------\n",
    "    dec = Dense(512, activation='selu', name='DecLayer1', kernel_regularizer=regularizers.l2(0.000001))(lat_space)\n",
    "\n",
    "    # Output\n",
    "    output_layer = Dense(X.shape[1], activation='linear', name='UserScorePred', kernel_regularizer=regularizers.l2(0.000001))(dec)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    model = Model(input_layer, output_layer)    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mask = (train == 0)\n",
    "positive_feedback_mask = (train > 3)\n",
    "negative_feedback_mask = ((train < 4) * (1 - zero_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (positive_feedback_mask + negative_feedback_mask != zero_mask).all()\n",
    "assert (positive_feedback_mask + negative_feedback_mask == 1 - zero_mask).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95.97847414073473, 2.3124349989099473, 1.7090908603553212)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(zero_mask), get_sparsity(positive_feedback_mask), get_sparsity(negative_feedback_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.021525859265267, 2.3124349989099473, 1.7090908603553212, 4.021525859265268)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 - get_sparsity(zero_mask), get_sparsity(positive_feedback_mask), get_sparsity(negative_feedback_mask), get_sparsity(positive_feedback_mask) + get_sparsity(negative_feedback_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.4\n",
    "mask_arr_neg = (np.random.rand(negative_feedback_mask.shape[0], negative_feedback_mask.shape[1]) > P)\n",
    "y_neg = negative_feedback_mask\n",
    "X_neg = negative_feedback_mask*mask_arr_neg # corrupting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr_pos = (np.random.rand(positive_feedback_mask.shape[0], positive_feedback_mask.shape[1]) > P)\n",
    "y_pos = positive_feedback_mask\n",
    "X_pos = positive_feedback_mask*mask_arr_pos # corrupting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_tr = (mask_arr_neg*(tr>0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.021525859265269,\n",
       " 1.026195215919772,\n",
       " 1.7090908603553212,\n",
       " 1.3870741200058612,\n",
       " 2.3124349989099473,\n",
       " 2.4134703702247653)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(tr), get_sparsity(X_neg), get_sparsity(y_neg), get_sparsity(X_pos), get_sparsity(y_pos), get_sparsity(corrupted_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neg = autoEncoder(X_neg)\n",
    "model_neg.compile(optimizer = Adam(lr=0.0001), loss='mse')\n",
    "\n",
    "model_pos = autoEncoder(X_pos)\n",
    "model_pos.compile(optimizer = Adam(lr=0.0001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neg = keras.models.load_model('./model_neg')\n",
    "model_pos = keras.models.load_model('./model_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "UserScore (InputLayer)       [(None, 3706)]            0         \n",
      "_________________________________________________________________\n",
      "EncLayer1 (Dense)            (None, 512)               1897984   \n",
      "_________________________________________________________________\n",
      "LatentSpace (Dense)          (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "DecLayer1 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "UserScorePred (Dense)        (None, 3706)              1901178   \n",
      "=================================================================\n",
      "Total params: 4,324,474\n",
      "Trainable params: 4,324,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_neg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_tr = np.load('predicted_tr.npy')\n",
    "# augmented_train = np.load('augmented_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_neg = model_neg.fit(x=X_neg, y=y_neg,\n",
    "                  epochs=300,\n",
    "                  batch_size=128,\n",
    "                  shuffle=True,\n",
    "# augmented_train = np.load('augmented_train.npy')\n",
    "                  validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_pos = model_pos.fit(x=X_pos, y=y_pos,\n",
    "                  epochs=300,\n",
    "                  batch_size=128,\n",
    "                  shuffle=True,\n",
    "                  validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_hist(hist):\n",
    "    # summarize history for loss\n",
    "    fig, ax = plt.subplots()  # create figure & 1 axis\n",
    "\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    plt.plot(hist.history['loss'])\n",
    "    #plt.plot(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neg.save('./model_neg')\n",
    "model_pos.save('./model_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "predicted_neg = model_neg.predict(X_neg)\n",
    "predicted_pos = model_pos.predict(X_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170143, 382567)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_neg > 0.4).sum(), (y_neg == 1).sum() # predicted vs real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115775, 214496)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_neg>0.5).sum(), (predicted_pos>0.5).sum() # trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9528337927508037\n",
      "0.9187441580985445\n"
     ]
    }
   ],
   "source": [
    "print((y_neg * (predicted_neg>0.4)).sum()/(predicted_neg>0.4).sum()) # accuracy on actual \n",
    "print((y_pos * (predicted_pos>0.4)).sum()/(predicted_pos>0.4).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004936043939484681\n",
      "0.016499070751005707\n"
     ]
    }
   ],
   "source": [
    "print((y_pos * (predicted_neg>0.4)).sum()/(y_pos>0.4).sum()) # just to see that it's a low number\n",
    "print((y_neg * (predicted_pos>0.4)).sum()/(y_neg>0.4).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9862405527963722"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_neg * (predicted_neg>0.5)).sum()/((predicted_neg>0.5).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698642398925854"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pos * (predicted_pos>0.5)).sum()/((predicted_pos>0.5).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39637"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((predicted_neg>0.5)  * (X_neg<0.5)).sum() # predicted values which were not in the train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69892"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((predicted_pos>0.5)  * (X_pos<0.5)).sum() # predicted values which were not in the train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598102782753488"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_neg * (((predicted_neg>0.5)  * (X_neg<0.5)))) == 1).sum()/(((predicted_neg>0.5)  * (X_neg<0.5))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075144508670521"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_pos * (((predicted_pos>0.5)  * (X_pos<0.5)))) == 1).sum()/(((predicted_pos>0.5)  * (X_pos<0.5))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add_negative = model_neg.predict(y_neg)\n",
    "to_add_positive = model_neg.predict(y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207742, 234140)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(to_add_negative>0.5).sum(), (to_add_positive>0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9874735206891682, 0.9078462031914041)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_neg* (to_add_negative>0.8)).sum()/(((to_add_negative>0.8)).sum()), (y_pos* (to_add_positive>0.8)).sum()/(((to_add_positive>0.8)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep the balance\n",
    "threshold_neg = 0.2\n",
    "threshold_pos = 0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345157, 240626)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((to_add_negative > threshold_neg) * (tr==0)).sum(), ((to_add_positive > threshold_pos) * (tr==0)).sum() # new values # new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13207882540835983, 0.25313474502505445, 0.6147864295665857]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_probs_neg = [(tr == 1).sum()/((tr > 0) & (tr < 4)).sum(), (tr == 2).sum()/(((tr > 0) & (tr < 4))).sum(), (tr == 3).sum()/((tr > 0) & (tr < 4)).sum()]\n",
    "p_probs_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6064147320143503, 0.39358526798564974]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_probs_pos = [(tr == 4).sum()/((tr > 3) & (tr <= 5)).sum(), (tr == 5).sum()/((tr > 3) & (tr <= 5)).sum()]\n",
    "p_probs_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train = tr + (to_add_negative > threshold_neg) * (tr == 0) * np.random.choice(np.arange(1, 4), tr.shape, p=p_probs_neg) + (to_add_positive > threshold_pos) * (tr == 0) * np.random.choice(np.arange(4, 6), tr.shape, p=p_probs_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.021525859265269, 6.412851184583439)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(tr), get_sparsity(augmented_train) # reduced sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.isin(tr, augmented_train)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 203728\n",
      "4 313893\n",
      "3 235197\n",
      "2 96841\n",
      "1 50529\n",
      "0 21484052\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == tr).sum())\n",
    "print(4, (4 == tr).sum())\n",
    "print(3, (3 == tr).sum())\n",
    "print(2, (2 == tr).sum())\n",
    "print(1, (1 == tr).sum())\n",
    "print(0, (0 == tr).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 282704\n",
      "4 429003\n",
      "3 416147\n",
      "2 171461\n",
      "1 89613\n",
      "0 20948772\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == augmented_train).sum())\n",
    "print(4, (4 == augmented_train).sum())\n",
    "print(3, (3 == augmented_train).sum())\n",
    "print(2, (2 == augmented_train).sum())\n",
    "print(1, (1 == augmented_train).sum())\n",
    "print(0, (0 == augmented_train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535280"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((tr == 0) * (augmented_train > 0)).sum() # new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('predicted_tr', predicted_tr)\n",
    "np.save('augmented_train', augmented_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, feat_size):\n",
    "        super(NetD, self).__init__()\n",
    "        self.feat_size = feat_size\n",
    "#         self.use_cuda = True\n",
    "#         self.feat_size = feat_size\n",
    "        # top\n",
    "#         print(self.feat_size*2)\n",
    "        self.t1 = torch.nn.Linear(self.feat_size, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(self.feat_size, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, self.feat_size)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "        \n",
    "        filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "#         if self.use_cuda: \n",
    "        idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = F.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "        x = filt * x\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self, feat_size):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "        self.feat_size = feat_size\n",
    "        self.netGen = torch.nn.Sequential( \n",
    "                                torch.nn.Linear(nz + self.feat_size, 1024), \n",
    "#                                 torch.nn.BatchNorm1d(1024),\n",
    "                                torch.nn.ReLU(), \n",
    "#                                 nn.Dropout(0.5),\n",
    "#                                 torch.nn.Linear(1024, 1024),\n",
    "# #                                 torch.nn.BatchNorm1d(1024),\n",
    "#                                 torch.nn.ReLU(), \n",
    "#                                 nn.Dropout(0.6),\n",
    "                                torch.nn.Linear(1024, features_length), \n",
    "                                torch.nn.Sigmoid()\n",
    "#                                 torch.nn.BatchNorm1d(features_length),\n",
    "#                                 nn.Dropout(0.7),\n",
    "#                                 torch.nn.Sigmoid()\n",
    "                                )\n",
    "\n",
    "        \n",
    "    def forward(self, e_mask, x):\n",
    "        x = self.netGen(x)\n",
    "        x = x * e_mask\n",
    "        return x\n",
    "#         return F.dropout(x, 0.7)\n",
    "#         return 5 * self.netGen(x)\n",
    "#         return torch.sigmoid(x) \n",
    "#         return x*5 # to get values in range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch(mat, batch_size=64):\n",
    "    '''\n",
    "    returns random rows of size batch_size\n",
    "    '''\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))\n",
    "augmented_train = torch.autograd.Variable(torch.Tensor(augmented_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del augmented_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.021525859265269, 6.412851184583439)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train.cpu().numpy()), get_sparsity(augmented_train.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = get_random_batch(train)\n",
    "# xy = get_random_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_my(xx, xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sum(torch.abs(torch.abs(xx != 0).float()*xy - xy), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx > xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def d_my(x_r, x_g): # custom loss -todo\n",
    "# #     return torch.sum(torch.abs((x_r != 0).float() * x_g - x_r), 1)/x_r.shape[1]\n",
    "\n",
    "# def d_my(x_r, x_g): # custom loss -todo\n",
    "#     return torch.sum(torch.abs(x_g - x_r), 1)/x_r.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(corrupted, original, batch_size=64):\n",
    "    rand_rows = np.random.randint(corrupted.shape[0], size=batch_size)\n",
    "    return torch.Tensor(corrupted[rand_rows]).cuda().float(), torch.Tensor(original[rand_rows]).cuda().float(), rand_rows\n",
    "#     return torch.from_numpy(corrupted[rand_rows]).float(), torch.from_numpy(original[rand_rows]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.026195215919772, 1.7090908603553212)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(X_neg), get_sparsity(y_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1033627900701564,\n",
       " 4.1528939557474365,\n",
       " torch.Size([64, 3706]),\n",
       " torch.Size([64, 3706]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,_ = batch_generator(X_neg, (tr > 0).astype(float))\n",
    "\n",
    "get_sparsity(a.cpu().numpy()), get_sparsity(b.cpu().numpy()), a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_losses = []\n",
    "disc_losses = []\n",
    "def train_GAN(netD, netG, negative, steps_per_epoch = 100, epochs = 100):\n",
    "    d_iter = 5\n",
    "    g_iter = 1\n",
    "    gen_iterations = 0\n",
    "#     gen_losses = []\n",
    "#     disc_losses = []\n",
    "#     train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for c in range(steps_per_epoch):\n",
    "            data_iter = 100\n",
    "            i = 0\n",
    "            while i < 100:\n",
    "                ############################\n",
    "                # (1) Update D network\n",
    "                ###########################\n",
    "                for p in netD.parameters(): # reset requires_grad\n",
    "                    p.requires_grad = True # they are set to False below in netG update\n",
    "    #             d_iter = d_iter\n",
    "                j = 0\n",
    "                while j < d_iter*5:\n",
    "                    j += 1\n",
    "                    # load real data\n",
    "                    i += 1\n",
    "                    if negative:\n",
    "                        condition, X, idxs = batch_generator(X_neg, y_neg)\n",
    "    #                 X, _ = data_iter.next()\n",
    "    #                 X = X.view(X.size(0), -1)\n",
    "    #                 X = (X >= 0.5).float()\n",
    "#                     if cuda: \n",
    "                    X = X.cuda()\n",
    "                    condition = condition.cuda()\n",
    "    #                 print(condition.shape, X_neg.shape, y_neg.shape)\n",
    "                    real = Variable(X)\n",
    "\n",
    "                    # generate fake data\n",
    "                    noise = torch.randn(batch_size, nz)\n",
    "#                     if cuda: \n",
    "                    noise = noise.cuda()\n",
    "                    noisev = Variable(noise, volatile = True) # totally freeze netG\n",
    "                    concated = torch.cat((noisev, condition), 1)\n",
    "    #                 print(condition.shape, condition.shape, X.shape, noisev.shape, )\n",
    "                    e_mask = torch.Tensor(tr[idxs]>0).cuda()\n",
    "                    fake = Variable(netG(e_mask, concated).data)\n",
    "\n",
    "                    # compute gradient, take step\n",
    "                    netD.zero_grad()\n",
    "    #                 concated_real = torch.cat((real, condition), 1)\n",
    "    #                 print(concated_real)\n",
    "                    out = netD(real, fake)\n",
    "                    outputD = torch.mean(out) + lamba * out.norm()\n",
    "                    stdD = torch.std(out)\n",
    "                    outputD.backward(mone)\n",
    "                    optimizerD.step()\n",
    "#                     print('AAAAAAAAA mse:=WWWWWWWWWWWWWWWWWWWWWW')\n",
    "            ############################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "\n",
    "    #         g_iter = g_iter\n",
    "            j = 0\n",
    "            while j < g_iter*5:\n",
    "                j += 1\n",
    "                for p in netD.parameters():\n",
    "                    p.requires_grad = False # to avoid computation\n",
    "                netG.zero_grad()\n",
    "                # load real data\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                if negative:\n",
    "                    condition, X, idxs = batch_generator(X_neg, y_neg)\n",
    "                    \n",
    "                X = X.cuda()\n",
    "                condition = condition.cuda()\n",
    "                real = Variable(X)\n",
    "\n",
    "                # update generator\n",
    "                noise = torch.randn(batch_size, nz)\n",
    "                noise = noise.cuda()\n",
    "                noisev = Variable(noise)\n",
    "                concated_ = torch.cat((noisev, condition), 1)\n",
    "                e_mask_ = torch.Tensor(tr[idxs]>0).cuda()\n",
    " \n",
    "                fake = netG(e_mask_, concated_)\n",
    "                out = netD(real, fake)\n",
    "                outputG = torch.mean(out) + lamba * out.norm()\n",
    "                stdG = torch.std(out)\n",
    "                outputG.backward(one)\n",
    "                optimizerG.step()\n",
    "                gen_iterations += 1\n",
    "#             print('AAAAAA')\n",
    "            eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "#             eval_losses.append(eval_loss)\n",
    "#             print('mse:', eval_loss)\n",
    "#             print(outputG.item(), outputD.item())\n",
    "            gen_losses.append(outputG.item())\n",
    "            disc_losses.append(outputD.item())\n",
    "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, 100, gen_iterations, outputD.item(), outputG.item()))\n",
    "    return gen_losses, disc_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.026195215919772, 1.7090908603553212)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(X_neg), get_sparsity(y_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrD = 5e-4\n",
    "# lrG = 5e-4\n",
    "# batch_size = 128\n",
    "# cuda = True\n",
    "# epochs = 1000 #change\n",
    "# seed = 1\n",
    "# nz = 16\n",
    "# d_iter = 5\n",
    "# g_iter = 1\n",
    "# lamba = 2e-4\n",
    "\n",
    "lrD = 1e-4\n",
    "lrG = 1e-4\n",
    "batch_size = 64\n",
    "cuda = True\n",
    "epochs = 1000\n",
    "device = 5\n",
    "seed = 1\n",
    "nz = 20\n",
    "lamba = 1e-4 \n",
    "# lamba = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_feedback_mask.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n",
      "NetG(\n",
      "  (netGen): Sequential(\n",
      "    (0): Linear(in_features=3726, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# networks\n",
    "netD_neg = NetD(negative_feedback_mask.shape[1]).cuda()\n",
    "netG_neg = NetG(negative_feedback_mask.shape[1]).cuda()\n",
    "print(netD_neg)\n",
    "print(netG_neg)\n",
    "optimizerG = optim.Adam(netG_neg.parameters(), lr=lrG, weight_decay=1e-5)\n",
    "optimizerD = optim.Adam(netD_neg.parameters(), lr=lrD, weight_decay=1e-5)\n",
    "one = torch.FloatTensor([1]).cuda()\n",
    "mone = (-1 * one).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][105/100][5] Loss_D: 0.004765 Loss_G: 0.005677 \n",
      "[0/100][105/100][10] Loss_D: 0.011974 Loss_G: 0.013254 \n",
      "[0/100][105/100][15] Loss_D: 0.015144 Loss_G: 0.014056 \n",
      "[0/100][105/100][20] Loss_D: 0.012693 Loss_G: 0.013647 \n",
      "[0/100][105/100][25] Loss_D: 0.010267 Loss_G: 0.011395 \n",
      "[0/100][105/100][30] Loss_D: 0.015602 Loss_G: 0.014241 \n",
      "[0/100][105/100][35] Loss_D: 0.014503 Loss_G: 0.011896 \n",
      "[0/100][105/100][40] Loss_D: 0.016728 Loss_G: 0.007080 \n",
      "[0/100][105/100][45] Loss_D: 0.010229 Loss_G: 0.008234 \n",
      "[0/100][105/100][50] Loss_D: 0.010473 Loss_G: 0.012013 \n",
      "[0/100][105/100][55] Loss_D: 0.012195 Loss_G: 0.007282 \n",
      "[0/100][105/100][60] Loss_D: 0.007312 Loss_G: 0.004856 \n",
      "[0/100][105/100][65] Loss_D: 0.005318 Loss_G: 0.005430 \n",
      "[0/100][105/100][70] Loss_D: 0.010276 Loss_G: 0.004839 \n",
      "[0/100][105/100][75] Loss_D: 0.008518 Loss_G: 0.006709 \n",
      "[0/100][105/100][80] Loss_D: 0.005113 Loss_G: 0.010600 \n",
      "[0/100][105/100][85] Loss_D: 0.003609 Loss_G: 0.006810 \n",
      "[0/100][105/100][90] Loss_D: 0.009268 Loss_G: 0.002448 \n",
      "[0/100][105/100][95] Loss_D: 0.004614 Loss_G: 0.003286 \n",
      "[0/100][105/100][100] Loss_D: 0.005863 Loss_G: 0.006309 \n",
      "[0/100][105/100][105] Loss_D: 0.008524 Loss_G: 0.001467 \n",
      "[0/100][105/100][110] Loss_D: 0.007723 Loss_G: 0.008898 \n",
      "[0/100][105/100][115] Loss_D: 0.009716 Loss_G: 0.005213 \n",
      "[0/100][105/100][120] Loss_D: 0.006994 Loss_G: 0.005800 \n",
      "[0/100][105/100][125] Loss_D: 0.007310 Loss_G: 0.008497 \n",
      "[0/100][105/100][130] Loss_D: 0.007380 Loss_G: 0.007435 \n",
      "[0/100][105/100][135] Loss_D: 0.009637 Loss_G: 0.008087 \n",
      "[0/100][105/100][140] Loss_D: 0.010601 Loss_G: 0.006396 \n",
      "[0/100][105/100][145] Loss_D: 0.010147 Loss_G: 0.008018 \n",
      "[0/100][105/100][150] Loss_D: 0.008254 Loss_G: 0.006409 \n",
      "[0/100][105/100][155] Loss_D: 0.008711 Loss_G: 0.005750 \n",
      "[0/100][105/100][160] Loss_D: 0.007867 Loss_G: 0.003856 \n",
      "[0/100][105/100][165] Loss_D: 0.004592 Loss_G: 0.002450 \n",
      "[0/100][105/100][170] Loss_D: 0.004924 Loss_G: 0.001735 \n",
      "[0/100][105/100][175] Loss_D: 0.005749 Loss_G: 0.002267 \n",
      "[0/100][105/100][180] Loss_D: 0.008470 Loss_G: 0.005225 \n",
      "[0/100][105/100][185] Loss_D: 0.009308 Loss_G: 0.005048 \n",
      "[0/100][105/100][190] Loss_D: 0.012003 Loss_G: 0.005276 \n",
      "[0/100][105/100][195] Loss_D: 0.007419 Loss_G: 0.010286 \n",
      "[0/100][105/100][200] Loss_D: 0.010147 Loss_G: 0.006359 \n",
      "[0/100][105/100][205] Loss_D: 0.009144 Loss_G: 0.012661 \n",
      "[0/100][105/100][210] Loss_D: 0.011903 Loss_G: 0.008842 \n",
      "[0/100][105/100][215] Loss_D: 0.006963 Loss_G: 0.011008 \n",
      "[0/100][105/100][220] Loss_D: 0.007314 Loss_G: 0.008057 \n",
      "[0/100][105/100][225] Loss_D: 0.011273 Loss_G: 0.005902 \n",
      "[0/100][105/100][230] Loss_D: 0.007471 Loss_G: 0.010098 \n",
      "[0/100][105/100][235] Loss_D: 0.006250 Loss_G: 0.010512 \n",
      "[0/100][105/100][240] Loss_D: 0.007812 Loss_G: 0.010695 \n",
      "[0/100][105/100][245] Loss_D: 0.006226 Loss_G: 0.009619 \n",
      "[0/100][105/100][250] Loss_D: 0.009828 Loss_G: 0.006211 \n",
      "[0/100][105/100][255] Loss_D: 0.005572 Loss_G: 0.010830 \n",
      "[0/100][105/100][260] Loss_D: 0.008757 Loss_G: 0.009427 \n",
      "[0/100][105/100][265] Loss_D: 0.010097 Loss_G: 0.006341 \n",
      "[0/100][105/100][270] Loss_D: 0.010831 Loss_G: 0.005314 \n",
      "[0/100][105/100][275] Loss_D: 0.007435 Loss_G: 0.007053 \n",
      "[0/100][105/100][280] Loss_D: 0.007473 Loss_G: 0.004991 \n",
      "[0/100][105/100][285] Loss_D: 0.003049 Loss_G: 0.002740 \n",
      "[0/100][105/100][290] Loss_D: 0.005656 Loss_G: 0.003775 \n",
      "[0/100][105/100][295] Loss_D: 0.007502 Loss_G: 0.003997 \n",
      "[0/100][105/100][300] Loss_D: 0.006558 Loss_G: 0.005823 \n",
      "[0/100][105/100][305] Loss_D: 0.009917 Loss_G: 0.004511 \n",
      "[0/100][105/100][310] Loss_D: 0.008806 Loss_G: 0.010171 \n",
      "[0/100][105/100][315] Loss_D: 0.008641 Loss_G: 0.007118 \n",
      "[0/100][105/100][320] Loss_D: 0.004551 Loss_G: 0.002788 \n",
      "[0/100][105/100][325] Loss_D: 0.008045 Loss_G: 0.002504 \n",
      "[0/100][105/100][330] Loss_D: 0.008578 Loss_G: 0.004169 \n",
      "[0/100][105/100][335] Loss_D: 0.006377 Loss_G: 0.007051 \n",
      "[0/100][105/100][340] Loss_D: 0.003255 Loss_G: 0.003629 \n",
      "[0/100][105/100][345] Loss_D: 0.007181 Loss_G: 0.003196 \n",
      "[0/100][105/100][350] Loss_D: 0.005838 Loss_G: 0.003063 \n",
      "[0/100][105/100][355] Loss_D: 0.003809 Loss_G: 0.003954 \n",
      "[0/100][105/100][360] Loss_D: 0.006910 Loss_G: 0.006803 \n",
      "[0/100][105/100][365] Loss_D: 0.010304 Loss_G: 0.004450 \n",
      "[0/100][105/100][370] Loss_D: 0.006917 Loss_G: 0.005561 \n",
      "[0/100][105/100][375] Loss_D: 0.005044 Loss_G: 0.009377 \n",
      "[0/100][105/100][380] Loss_D: 0.006214 Loss_G: 0.004987 \n",
      "[0/100][105/100][385] Loss_D: 0.006157 Loss_G: 0.005162 \n",
      "[0/100][105/100][390] Loss_D: 0.005155 Loss_G: 0.000983 \n",
      "[0/100][105/100][395] Loss_D: 0.003345 Loss_G: 0.000278 \n",
      "[0/100][105/100][400] Loss_D: 0.002268 Loss_G: 0.001573 \n",
      "[0/100][105/100][405] Loss_D: 0.003236 Loss_G: 0.002025 \n",
      "[0/100][105/100][410] Loss_D: 0.003834 Loss_G: 0.001958 \n",
      "[0/100][105/100][415] Loss_D: 0.003705 Loss_G: 0.001624 \n",
      "[0/100][105/100][420] Loss_D: 0.003046 Loss_G: 0.002533 \n",
      "[0/100][105/100][425] Loss_D: 0.002798 Loss_G: 0.004155 \n",
      "[0/100][105/100][430] Loss_D: 0.005347 Loss_G: 0.003177 \n",
      "[0/100][105/100][435] Loss_D: 0.005806 Loss_G: 0.005989 \n",
      "[0/100][105/100][440] Loss_D: 0.004559 Loss_G: 0.005850 \n",
      "[0/100][105/100][445] Loss_D: 0.004565 Loss_G: 0.006597 \n",
      "[0/100][105/100][450] Loss_D: 0.006322 Loss_G: 0.009532 \n",
      "[0/100][105/100][455] Loss_D: 0.007852 Loss_G: 0.005734 \n",
      "[0/100][105/100][460] Loss_D: 0.008138 Loss_G: 0.003991 \n",
      "[0/100][105/100][465] Loss_D: 0.004912 Loss_G: 0.006208 \n",
      "[0/100][105/100][470] Loss_D: 0.004823 Loss_G: 0.002720 \n",
      "[0/100][105/100][475] Loss_D: 0.007763 Loss_G: 0.004374 \n",
      "[0/100][105/100][480] Loss_D: 0.004083 Loss_G: 0.006082 \n",
      "[0/100][105/100][485] Loss_D: 0.002800 Loss_G: 0.002064 \n",
      "[0/100][105/100][490] Loss_D: 0.003909 Loss_G: 0.002452 \n",
      "[0/100][105/100][495] Loss_D: 0.003140 Loss_G: 0.002380 \n",
      "[0/100][105/100][500] Loss_D: 0.001390 Loss_G: 0.001712 \n",
      "[1/100][105/100][505] Loss_D: 0.002810 Loss_G: 0.002469 \n",
      "[1/100][105/100][510] Loss_D: 0.004955 Loss_G: 0.004089 \n",
      "[1/100][105/100][515] Loss_D: 0.006229 Loss_G: 0.005192 \n",
      "[1/100][105/100][520] Loss_D: 0.005332 Loss_G: 0.004823 \n",
      "[1/100][105/100][525] Loss_D: 0.009587 Loss_G: 0.006541 \n",
      "[1/100][105/100][530] Loss_D: 0.006361 Loss_G: 0.005613 \n",
      "[1/100][105/100][535] Loss_D: 0.008134 Loss_G: 0.007215 \n",
      "[1/100][105/100][540] Loss_D: 0.007399 Loss_G: 0.005017 \n",
      "[1/100][105/100][545] Loss_D: 0.007817 Loss_G: 0.006431 \n",
      "[1/100][105/100][550] Loss_D: 0.003002 Loss_G: 0.003684 \n",
      "[1/100][105/100][555] Loss_D: 0.003929 Loss_G: 0.001528 \n",
      "[1/100][105/100][560] Loss_D: 0.004736 Loss_G: 0.002270 \n",
      "[1/100][105/100][565] Loss_D: 0.002547 Loss_G: 0.005077 \n",
      "[1/100][105/100][570] Loss_D: 0.003517 Loss_G: 0.001918 \n",
      "[1/100][105/100][575] Loss_D: 0.001666 Loss_G: 0.002976 \n",
      "[1/100][105/100][580] Loss_D: 0.002921 Loss_G: 0.002467 \n",
      "[1/100][105/100][585] Loss_D: 0.002159 Loss_G: 0.001965 \n",
      "[1/100][105/100][590] Loss_D: 0.003740 Loss_G: 0.002569 \n",
      "[1/100][105/100][595] Loss_D: 0.004713 Loss_G: 0.003544 \n",
      "[1/100][105/100][600] Loss_D: 0.003669 Loss_G: 0.003813 \n",
      "[1/100][105/100][605] Loss_D: 0.005083 Loss_G: 0.001559 \n",
      "[1/100][105/100][610] Loss_D: 0.005861 Loss_G: 0.005287 \n",
      "[1/100][105/100][615] Loss_D: 0.005334 Loss_G: 0.004023 \n",
      "[1/100][105/100][620] Loss_D: 0.004479 Loss_G: 0.008119 \n",
      "[1/100][105/100][625] Loss_D: 0.006925 Loss_G: 0.006862 \n",
      "[1/100][105/100][630] Loss_D: 0.005529 Loss_G: 0.003781 \n",
      "[1/100][105/100][635] Loss_D: 0.005802 Loss_G: 0.002893 \n",
      "[1/100][105/100][640] Loss_D: 0.005148 Loss_G: 0.005629 \n",
      "[1/100][105/100][645] Loss_D: 0.004335 Loss_G: 0.006208 \n",
      "[1/100][105/100][650] Loss_D: 0.004244 Loss_G: 0.004776 \n",
      "[1/100][105/100][655] Loss_D: 0.001250 Loss_G: 0.002451 \n",
      "[1/100][105/100][660] Loss_D: 0.002156 Loss_G: 0.003117 \n",
      "[1/100][105/100][665] Loss_D: 0.005583 Loss_G: 0.002327 \n",
      "[1/100][105/100][670] Loss_D: 0.004029 Loss_G: 0.002995 \n",
      "[1/100][105/100][675] Loss_D: 0.002725 Loss_G: 0.002631 \n",
      "[1/100][105/100][680] Loss_D: 0.004232 Loss_G: 0.003170 \n",
      "[1/100][105/100][685] Loss_D: 0.004919 Loss_G: 0.005781 \n",
      "[1/100][105/100][690] Loss_D: 0.004062 Loss_G: 0.004255 \n",
      "[1/100][105/100][695] Loss_D: 0.006577 Loss_G: 0.005265 \n",
      "[1/100][105/100][700] Loss_D: 0.006870 Loss_G: 0.005576 \n",
      "[1/100][105/100][705] Loss_D: 0.006288 Loss_G: 0.006891 \n",
      "[1/100][105/100][710] Loss_D: 0.005133 Loss_G: 0.003190 \n",
      "[1/100][105/100][715] Loss_D: 0.011080 Loss_G: 0.003636 \n",
      "[1/100][105/100][720] Loss_D: 0.005581 Loss_G: 0.003342 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100][105/100][725] Loss_D: 0.003820 Loss_G: 0.003263 \n",
      "[1/100][105/100][730] Loss_D: 0.005123 Loss_G: 0.003017 \n",
      "[1/100][105/100][735] Loss_D: 0.002285 Loss_G: 0.004440 \n",
      "[1/100][105/100][740] Loss_D: 0.007313 Loss_G: 0.004237 \n",
      "[1/100][105/100][745] Loss_D: 0.004081 Loss_G: 0.002286 \n",
      "[1/100][105/100][750] Loss_D: 0.005370 Loss_G: 0.003664 \n",
      "[1/100][105/100][755] Loss_D: 0.004580 Loss_G: 0.003621 \n",
      "[1/100][105/100][760] Loss_D: 0.004311 Loss_G: 0.003937 \n",
      "[1/100][105/100][765] Loss_D: 0.007531 Loss_G: 0.006046 \n",
      "[1/100][105/100][770] Loss_D: 0.004024 Loss_G: 0.005351 \n",
      "[1/100][105/100][775] Loss_D: 0.005362 Loss_G: 0.003614 \n",
      "[1/100][105/100][780] Loss_D: 0.003904 Loss_G: 0.004471 \n",
      "[1/100][105/100][785] Loss_D: 0.005751 Loss_G: 0.003906 \n",
      "[1/100][105/100][790] Loss_D: 0.005085 Loss_G: 0.003947 \n",
      "[1/100][105/100][795] Loss_D: 0.003909 Loss_G: 0.004857 \n",
      "[1/100][105/100][800] Loss_D: 0.003367 Loss_G: 0.003488 \n",
      "[1/100][105/100][805] Loss_D: 0.002750 Loss_G: 0.006251 \n",
      "[1/100][105/100][810] Loss_D: 0.002780 Loss_G: 0.005443 \n",
      "[1/100][105/100][815] Loss_D: 0.003736 Loss_G: 0.002905 \n",
      "[1/100][105/100][820] Loss_D: 0.004194 Loss_G: 0.005602 \n",
      "[1/100][105/100][825] Loss_D: 0.006196 Loss_G: 0.003591 \n",
      "[1/100][105/100][830] Loss_D: 0.003170 Loss_G: 0.003957 \n",
      "[1/100][105/100][835] Loss_D: 0.006197 Loss_G: 0.002880 \n",
      "[1/100][105/100][840] Loss_D: 0.007462 Loss_G: 0.003604 \n",
      "[1/100][105/100][845] Loss_D: 0.003586 Loss_G: 0.007417 \n",
      "[1/100][105/100][850] Loss_D: 0.005047 Loss_G: 0.002782 \n",
      "[1/100][105/100][855] Loss_D: 0.003901 Loss_G: 0.004133 \n",
      "[1/100][105/100][860] Loss_D: 0.004315 Loss_G: 0.003425 \n",
      "[1/100][105/100][865] Loss_D: 0.004666 Loss_G: 0.004608 \n",
      "[1/100][105/100][870] Loss_D: 0.005316 Loss_G: 0.004585 \n",
      "[1/100][105/100][875] Loss_D: 0.005240 Loss_G: 0.004585 \n",
      "[1/100][105/100][880] Loss_D: 0.002568 Loss_G: 0.004235 \n",
      "[1/100][105/100][885] Loss_D: 0.005030 Loss_G: 0.005196 \n",
      "[1/100][105/100][890] Loss_D: 0.006249 Loss_G: 0.004404 \n",
      "[1/100][105/100][895] Loss_D: 0.005602 Loss_G: 0.004620 \n",
      "[1/100][105/100][900] Loss_D: 0.006514 Loss_G: 0.005429 \n",
      "[1/100][105/100][905] Loss_D: 0.006323 Loss_G: 0.004597 \n",
      "[1/100][105/100][910] Loss_D: 0.005794 Loss_G: 0.006749 \n",
      "[1/100][105/100][915] Loss_D: 0.005240 Loss_G: 0.004392 \n",
      "[1/100][105/100][920] Loss_D: 0.002791 Loss_G: 0.005362 \n",
      "[1/100][105/100][925] Loss_D: 0.002664 Loss_G: 0.006733 \n",
      "[1/100][105/100][930] Loss_D: 0.006345 Loss_G: 0.003925 \n",
      "[1/100][105/100][935] Loss_D: 0.005781 Loss_G: 0.004888 \n",
      "[1/100][105/100][940] Loss_D: 0.003748 Loss_G: 0.005122 \n",
      "[1/100][105/100][945] Loss_D: 0.005353 Loss_G: 0.006663 \n",
      "[1/100][105/100][950] Loss_D: 0.004226 Loss_G: 0.007326 \n",
      "[1/100][105/100][955] Loss_D: 0.004176 Loss_G: 0.002958 \n",
      "[1/100][105/100][960] Loss_D: 0.003679 Loss_G: 0.004058 \n",
      "[1/100][105/100][965] Loss_D: 0.005351 Loss_G: 0.006668 \n",
      "[1/100][105/100][970] Loss_D: 0.005505 Loss_G: 0.004006 \n",
      "[1/100][105/100][975] Loss_D: 0.005480 Loss_G: 0.004532 \n",
      "[1/100][105/100][980] Loss_D: 0.005003 Loss_G: 0.008500 \n",
      "[1/100][105/100][985] Loss_D: 0.003764 Loss_G: 0.005324 \n",
      "[1/100][105/100][990] Loss_D: 0.004079 Loss_G: 0.006346 \n",
      "[1/100][105/100][995] Loss_D: 0.006518 Loss_G: 0.005593 \n",
      "[1/100][105/100][1000] Loss_D: 0.006087 Loss_G: 0.004551 \n",
      "[2/100][105/100][1005] Loss_D: 0.005494 Loss_G: 0.006819 \n",
      "[2/100][105/100][1010] Loss_D: 0.004715 Loss_G: 0.002446 \n",
      "[2/100][105/100][1015] Loss_D: 0.006522 Loss_G: 0.007095 \n",
      "[2/100][105/100][1020] Loss_D: 0.007510 Loss_G: 0.004963 \n",
      "[2/100][105/100][1025] Loss_D: 0.005829 Loss_G: 0.005544 \n",
      "[2/100][105/100][1030] Loss_D: 0.006777 Loss_G: 0.005407 \n",
      "[2/100][105/100][1035] Loss_D: 0.006217 Loss_G: 0.007371 \n",
      "[2/100][105/100][1040] Loss_D: 0.003768 Loss_G: 0.007845 \n",
      "[2/100][105/100][1045] Loss_D: 0.004863 Loss_G: 0.004056 \n",
      "[2/100][105/100][1050] Loss_D: 0.006246 Loss_G: 0.005839 \n",
      "[2/100][105/100][1055] Loss_D: 0.006585 Loss_G: 0.004161 \n",
      "[2/100][105/100][1060] Loss_D: 0.006610 Loss_G: 0.008560 \n",
      "[2/100][105/100][1065] Loss_D: 0.006260 Loss_G: 0.006343 \n",
      "[2/100][105/100][1070] Loss_D: 0.004413 Loss_G: 0.005701 \n",
      "[2/100][105/100][1075] Loss_D: 0.005858 Loss_G: 0.004811 \n",
      "[2/100][105/100][1080] Loss_D: 0.005065 Loss_G: 0.005671 \n",
      "[2/100][105/100][1085] Loss_D: 0.005473 Loss_G: 0.002987 \n",
      "[2/100][105/100][1090] Loss_D: 0.006817 Loss_G: 0.002427 \n",
      "[2/100][105/100][1095] Loss_D: 0.004912 Loss_G: 0.004134 \n",
      "[2/100][105/100][1100] Loss_D: 0.007148 Loss_G: 0.004555 \n",
      "[2/100][105/100][1105] Loss_D: 0.007471 Loss_G: 0.006923 \n",
      "[2/100][105/100][1110] Loss_D: 0.005863 Loss_G: 0.004848 \n",
      "[2/100][105/100][1115] Loss_D: 0.007082 Loss_G: 0.011250 \n",
      "[2/100][105/100][1120] Loss_D: 0.008321 Loss_G: 0.006928 \n",
      "[2/100][105/100][1125] Loss_D: 0.006398 Loss_G: 0.003837 \n",
      "[2/100][105/100][1130] Loss_D: 0.006977 Loss_G: 0.012239 \n",
      "[2/100][105/100][1135] Loss_D: 0.007289 Loss_G: 0.006559 \n",
      "[2/100][105/100][1140] Loss_D: 0.009034 Loss_G: 0.006457 \n",
      "[2/100][105/100][1145] Loss_D: 0.007692 Loss_G: 0.006702 \n",
      "[2/100][105/100][1150] Loss_D: 0.007194 Loss_G: 0.007572 \n",
      "[2/100][105/100][1155] Loss_D: 0.005896 Loss_G: 0.004150 \n",
      "[2/100][105/100][1160] Loss_D: 0.006144 Loss_G: 0.007482 \n",
      "[2/100][105/100][1165] Loss_D: 0.004463 Loss_G: 0.004948 \n",
      "[2/100][105/100][1170] Loss_D: 0.007433 Loss_G: 0.006804 \n",
      "[2/100][105/100][1175] Loss_D: 0.005882 Loss_G: 0.009635 \n",
      "[2/100][105/100][1180] Loss_D: 0.007440 Loss_G: 0.005426 \n",
      "[2/100][105/100][1185] Loss_D: 0.004961 Loss_G: 0.004519 \n",
      "[2/100][105/100][1190] Loss_D: 0.006377 Loss_G: 0.006899 \n",
      "[2/100][105/100][1195] Loss_D: 0.006499 Loss_G: 0.008307 \n",
      "[2/100][105/100][1200] Loss_D: 0.003781 Loss_G: 0.006692 \n",
      "[2/100][105/100][1205] Loss_D: 0.005551 Loss_G: 0.005154 \n",
      "[2/100][105/100][1210] Loss_D: 0.005966 Loss_G: 0.006808 \n",
      "[2/100][105/100][1215] Loss_D: 0.006457 Loss_G: 0.007116 \n",
      "[2/100][105/100][1220] Loss_D: 0.007133 Loss_G: 0.006886 \n",
      "[2/100][105/100][1225] Loss_D: 0.003719 Loss_G: 0.006995 \n",
      "[2/100][105/100][1230] Loss_D: 0.005770 Loss_G: 0.007537 \n",
      "[2/100][105/100][1235] Loss_D: 0.006906 Loss_G: 0.007249 \n",
      "[2/100][105/100][1240] Loss_D: 0.005217 Loss_G: 0.006803 \n",
      "[2/100][105/100][1245] Loss_D: 0.007142 Loss_G: 0.004977 \n",
      "[2/100][105/100][1250] Loss_D: 0.008250 Loss_G: 0.006835 \n",
      "[2/100][105/100][1255] Loss_D: 0.004725 Loss_G: 0.006848 \n",
      "[2/100][105/100][1260] Loss_D: 0.007817 Loss_G: 0.007436 \n",
      "[2/100][105/100][1265] Loss_D: 0.007893 Loss_G: 0.008004 \n",
      "[2/100][105/100][1270] Loss_D: 0.004865 Loss_G: 0.009270 \n",
      "[2/100][105/100][1275] Loss_D: 0.007151 Loss_G: 0.006108 \n",
      "[2/100][105/100][1280] Loss_D: 0.006407 Loss_G: 0.006238 \n",
      "[2/100][105/100][1285] Loss_D: 0.008744 Loss_G: 0.006158 \n",
      "[2/100][105/100][1290] Loss_D: 0.006753 Loss_G: 0.007577 \n",
      "[2/100][105/100][1295] Loss_D: 0.007896 Loss_G: 0.004853 \n",
      "[2/100][105/100][1300] Loss_D: 0.005784 Loss_G: 0.005408 \n",
      "[2/100][105/100][1305] Loss_D: 0.005730 Loss_G: 0.007639 \n",
      "[2/100][105/100][1310] Loss_D: 0.007536 Loss_G: 0.007928 \n",
      "[2/100][105/100][1315] Loss_D: 0.006734 Loss_G: 0.007009 \n",
      "[2/100][105/100][1320] Loss_D: 0.006127 Loss_G: 0.006740 \n",
      "[2/100][105/100][1325] Loss_D: 0.006568 Loss_G: 0.007676 \n",
      "[2/100][105/100][1330] Loss_D: 0.008368 Loss_G: 0.005291 \n",
      "[2/100][105/100][1335] Loss_D: 0.009728 Loss_G: 0.006865 \n",
      "[2/100][105/100][1340] Loss_D: 0.006513 Loss_G: 0.007843 \n",
      "[2/100][105/100][1345] Loss_D: 0.006788 Loss_G: 0.004652 \n",
      "[2/100][105/100][1350] Loss_D: 0.004077 Loss_G: 0.004648 \n",
      "[2/100][105/100][1355] Loss_D: 0.008040 Loss_G: 0.004541 \n",
      "[2/100][105/100][1360] Loss_D: 0.006524 Loss_G: 0.003012 \n",
      "[2/100][105/100][1365] Loss_D: 0.004533 Loss_G: 0.008717 \n",
      "[2/100][105/100][1370] Loss_D: 0.010156 Loss_G: 0.008419 \n",
      "[2/100][105/100][1375] Loss_D: 0.008358 Loss_G: 0.010661 \n",
      "[2/100][105/100][1380] Loss_D: 0.009020 Loss_G: 0.008569 \n",
      "[2/100][105/100][1385] Loss_D: 0.010322 Loss_G: 0.007272 \n",
      "[2/100][105/100][1390] Loss_D: 0.009715 Loss_G: 0.008901 \n",
      "[2/100][105/100][1395] Loss_D: 0.008144 Loss_G: 0.005715 \n",
      "[2/100][105/100][1400] Loss_D: 0.007411 Loss_G: 0.004020 \n",
      "[2/100][105/100][1405] Loss_D: 0.006571 Loss_G: 0.004045 \n",
      "[2/100][105/100][1410] Loss_D: 0.007758 Loss_G: 0.003569 \n",
      "[2/100][105/100][1415] Loss_D: 0.006183 Loss_G: 0.003426 \n",
      "[2/100][105/100][1420] Loss_D: 0.005155 Loss_G: 0.007355 \n",
      "[2/100][105/100][1425] Loss_D: 0.007629 Loss_G: 0.005266 \n",
      "[2/100][105/100][1430] Loss_D: 0.007544 Loss_G: 0.010518 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100][105/100][1435] Loss_D: 0.004806 Loss_G: 0.008301 \n",
      "[2/100][105/100][1440] Loss_D: 0.007686 Loss_G: 0.004062 \n",
      "[2/100][105/100][1445] Loss_D: 0.004203 Loss_G: 0.003995 \n",
      "[2/100][105/100][1450] Loss_D: 0.006330 Loss_G: 0.006498 \n",
      "[2/100][105/100][1455] Loss_D: 0.005980 Loss_G: 0.006398 \n",
      "[2/100][105/100][1460] Loss_D: 0.007376 Loss_G: 0.005464 \n",
      "[2/100][105/100][1465] Loss_D: 0.006165 Loss_G: 0.006619 \n",
      "[2/100][105/100][1470] Loss_D: 0.007495 Loss_G: 0.007382 \n",
      "[2/100][105/100][1475] Loss_D: 0.005264 Loss_G: 0.008153 \n",
      "[2/100][105/100][1480] Loss_D: 0.007551 Loss_G: 0.005735 \n",
      "[2/100][105/100][1485] Loss_D: 0.007449 Loss_G: 0.007875 \n",
      "[2/100][105/100][1490] Loss_D: 0.007589 Loss_G: 0.003581 \n",
      "[2/100][105/100][1495] Loss_D: 0.005790 Loss_G: 0.004218 \n",
      "[2/100][105/100][1500] Loss_D: 0.006050 Loss_G: 0.004989 \n",
      "[3/100][105/100][1505] Loss_D: 0.004186 Loss_G: 0.005205 \n",
      "[3/100][105/100][1510] Loss_D: 0.002844 Loss_G: 0.003980 \n",
      "[3/100][105/100][1515] Loss_D: 0.008137 Loss_G: 0.005705 \n",
      "[3/100][105/100][1520] Loss_D: 0.007861 Loss_G: 0.004546 \n",
      "[3/100][105/100][1525] Loss_D: 0.006840 Loss_G: 0.006081 \n",
      "[3/100][105/100][1530] Loss_D: 0.005784 Loss_G: 0.007150 \n",
      "[3/100][105/100][1535] Loss_D: 0.006808 Loss_G: 0.005247 \n",
      "[3/100][105/100][1540] Loss_D: 0.005868 Loss_G: 0.003132 \n",
      "[3/100][105/100][1545] Loss_D: 0.006041 Loss_G: 0.006190 \n",
      "[3/100][105/100][1550] Loss_D: 0.007401 Loss_G: 0.005969 \n",
      "[3/100][105/100][1555] Loss_D: 0.005678 Loss_G: 0.005039 \n",
      "[3/100][105/100][1560] Loss_D: 0.006856 Loss_G: 0.007219 \n",
      "[3/100][105/100][1565] Loss_D: 0.008716 Loss_G: 0.005767 \n",
      "[3/100][105/100][1570] Loss_D: 0.005379 Loss_G: 0.007573 \n",
      "[3/100][105/100][1575] Loss_D: 0.004351 Loss_G: 0.006002 \n",
      "[3/100][105/100][1580] Loss_D: 0.007075 Loss_G: 0.007665 \n",
      "[3/100][105/100][1585] Loss_D: 0.006285 Loss_G: 0.003998 \n",
      "[3/100][105/100][1590] Loss_D: 0.004953 Loss_G: 0.005709 \n",
      "[3/100][105/100][1595] Loss_D: 0.006812 Loss_G: 0.004235 \n",
      "[3/100][105/100][1600] Loss_D: 0.006322 Loss_G: 0.006106 \n",
      "[3/100][105/100][1605] Loss_D: 0.007164 Loss_G: 0.005647 \n",
      "[3/100][105/100][1610] Loss_D: 0.005533 Loss_G: 0.005976 \n",
      "[3/100][105/100][1615] Loss_D: 0.008715 Loss_G: 0.004795 \n",
      "[3/100][105/100][1620] Loss_D: 0.007902 Loss_G: 0.006211 \n",
      "[3/100][105/100][1625] Loss_D: 0.008260 Loss_G: 0.005168 \n",
      "[3/100][105/100][1630] Loss_D: 0.005479 Loss_G: 0.006634 \n",
      "[3/100][105/100][1635] Loss_D: 0.006497 Loss_G: 0.005720 \n",
      "[3/100][105/100][1640] Loss_D: 0.006026 Loss_G: 0.007182 \n",
      "[3/100][105/100][1645] Loss_D: 0.003279 Loss_G: 0.004105 \n",
      "[3/100][105/100][1650] Loss_D: 0.004988 Loss_G: 0.006648 \n",
      "[3/100][105/100][1655] Loss_D: 0.005719 Loss_G: 0.008072 \n",
      "[3/100][105/100][1660] Loss_D: 0.005543 Loss_G: 0.005817 \n",
      "[3/100][105/100][1665] Loss_D: 0.008401 Loss_G: 0.003523 \n",
      "[3/100][105/100][1670] Loss_D: 0.006083 Loss_G: 0.005446 \n",
      "[3/100][105/100][1675] Loss_D: 0.007196 Loss_G: 0.008709 \n",
      "[3/100][105/100][1680] Loss_D: 0.005963 Loss_G: 0.004706 \n",
      "[3/100][105/100][1685] Loss_D: 0.006784 Loss_G: 0.004553 \n",
      "[3/100][105/100][1690] Loss_D: 0.003983 Loss_G: 0.006372 \n",
      "[3/100][105/100][1695] Loss_D: 0.004589 Loss_G: 0.006957 \n",
      "[3/100][105/100][1700] Loss_D: 0.006863 Loss_G: 0.005765 \n",
      "[3/100][105/100][1705] Loss_D: 0.006603 Loss_G: 0.007444 \n",
      "[3/100][105/100][1710] Loss_D: 0.005112 Loss_G: 0.005397 \n",
      "[3/100][105/100][1715] Loss_D: 0.005585 Loss_G: 0.005366 \n",
      "[3/100][105/100][1720] Loss_D: 0.007450 Loss_G: 0.009215 \n",
      "[3/100][105/100][1725] Loss_D: 0.008803 Loss_G: 0.006999 \n",
      "[3/100][105/100][1730] Loss_D: 0.004827 Loss_G: 0.005199 \n",
      "[3/100][105/100][1735] Loss_D: 0.006144 Loss_G: 0.008260 \n",
      "[3/100][105/100][1740] Loss_D: 0.004133 Loss_G: 0.006141 \n",
      "[3/100][105/100][1745] Loss_D: 0.008354 Loss_G: 0.003727 \n",
      "[3/100][105/100][1750] Loss_D: 0.008270 Loss_G: 0.006555 \n",
      "[3/100][105/100][1755] Loss_D: 0.007731 Loss_G: 0.006667 \n",
      "[3/100][105/100][1760] Loss_D: 0.004137 Loss_G: 0.005003 \n",
      "[3/100][105/100][1765] Loss_D: 0.006461 Loss_G: 0.006701 \n",
      "[3/100][105/100][1770] Loss_D: 0.005271 Loss_G: 0.006496 \n",
      "[3/100][105/100][1775] Loss_D: 0.005419 Loss_G: 0.004352 \n",
      "[3/100][105/100][1780] Loss_D: 0.005364 Loss_G: 0.004723 \n",
      "[3/100][105/100][1785] Loss_D: 0.006108 Loss_G: 0.004932 \n",
      "[3/100][105/100][1790] Loss_D: 0.006960 Loss_G: 0.007351 \n",
      "[3/100][105/100][1795] Loss_D: 0.005309 Loss_G: 0.006354 \n",
      "[3/100][105/100][1800] Loss_D: 0.006572 Loss_G: 0.008073 \n",
      "[3/100][105/100][1805] Loss_D: 0.008754 Loss_G: 0.004946 \n",
      "[3/100][105/100][1810] Loss_D: 0.004224 Loss_G: 0.004648 \n",
      "[3/100][105/100][1815] Loss_D: 0.005913 Loss_G: 0.007137 \n",
      "[3/100][105/100][1820] Loss_D: 0.008535 Loss_G: 0.005972 \n",
      "[3/100][105/100][1825] Loss_D: 0.005179 Loss_G: 0.008332 \n",
      "[3/100][105/100][1830] Loss_D: 0.005971 Loss_G: 0.006852 \n",
      "[3/100][105/100][1835] Loss_D: 0.007387 Loss_G: 0.008080 \n",
      "[3/100][105/100][1840] Loss_D: 0.007242 Loss_G: 0.005586 \n",
      "[3/100][105/100][1845] Loss_D: 0.005248 Loss_G: 0.005263 \n",
      "[3/100][105/100][1850] Loss_D: 0.006246 Loss_G: 0.008793 \n",
      "[3/100][105/100][1855] Loss_D: 0.005362 Loss_G: 0.003054 \n",
      "[3/100][105/100][1860] Loss_D: 0.007997 Loss_G: 0.007083 \n",
      "[3/100][105/100][1865] Loss_D: 0.008480 Loss_G: 0.005279 \n",
      "[3/100][105/100][1870] Loss_D: 0.006797 Loss_G: 0.008905 \n",
      "[3/100][105/100][1875] Loss_D: 0.004793 Loss_G: 0.006033 \n",
      "[3/100][105/100][1880] Loss_D: 0.004202 Loss_G: 0.008041 \n",
      "[3/100][105/100][1885] Loss_D: 0.004566 Loss_G: 0.006782 \n",
      "[3/100][105/100][1890] Loss_D: 0.005228 Loss_G: 0.005879 \n",
      "[3/100][105/100][1895] Loss_D: 0.007273 Loss_G: 0.004238 \n",
      "[3/100][105/100][1900] Loss_D: 0.005938 Loss_G: 0.005515 \n",
      "[3/100][105/100][1905] Loss_D: 0.007128 Loss_G: 0.005897 \n",
      "[3/100][105/100][1910] Loss_D: 0.006966 Loss_G: 0.005800 \n",
      "[3/100][105/100][1915] Loss_D: 0.011432 Loss_G: 0.007788 \n",
      "[3/100][105/100][1920] Loss_D: 0.009916 Loss_G: 0.006599 \n",
      "[3/100][105/100][1925] Loss_D: 0.005667 Loss_G: 0.005839 \n",
      "[3/100][105/100][1930] Loss_D: 0.005570 Loss_G: 0.007103 \n",
      "[3/100][105/100][1935] Loss_D: 0.006248 Loss_G: 0.008118 \n",
      "[3/100][105/100][1940] Loss_D: 0.006548 Loss_G: 0.004804 \n",
      "[3/100][105/100][1945] Loss_D: 0.005125 Loss_G: 0.005240 \n",
      "[3/100][105/100][1950] Loss_D: 0.006176 Loss_G: 0.003670 \n",
      "[3/100][105/100][1955] Loss_D: 0.008307 Loss_G: 0.005359 \n",
      "[3/100][105/100][1960] Loss_D: 0.004469 Loss_G: 0.006233 \n",
      "[3/100][105/100][1965] Loss_D: 0.007059 Loss_G: 0.005878 \n",
      "[3/100][105/100][1970] Loss_D: 0.006121 Loss_G: 0.008668 \n",
      "[3/100][105/100][1975] Loss_D: 0.006075 Loss_G: 0.012312 \n",
      "[3/100][105/100][1980] Loss_D: 0.011865 Loss_G: 0.009999 \n",
      "[3/100][105/100][1985] Loss_D: 0.005769 Loss_G: 0.007181 \n",
      "[3/100][105/100][1990] Loss_D: 0.007943 Loss_G: 0.005250 \n",
      "[3/100][105/100][1995] Loss_D: 0.006565 Loss_G: 0.005964 \n",
      "[3/100][105/100][2000] Loss_D: 0.006448 Loss_G: 0.004931 \n",
      "[4/100][105/100][2005] Loss_D: 0.005188 Loss_G: 0.006450 \n",
      "[4/100][105/100][2010] Loss_D: 0.006941 Loss_G: 0.005740 \n",
      "[4/100][105/100][2015] Loss_D: 0.009004 Loss_G: 0.007755 \n",
      "[4/100][105/100][2020] Loss_D: 0.006970 Loss_G: 0.008086 \n",
      "[4/100][105/100][2025] Loss_D: 0.006230 Loss_G: 0.010195 \n",
      "[4/100][105/100][2030] Loss_D: 0.008085 Loss_G: 0.005736 \n",
      "[4/100][105/100][2035] Loss_D: 0.006289 Loss_G: 0.008748 \n",
      "[4/100][105/100][2040] Loss_D: 0.006044 Loss_G: 0.008070 \n",
      "[4/100][105/100][2045] Loss_D: 0.003617 Loss_G: 0.007775 \n",
      "[4/100][105/100][2050] Loss_D: 0.006695 Loss_G: 0.007431 \n",
      "[4/100][105/100][2055] Loss_D: 0.004839 Loss_G: 0.005708 \n",
      "[4/100][105/100][2060] Loss_D: 0.005094 Loss_G: 0.004796 \n",
      "[4/100][105/100][2065] Loss_D: 0.006488 Loss_G: 0.004702 \n",
      "[4/100][105/100][2070] Loss_D: 0.007279 Loss_G: 0.005253 \n",
      "[4/100][105/100][2075] Loss_D: 0.009107 Loss_G: 0.008272 \n",
      "[4/100][105/100][2080] Loss_D: 0.007303 Loss_G: 0.006318 \n",
      "[4/100][105/100][2085] Loss_D: 0.005811 Loss_G: 0.008038 \n",
      "[4/100][105/100][2090] Loss_D: 0.008286 Loss_G: 0.004815 \n",
      "[4/100][105/100][2095] Loss_D: 0.006507 Loss_G: 0.005714 \n",
      "[4/100][105/100][2100] Loss_D: 0.005327 Loss_G: 0.006017 \n",
      "[4/100][105/100][2105] Loss_D: 0.007205 Loss_G: 0.003540 \n",
      "[4/100][105/100][2110] Loss_D: 0.006060 Loss_G: 0.003794 \n",
      "[4/100][105/100][2115] Loss_D: 0.006151 Loss_G: 0.005992 \n",
      "[4/100][105/100][2120] Loss_D: 0.004443 Loss_G: 0.006607 \n",
      "[4/100][105/100][2125] Loss_D: 0.006824 Loss_G: 0.006317 \n",
      "[4/100][105/100][2130] Loss_D: 0.005841 Loss_G: 0.006547 \n",
      "[4/100][105/100][2135] Loss_D: 0.009133 Loss_G: 0.006111 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/100][105/100][2140] Loss_D: 0.005397 Loss_G: 0.008067 \n",
      "[4/100][105/100][2145] Loss_D: 0.006114 Loss_G: 0.006646 \n",
      "[4/100][105/100][2150] Loss_D: 0.002982 Loss_G: 0.006516 \n",
      "[4/100][105/100][2155] Loss_D: 0.003202 Loss_G: 0.003983 \n",
      "[4/100][105/100][2160] Loss_D: 0.004661 Loss_G: 0.005527 \n",
      "[4/100][105/100][2165] Loss_D: 0.009507 Loss_G: 0.006536 \n",
      "[4/100][105/100][2170] Loss_D: 0.009770 Loss_G: 0.005267 \n",
      "[4/100][105/100][2175] Loss_D: 0.009493 Loss_G: 0.006496 \n",
      "[4/100][105/100][2180] Loss_D: 0.008079 Loss_G: 0.005069 \n",
      "[4/100][105/100][2185] Loss_D: 0.006594 Loss_G: 0.005928 \n",
      "[4/100][105/100][2190] Loss_D: 0.005231 Loss_G: 0.005411 \n",
      "[4/100][105/100][2195] Loss_D: 0.006604 Loss_G: 0.007546 \n",
      "[4/100][105/100][2200] Loss_D: 0.005046 Loss_G: 0.005359 \n",
      "[4/100][105/100][2205] Loss_D: 0.007615 Loss_G: 0.005027 \n",
      "[4/100][105/100][2210] Loss_D: 0.005627 Loss_G: 0.006062 \n",
      "[4/100][105/100][2215] Loss_D: 0.007993 Loss_G: 0.006666 \n",
      "[4/100][105/100][2220] Loss_D: 0.006909 Loss_G: 0.005164 \n",
      "[4/100][105/100][2225] Loss_D: 0.003445 Loss_G: 0.005321 \n",
      "[4/100][105/100][2230] Loss_D: 0.007432 Loss_G: 0.003975 \n",
      "[4/100][105/100][2235] Loss_D: 0.004600 Loss_G: 0.006573 \n",
      "[4/100][105/100][2240] Loss_D: 0.005064 Loss_G: 0.005651 \n",
      "[4/100][105/100][2245] Loss_D: 0.006183 Loss_G: 0.007258 \n",
      "[4/100][105/100][2250] Loss_D: 0.008220 Loss_G: 0.006276 \n",
      "[4/100][105/100][2255] Loss_D: 0.005216 Loss_G: 0.005909 \n",
      "[4/100][105/100][2260] Loss_D: 0.004835 Loss_G: 0.006557 \n",
      "[4/100][105/100][2265] Loss_D: 0.005118 Loss_G: 0.004982 \n",
      "[4/100][105/100][2270] Loss_D: 0.005598 Loss_G: 0.007681 \n",
      "[4/100][105/100][2275] Loss_D: 0.006968 Loss_G: 0.008220 \n",
      "[4/100][105/100][2280] Loss_D: 0.005009 Loss_G: 0.007160 \n",
      "[4/100][105/100][2285] Loss_D: 0.008795 Loss_G: 0.006812 \n",
      "[4/100][105/100][2290] Loss_D: 0.006647 Loss_G: 0.006301 \n",
      "[4/100][105/100][2295] Loss_D: 0.006952 Loss_G: 0.006195 \n",
      "[4/100][105/100][2300] Loss_D: 0.007239 Loss_G: 0.006032 \n",
      "[4/100][105/100][2305] Loss_D: 0.006863 Loss_G: 0.005569 \n",
      "[4/100][105/100][2310] Loss_D: 0.006868 Loss_G: 0.006899 \n",
      "[4/100][105/100][2315] Loss_D: 0.005011 Loss_G: 0.005564 \n",
      "[4/100][105/100][2320] Loss_D: 0.004817 Loss_G: 0.004607 \n",
      "[4/100][105/100][2325] Loss_D: 0.005150 Loss_G: 0.005950 \n",
      "[4/100][105/100][2330] Loss_D: 0.007561 Loss_G: 0.007623 \n",
      "[4/100][105/100][2335] Loss_D: 0.005866 Loss_G: 0.007018 \n",
      "[4/100][105/100][2340] Loss_D: 0.005518 Loss_G: 0.006878 \n",
      "[4/100][105/100][2345] Loss_D: 0.004438 Loss_G: 0.005939 \n",
      "[4/100][105/100][2350] Loss_D: 0.004227 Loss_G: 0.007733 \n",
      "[4/100][105/100][2355] Loss_D: 0.007218 Loss_G: 0.005595 \n",
      "[4/100][105/100][2360] Loss_D: 0.004146 Loss_G: 0.005007 \n",
      "[4/100][105/100][2365] Loss_D: 0.007558 Loss_G: 0.007610 \n",
      "[4/100][105/100][2370] Loss_D: 0.006786 Loss_G: 0.005649 \n",
      "[4/100][105/100][2375] Loss_D: 0.006178 Loss_G: 0.005589 \n",
      "[4/100][105/100][2380] Loss_D: 0.003341 Loss_G: 0.008351 \n",
      "[4/100][105/100][2385] Loss_D: 0.006178 Loss_G: 0.006054 \n",
      "[4/100][105/100][2390] Loss_D: 0.008122 Loss_G: 0.004796 \n",
      "[4/100][105/100][2395] Loss_D: 0.006722 Loss_G: 0.005125 \n",
      "[4/100][105/100][2400] Loss_D: 0.004604 Loss_G: 0.003277 \n",
      "[4/100][105/100][2405] Loss_D: 0.004073 Loss_G: 0.007707 \n",
      "[4/100][105/100][2410] Loss_D: 0.005867 Loss_G: 0.005886 \n",
      "[4/100][105/100][2415] Loss_D: 0.007389 Loss_G: 0.006102 \n",
      "[4/100][105/100][2420] Loss_D: 0.004931 Loss_G: 0.007507 \n",
      "[4/100][105/100][2425] Loss_D: 0.007500 Loss_G: 0.008135 \n",
      "[4/100][105/100][2430] Loss_D: 0.003298 Loss_G: 0.007325 \n",
      "[4/100][105/100][2435] Loss_D: 0.006459 Loss_G: 0.008482 \n",
      "[4/100][105/100][2440] Loss_D: 0.005157 Loss_G: 0.007180 \n",
      "[4/100][105/100][2445] Loss_D: 0.005765 Loss_G: 0.006104 \n",
      "[4/100][105/100][2450] Loss_D: 0.005342 Loss_G: 0.007415 \n",
      "[4/100][105/100][2455] Loss_D: 0.006759 Loss_G: 0.003860 \n",
      "[4/100][105/100][2460] Loss_D: 0.004420 Loss_G: 0.005262 \n",
      "[4/100][105/100][2465] Loss_D: 0.004976 Loss_G: 0.004583 \n",
      "[4/100][105/100][2470] Loss_D: 0.006040 Loss_G: 0.006390 \n",
      "[4/100][105/100][2475] Loss_D: 0.006375 Loss_G: 0.007975 \n",
      "[4/100][105/100][2480] Loss_D: 0.009130 Loss_G: 0.005833 \n",
      "[4/100][105/100][2485] Loss_D: 0.004172 Loss_G: 0.005609 \n",
      "[4/100][105/100][2490] Loss_D: 0.007166 Loss_G: 0.006036 \n",
      "[4/100][105/100][2495] Loss_D: 0.004670 Loss_G: 0.004933 \n",
      "[4/100][105/100][2500] Loss_D: 0.007752 Loss_G: 0.004697 \n",
      "[5/100][105/100][2505] Loss_D: 0.005438 Loss_G: 0.004865 \n",
      "[5/100][105/100][2510] Loss_D: 0.006681 Loss_G: 0.005556 \n",
      "[5/100][105/100][2515] Loss_D: 0.007035 Loss_G: 0.005077 \n",
      "[5/100][105/100][2520] Loss_D: 0.004545 Loss_G: 0.006400 \n",
      "[5/100][105/100][2525] Loss_D: 0.007402 Loss_G: 0.008654 \n",
      "[5/100][105/100][2530] Loss_D: 0.008872 Loss_G: 0.009713 \n",
      "[5/100][105/100][2535] Loss_D: 0.004252 Loss_G: 0.007224 \n",
      "[5/100][105/100][2540] Loss_D: 0.005654 Loss_G: 0.008444 \n",
      "[5/100][105/100][2545] Loss_D: 0.009410 Loss_G: 0.005330 \n",
      "[5/100][105/100][2550] Loss_D: 0.007082 Loss_G: 0.006761 \n",
      "[5/100][105/100][2555] Loss_D: 0.007298 Loss_G: 0.005002 \n",
      "[5/100][105/100][2560] Loss_D: 0.007910 Loss_G: 0.003414 \n",
      "[5/100][105/100][2565] Loss_D: 0.005925 Loss_G: 0.004688 \n",
      "[5/100][105/100][2570] Loss_D: 0.006123 Loss_G: 0.006430 \n",
      "[5/100][105/100][2575] Loss_D: 0.004332 Loss_G: 0.003777 \n",
      "[5/100][105/100][2580] Loss_D: 0.009213 Loss_G: 0.006784 \n",
      "[5/100][105/100][2585] Loss_D: 0.010970 Loss_G: 0.011150 \n",
      "[5/100][105/100][2590] Loss_D: 0.008771 Loss_G: 0.005955 \n",
      "[5/100][105/100][2595] Loss_D: 0.006010 Loss_G: 0.006761 \n",
      "[5/100][105/100][2600] Loss_D: 0.006828 Loss_G: 0.006893 \n",
      "[5/100][105/100][2605] Loss_D: 0.006008 Loss_G: 0.005544 \n",
      "[5/100][105/100][2610] Loss_D: 0.005352 Loss_G: 0.005594 \n",
      "[5/100][105/100][2615] Loss_D: 0.004650 Loss_G: 0.005750 \n",
      "[5/100][105/100][2620] Loss_D: 0.005846 Loss_G: 0.006947 \n",
      "[5/100][105/100][2625] Loss_D: 0.005333 Loss_G: 0.010425 \n",
      "[5/100][105/100][2630] Loss_D: 0.007282 Loss_G: 0.005706 \n",
      "[5/100][105/100][2635] Loss_D: 0.005989 Loss_G: 0.008683 \n",
      "[5/100][105/100][2640] Loss_D: 0.009390 Loss_G: 0.007706 \n",
      "[5/100][105/100][2645] Loss_D: 0.007153 Loss_G: 0.006343 \n",
      "[5/100][105/100][2650] Loss_D: 0.010398 Loss_G: 0.008382 \n",
      "[5/100][105/100][2655] Loss_D: 0.005856 Loss_G: 0.005915 \n",
      "[5/100][105/100][2660] Loss_D: 0.007827 Loss_G: 0.005559 \n",
      "[5/100][105/100][2665] Loss_D: 0.008194 Loss_G: 0.004992 \n",
      "[5/100][105/100][2670] Loss_D: 0.003708 Loss_G: 0.003529 \n",
      "[5/100][105/100][2675] Loss_D: 0.006671 Loss_G: 0.005525 \n",
      "[5/100][105/100][2680] Loss_D: 0.004480 Loss_G: 0.006007 \n",
      "[5/100][105/100][2685] Loss_D: 0.006728 Loss_G: 0.008486 \n",
      "[5/100][105/100][2690] Loss_D: 0.005353 Loss_G: 0.006389 \n",
      "[5/100][105/100][2695] Loss_D: 0.007179 Loss_G: 0.005247 \n",
      "[5/100][105/100][2700] Loss_D: 0.008288 Loss_G: 0.008352 \n",
      "[5/100][105/100][2705] Loss_D: 0.006265 Loss_G: 0.005970 \n",
      "[5/100][105/100][2710] Loss_D: 0.006500 Loss_G: 0.007352 \n",
      "[5/100][105/100][2715] Loss_D: 0.006744 Loss_G: 0.005958 \n",
      "[5/100][105/100][2720] Loss_D: 0.006090 Loss_G: 0.007769 \n",
      "[5/100][105/100][2725] Loss_D: 0.005583 Loss_G: 0.007706 \n",
      "[5/100][105/100][2730] Loss_D: 0.005142 Loss_G: 0.005390 \n",
      "[5/100][105/100][2735] Loss_D: 0.004932 Loss_G: 0.005661 \n",
      "[5/100][105/100][2740] Loss_D: 0.005548 Loss_G: 0.005325 \n",
      "[5/100][105/100][2745] Loss_D: 0.007238 Loss_G: 0.008111 \n",
      "[5/100][105/100][2750] Loss_D: 0.006966 Loss_G: 0.005467 \n",
      "[5/100][105/100][2755] Loss_D: 0.004252 Loss_G: 0.006486 \n",
      "[5/100][105/100][2760] Loss_D: 0.006141 Loss_G: 0.008330 \n",
      "[5/100][105/100][2765] Loss_D: 0.006700 Loss_G: 0.007864 \n",
      "[5/100][105/100][2770] Loss_D: 0.009847 Loss_G: 0.004150 \n",
      "[5/100][105/100][2775] Loss_D: 0.004891 Loss_G: 0.003973 \n",
      "[5/100][105/100][2780] Loss_D: 0.005203 Loss_G: 0.003926 \n",
      "[5/100][105/100][2785] Loss_D: 0.005257 Loss_G: 0.004671 \n",
      "[5/100][105/100][2790] Loss_D: 0.004890 Loss_G: 0.005420 \n",
      "[5/100][105/100][2795] Loss_D: 0.006118 Loss_G: 0.004226 \n",
      "[5/100][105/100][2800] Loss_D: 0.004360 Loss_G: 0.009630 \n",
      "[5/100][105/100][2805] Loss_D: 0.008728 Loss_G: 0.004756 \n",
      "[5/100][105/100][2810] Loss_D: 0.005516 Loss_G: 0.008005 \n",
      "[5/100][105/100][2815] Loss_D: 0.009004 Loss_G: 0.006132 \n",
      "[5/100][105/100][2820] Loss_D: 0.005632 Loss_G: 0.004621 \n",
      "[5/100][105/100][2825] Loss_D: 0.007280 Loss_G: 0.005454 \n",
      "[5/100][105/100][2830] Loss_D: 0.007027 Loss_G: 0.004863 \n",
      "[5/100][105/100][2835] Loss_D: 0.007105 Loss_G: 0.004901 \n",
      "[5/100][105/100][2840] Loss_D: 0.007802 Loss_G: 0.005125 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/100][105/100][2845] Loss_D: 0.004119 Loss_G: 0.004469 \n",
      "[5/100][105/100][2850] Loss_D: 0.005417 Loss_G: 0.004402 \n",
      "[5/100][105/100][2855] Loss_D: 0.007087 Loss_G: 0.004485 \n",
      "[5/100][105/100][2860] Loss_D: 0.009024 Loss_G: 0.007040 \n",
      "[5/100][105/100][2865] Loss_D: 0.008499 Loss_G: 0.004693 \n",
      "[5/100][105/100][2870] Loss_D: 0.008288 Loss_G: 0.009006 \n",
      "[5/100][105/100][2875] Loss_D: 0.006770 Loss_G: 0.005942 \n",
      "[5/100][105/100][2880] Loss_D: 0.006273 Loss_G: 0.005287 \n",
      "[5/100][105/100][2885] Loss_D: 0.004838 Loss_G: 0.003887 \n",
      "[5/100][105/100][2890] Loss_D: 0.003881 Loss_G: 0.003454 \n",
      "[5/100][105/100][2895] Loss_D: 0.004680 Loss_G: 0.005334 \n",
      "[5/100][105/100][2900] Loss_D: 0.005735 Loss_G: 0.005706 \n",
      "[5/100][105/100][2905] Loss_D: 0.005310 Loss_G: 0.006628 \n",
      "[5/100][105/100][2910] Loss_D: 0.004858 Loss_G: 0.006431 \n",
      "[5/100][105/100][2915] Loss_D: 0.004043 Loss_G: 0.006606 \n",
      "[5/100][105/100][2920] Loss_D: 0.008372 Loss_G: 0.007513 \n",
      "[5/100][105/100][2925] Loss_D: 0.006713 Loss_G: 0.008142 \n",
      "[5/100][105/100][2930] Loss_D: 0.008248 Loss_G: 0.006099 \n",
      "[5/100][105/100][2935] Loss_D: 0.008368 Loss_G: 0.006750 \n",
      "[5/100][105/100][2940] Loss_D: 0.006002 Loss_G: 0.003917 \n",
      "[5/100][105/100][2945] Loss_D: 0.005826 Loss_G: 0.003483 \n",
      "[5/100][105/100][2950] Loss_D: 0.007546 Loss_G: 0.006296 \n",
      "[5/100][105/100][2955] Loss_D: 0.009289 Loss_G: 0.009323 \n",
      "[5/100][105/100][2960] Loss_D: 0.011485 Loss_G: 0.006006 \n",
      "[5/100][105/100][2965] Loss_D: 0.005049 Loss_G: 0.007352 \n",
      "[5/100][105/100][2970] Loss_D: 0.005659 Loss_G: 0.006805 \n",
      "[5/100][105/100][2975] Loss_D: 0.004772 Loss_G: 0.006853 \n",
      "[5/100][105/100][2980] Loss_D: 0.008352 Loss_G: 0.005745 \n",
      "[5/100][105/100][2985] Loss_D: 0.006254 Loss_G: 0.004558 \n",
      "[5/100][105/100][2990] Loss_D: 0.006653 Loss_G: 0.003017 \n",
      "[5/100][105/100][2995] Loss_D: 0.007242 Loss_G: 0.004030 \n",
      "[5/100][105/100][3000] Loss_D: 0.006687 Loss_G: 0.004246 \n",
      "[6/100][105/100][3005] Loss_D: 0.007062 Loss_G: 0.006575 \n",
      "[6/100][105/100][3010] Loss_D: 0.007806 Loss_G: 0.009303 \n",
      "[6/100][105/100][3015] Loss_D: 0.008591 Loss_G: 0.007584 \n",
      "[6/100][105/100][3020] Loss_D: 0.007028 Loss_G: 0.006201 \n",
      "[6/100][105/100][3025] Loss_D: 0.006610 Loss_G: 0.007947 \n",
      "[6/100][105/100][3030] Loss_D: 0.007711 Loss_G: 0.005480 \n",
      "[6/100][105/100][3035] Loss_D: 0.004752 Loss_G: 0.005390 \n",
      "[6/100][105/100][3040] Loss_D: 0.006498 Loss_G: 0.007153 \n",
      "[6/100][105/100][3045] Loss_D: 0.004283 Loss_G: 0.004674 \n",
      "[6/100][105/100][3050] Loss_D: 0.004766 Loss_G: 0.006946 \n",
      "[6/100][105/100][3055] Loss_D: 0.008220 Loss_G: 0.005211 \n",
      "[6/100][105/100][3060] Loss_D: 0.007203 Loss_G: 0.005198 \n",
      "[6/100][105/100][3065] Loss_D: 0.007857 Loss_G: 0.006411 \n",
      "[6/100][105/100][3070] Loss_D: 0.007370 Loss_G: 0.007176 \n",
      "[6/100][105/100][3075] Loss_D: 0.007891 Loss_G: 0.004534 \n",
      "[6/100][105/100][3080] Loss_D: 0.004372 Loss_G: 0.005344 \n",
      "[6/100][105/100][3085] Loss_D: 0.004434 Loss_G: 0.005425 \n",
      "[6/100][105/100][3090] Loss_D: 0.006385 Loss_G: 0.005416 \n",
      "[6/100][105/100][3095] Loss_D: 0.004844 Loss_G: 0.004959 \n",
      "[6/100][105/100][3100] Loss_D: 0.005983 Loss_G: 0.006948 \n",
      "[6/100][105/100][3105] Loss_D: 0.006698 Loss_G: 0.006080 \n",
      "[6/100][105/100][3110] Loss_D: 0.004562 Loss_G: 0.006014 \n",
      "[6/100][105/100][3115] Loss_D: 0.006611 Loss_G: 0.006916 \n",
      "[6/100][105/100][3120] Loss_D: 0.003639 Loss_G: 0.008335 \n",
      "[6/100][105/100][3125] Loss_D: 0.007559 Loss_G: 0.006367 \n",
      "[6/100][105/100][3130] Loss_D: 0.006746 Loss_G: 0.006306 \n",
      "[6/100][105/100][3135] Loss_D: 0.007286 Loss_G: 0.009663 \n",
      "[6/100][105/100][3140] Loss_D: 0.006098 Loss_G: 0.004213 \n",
      "[6/100][105/100][3145] Loss_D: 0.005139 Loss_G: 0.005387 \n",
      "[6/100][105/100][3150] Loss_D: 0.004915 Loss_G: 0.004436 \n",
      "[6/100][105/100][3155] Loss_D: 0.006668 Loss_G: 0.004635 \n",
      "[6/100][105/100][3160] Loss_D: 0.005522 Loss_G: 0.004151 \n",
      "[6/100][105/100][3165] Loss_D: 0.005225 Loss_G: 0.005551 \n",
      "[6/100][105/100][3170] Loss_D: 0.006582 Loss_G: 0.005902 \n",
      "[6/100][105/100][3175] Loss_D: 0.007714 Loss_G: 0.005952 \n",
      "[6/100][105/100][3180] Loss_D: 0.006459 Loss_G: 0.006093 \n",
      "[6/100][105/100][3185] Loss_D: 0.007166 Loss_G: 0.005159 \n",
      "[6/100][105/100][3190] Loss_D: 0.005934 Loss_G: 0.004569 \n",
      "[6/100][105/100][3195] Loss_D: 0.006291 Loss_G: 0.006093 \n",
      "[6/100][105/100][3200] Loss_D: 0.006813 Loss_G: 0.005507 \n",
      "[6/100][105/100][3205] Loss_D: 0.004786 Loss_G: 0.004779 \n",
      "[6/100][105/100][3210] Loss_D: 0.004523 Loss_G: 0.006149 \n",
      "[6/100][105/100][3215] Loss_D: 0.006888 Loss_G: 0.005496 \n",
      "[6/100][105/100][3220] Loss_D: 0.005537 Loss_G: 0.007686 \n",
      "[6/100][105/100][3225] Loss_D: 0.010850 Loss_G: 0.006005 \n",
      "[6/100][105/100][3230] Loss_D: 0.007648 Loss_G: 0.004879 \n",
      "[6/100][105/100][3235] Loss_D: 0.004515 Loss_G: 0.007163 \n",
      "[6/100][105/100][3240] Loss_D: 0.007173 Loss_G: 0.007250 \n",
      "[6/100][105/100][3245] Loss_D: 0.006094 Loss_G: 0.007224 \n",
      "[6/100][105/100][3250] Loss_D: 0.006538 Loss_G: 0.008140 \n",
      "[6/100][105/100][3255] Loss_D: 0.004919 Loss_G: 0.005912 \n",
      "[6/100][105/100][3260] Loss_D: 0.003268 Loss_G: 0.005909 \n",
      "[6/100][105/100][3265] Loss_D: 0.005841 Loss_G: 0.007153 \n",
      "[6/100][105/100][3270] Loss_D: 0.007099 Loss_G: 0.006304 \n",
      "[6/100][105/100][3275] Loss_D: 0.006444 Loss_G: 0.006340 \n",
      "[6/100][105/100][3280] Loss_D: 0.004695 Loss_G: 0.005170 \n",
      "[6/100][105/100][3285] Loss_D: 0.006198 Loss_G: 0.004117 \n",
      "[6/100][105/100][3290] Loss_D: 0.005449 Loss_G: 0.006934 \n",
      "[6/100][105/100][3295] Loss_D: 0.007063 Loss_G: 0.005837 \n",
      "[6/100][105/100][3300] Loss_D: 0.006391 Loss_G: 0.005079 \n",
      "[6/100][105/100][3305] Loss_D: 0.007440 Loss_G: 0.004817 \n",
      "[6/100][105/100][3310] Loss_D: 0.005793 Loss_G: 0.006522 \n",
      "[6/100][105/100][3315] Loss_D: 0.006958 Loss_G: 0.006119 \n",
      "[6/100][105/100][3320] Loss_D: 0.003465 Loss_G: 0.006949 \n",
      "[6/100][105/100][3325] Loss_D: 0.005759 Loss_G: 0.005563 \n",
      "[6/100][105/100][3330] Loss_D: 0.005522 Loss_G: 0.006295 \n",
      "[6/100][105/100][3335] Loss_D: 0.006488 Loss_G: 0.005556 \n",
      "[6/100][105/100][3340] Loss_D: 0.007302 Loss_G: 0.006059 \n",
      "[6/100][105/100][3345] Loss_D: 0.005854 Loss_G: 0.006526 \n",
      "[6/100][105/100][3350] Loss_D: 0.006858 Loss_G: 0.006568 \n",
      "[6/100][105/100][3355] Loss_D: 0.004749 Loss_G: 0.006942 \n",
      "[6/100][105/100][3360] Loss_D: 0.005683 Loss_G: 0.004352 \n",
      "[6/100][105/100][3365] Loss_D: 0.004617 Loss_G: 0.004413 \n",
      "[6/100][105/100][3370] Loss_D: 0.004314 Loss_G: 0.007675 \n",
      "[6/100][105/100][3375] Loss_D: 0.007757 Loss_G: 0.005617 \n",
      "[6/100][105/100][3380] Loss_D: 0.006665 Loss_G: 0.006061 \n",
      "[6/100][105/100][3385] Loss_D: 0.007027 Loss_G: 0.005816 \n",
      "[6/100][105/100][3390] Loss_D: 0.008256 Loss_G: 0.004829 \n",
      "[6/100][105/100][3395] Loss_D: 0.006242 Loss_G: 0.004862 \n",
      "[6/100][105/100][3400] Loss_D: 0.006311 Loss_G: 0.009593 \n",
      "[6/100][105/100][3405] Loss_D: 0.007847 Loss_G: 0.004517 \n",
      "[6/100][105/100][3410] Loss_D: 0.006209 Loss_G: 0.004291 \n",
      "[6/100][105/100][3415] Loss_D: 0.005989 Loss_G: 0.006423 \n",
      "[6/100][105/100][3420] Loss_D: 0.005422 Loss_G: 0.003643 \n",
      "[6/100][105/100][3425] Loss_D: 0.004434 Loss_G: 0.005894 \n",
      "[6/100][105/100][3430] Loss_D: 0.005649 Loss_G: 0.009120 \n",
      "[6/100][105/100][3435] Loss_D: 0.007208 Loss_G: 0.007118 \n",
      "[6/100][105/100][3440] Loss_D: 0.007316 Loss_G: 0.005134 \n",
      "[6/100][105/100][3445] Loss_D: 0.006039 Loss_G: 0.009180 \n",
      "[6/100][105/100][3450] Loss_D: 0.005344 Loss_G: 0.004796 \n",
      "[6/100][105/100][3455] Loss_D: 0.004087 Loss_G: 0.007295 \n",
      "[6/100][105/100][3460] Loss_D: 0.004952 Loss_G: 0.005567 \n",
      "[6/100][105/100][3465] Loss_D: 0.004745 Loss_G: 0.004652 \n",
      "[6/100][105/100][3470] Loss_D: 0.004007 Loss_G: 0.003518 \n",
      "[6/100][105/100][3475] Loss_D: 0.006777 Loss_G: 0.005256 \n",
      "[6/100][105/100][3480] Loss_D: 0.005683 Loss_G: 0.004988 \n",
      "[6/100][105/100][3485] Loss_D: 0.004880 Loss_G: 0.006704 \n",
      "[6/100][105/100][3490] Loss_D: 0.004658 Loss_G: 0.004227 \n",
      "[6/100][105/100][3495] Loss_D: 0.006572 Loss_G: 0.007057 \n",
      "[6/100][105/100][3500] Loss_D: 0.005368 Loss_G: 0.005418 \n",
      "[7/100][105/100][3505] Loss_D: 0.009533 Loss_G: 0.007407 \n",
      "[7/100][105/100][3510] Loss_D: 0.008810 Loss_G: 0.006634 \n",
      "[7/100][105/100][3515] Loss_D: 0.006126 Loss_G: 0.006254 \n",
      "[7/100][105/100][3520] Loss_D: 0.003852 Loss_G: 0.003240 \n",
      "[7/100][105/100][3525] Loss_D: 0.003455 Loss_G: 0.004649 \n",
      "[7/100][105/100][3530] Loss_D: 0.003843 Loss_G: 0.005616 \n",
      "[7/100][105/100][3535] Loss_D: 0.003571 Loss_G: 0.007563 \n",
      "[7/100][105/100][3540] Loss_D: 0.005447 Loss_G: 0.007786 \n",
      "[7/100][105/100][3545] Loss_D: 0.006440 Loss_G: 0.005306 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/100][105/100][3550] Loss_D: 0.006843 Loss_G: 0.006590 \n",
      "[7/100][105/100][3555] Loss_D: 0.010885 Loss_G: 0.008217 \n",
      "[7/100][105/100][3560] Loss_D: 0.007823 Loss_G: 0.005529 \n",
      "[7/100][105/100][3565] Loss_D: 0.006486 Loss_G: 0.006630 \n",
      "[7/100][105/100][3570] Loss_D: 0.004492 Loss_G: 0.006928 \n",
      "[7/100][105/100][3575] Loss_D: 0.004888 Loss_G: 0.004890 \n",
      "[7/100][105/100][3580] Loss_D: 0.003998 Loss_G: 0.004077 \n",
      "[7/100][105/100][3585] Loss_D: 0.005253 Loss_G: 0.004575 \n",
      "[7/100][105/100][3590] Loss_D: 0.006821 Loss_G: 0.007693 \n",
      "[7/100][105/100][3595] Loss_D: 0.007880 Loss_G: 0.004962 \n",
      "[7/100][105/100][3600] Loss_D: 0.004799 Loss_G: 0.005597 \n",
      "[7/100][105/100][3605] Loss_D: 0.010919 Loss_G: 0.007115 \n",
      "[7/100][105/100][3610] Loss_D: 0.007371 Loss_G: 0.009385 \n",
      "[7/100][105/100][3615] Loss_D: 0.003818 Loss_G: 0.006177 \n",
      "[7/100][105/100][3620] Loss_D: 0.005859 Loss_G: 0.006213 \n",
      "[7/100][105/100][3625] Loss_D: 0.006285 Loss_G: 0.005348 \n",
      "[7/100][105/100][3630] Loss_D: 0.003143 Loss_G: 0.003901 \n",
      "[7/100][105/100][3635] Loss_D: 0.006407 Loss_G: 0.003196 \n",
      "[7/100][105/100][3640] Loss_D: 0.003588 Loss_G: 0.005830 \n",
      "[7/100][105/100][3645] Loss_D: 0.007379 Loss_G: 0.005447 \n",
      "[7/100][105/100][3650] Loss_D: 0.005793 Loss_G: 0.006855 \n",
      "[7/100][105/100][3655] Loss_D: 0.004817 Loss_G: 0.006241 \n",
      "[7/100][105/100][3660] Loss_D: 0.006523 Loss_G: 0.011121 \n",
      "[7/100][105/100][3665] Loss_D: 0.005378 Loss_G: 0.007758 \n",
      "[7/100][105/100][3670] Loss_D: 0.010207 Loss_G: 0.007416 \n",
      "[7/100][105/100][3675] Loss_D: 0.009404 Loss_G: 0.004029 \n",
      "[7/100][105/100][3680] Loss_D: 0.005860 Loss_G: 0.005103 \n",
      "[7/100][105/100][3685] Loss_D: 0.003409 Loss_G: 0.003207 \n",
      "[7/100][105/100][3690] Loss_D: 0.006507 Loss_G: 0.002291 \n",
      "[7/100][105/100][3695] Loss_D: 0.003569 Loss_G: 0.005277 \n",
      "[7/100][105/100][3700] Loss_D: 0.005917 Loss_G: 0.008755 \n",
      "[7/100][105/100][3705] Loss_D: 0.009718 Loss_G: 0.006557 \n",
      "[7/100][105/100][3710] Loss_D: 0.006841 Loss_G: 0.011194 \n",
      "[7/100][105/100][3715] Loss_D: 0.005956 Loss_G: 0.010134 \n",
      "[7/100][105/100][3720] Loss_D: 0.009742 Loss_G: 0.007549 \n",
      "[7/100][105/100][3725] Loss_D: 0.007505 Loss_G: 0.007677 \n",
      "[7/100][105/100][3730] Loss_D: 0.007096 Loss_G: 0.008345 \n",
      "[7/100][105/100][3735] Loss_D: 0.009799 Loss_G: 0.007556 \n",
      "[7/100][105/100][3740] Loss_D: 0.008461 Loss_G: 0.008394 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-275-1201038fbbae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnetG_neg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# gen_losses, disc_losses = train_GAN(netD_neg, netG_neg, negative=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_GAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetD_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetG_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-266-95cba275f224>\u001b[0m in \u001b[0;36mtrain_GAN\u001b[1;34m(netD, netG, negative, steps_per_epoch, epochs)\u001b[0m\n\u001b[0;32m     53\u001b[0m                     \u001b[0mstdD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                     \u001b[0moutputD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                     \u001b[0moptimizerD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;31m#                     print('AAAAAAAAA mse:=WWWWWWWWWWWWWWWWWWWWWW')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;31m############################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "netD_neg.train()\n",
    "netG_neg.train()\n",
    "# gen_losses, disc_losses = train_GAN(netD_neg, netG_neg, negative=True)\n",
    "train_GAN(netD_neg, netG_neg, negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(gen_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(disc_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netD_neg.state_dict(), './netD_neg-1m')\n",
    "torch.save(netG_neg.state_dict(), './netG_neg-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetD(\n",
       "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
       "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
       "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD_neg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7561"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetG(\n",
       "  (netGen): Sequential(\n",
       "    (0): Linear(in_features=3726, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=3706, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# networks\n",
    "netD_neg_test = NetD(negative_feedback_mask.shape[1]).cuda()\n",
    "netG_neg_test = NetG(negative_feedback_mask.shape[1]).cuda()\n",
    "\n",
    "netD_neg_test.eval()\n",
    "netG_neg_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition, X, idxs = batch_generator(X_neg, y_neg, batch_size=256)\n",
    "\n",
    "X = X.cuda()\n",
    "condition = condition.cuda()\n",
    "# real = Variable(X)\n",
    "\n",
    "noise = torch.randn(256, nz).cuda()\n",
    "e_mask = torch.Tensor(tr[idxs]>0).cuda()\n",
    "\n",
    "concated = torch.cat((noise, condition), 1)\n",
    "fake = netG_neg(e_mask, concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test = netG_neg_test(e_mask, concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14022, device='cuda:0'),\n",
       " tensor(8502, device='cuda:0'),\n",
       " tensor(10039., device='cuda:0'),\n",
       " tensor(16809., device='cuda:0'),\n",
       " tensor(38566., device='cuda:0'))"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake >= 0.5).sum(), ((fake >= 0.5) * (condition==0)).sum(), condition.sum(), X.sum(), e_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = (fake > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test = (fake_test > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5498, device='cuda:0'), tensor(0.5527, device='cuda:0'))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake * condition).sum()/condition.sum(), (fake * X).sum()/X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4833, device='cuda:0'), tensor(0.4881, device='cuda:0'))"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_test * condition).sum()/condition.sum(), (fake_test * X).sum()/X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5572, device='cuda:0')"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuraccy on zeros (positive feedbacks)\n",
    "(fake * (1-condition)*X).sum()/(X * (1 - condition)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4953, device='cuda:0')"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_test * (1-condition)*X).sum()/(X * (1 - condition)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7825987038654226"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuraccy on zeros (positive feedbacks)\n",
    "((1 - fake)*(1-condition)*(torch.from_numpy(positive_feedback_mask[idxs]).float().cuda())).cpu().numpy().sum()/((positive_feedback_mask[idxs]).astype(float)*(1-condition).cpu().numpy()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X == torch.from_numpy(negative_feedback_mask[idxs]).float().cuda()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.519327113113021"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1 - fake_test)*(1-condition)*(torch.from_numpy(positive_feedback_mask[idxs]).float().cuda())).cpu().numpy().sum()/((positive_feedback_mask[idxs]).astype(float)*(1-condition).cpu().numpy()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(18663, device='cuda:0'),\n",
       " tensor(13811, device='cuda:0'),\n",
       " tensor(10039., device='cuda:0'),\n",
       " tensor(16809., device='cuda:0'))"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_test >= 0.5).sum(), ((fake_test >= 0.5) * (condition==0)).sum(), condition.sum(), X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14022, device='cuda:0'),\n",
       " tensor(8502, device='cuda:0'),\n",
       " tensor(10039., device='cuda:0'),\n",
       " tensor(16809., device='cuda:0'))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake >= 0.5).sum(), ((fake >= 0.5) * (condition==0)).sum(), condition.sum(), X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14021, device='cuda:0')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18663, device='cuda:0')"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_test > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3706])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(34164, device='cuda:0'),\n",
       " tensor(24892, device='cuda:0'),\n",
       " tensor(10422., device='cuda:0'))"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake > 0.48).sum(), ((fake > 0.48) * (condition==0)).sum(), condition.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_mask = torch.Tensor(tr[idxs]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(condition.cpu().numpy(), X.cpu().numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35208., device='cuda:0')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake > 0.4).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6323., device='cuda:0'),)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.4).float() * (condition==0).float() * X).sum(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24702., device='cuda:0')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float() * (condition==0).float()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9492, device='cuda:0')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float()).sum()/X.sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33895, device='cuda:0')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6068., device='cuda:0')"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float() *(condition==0).float()* X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4437, device='cuda:0')"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float() *(condition==0).float()* X).sum()/((fake > 0.5) * (condition==0)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2428, device='cuda:0')"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake_test > 0.5).float() *(condition==0).float()* X).sum()/((fake_test > 0.5) * (condition==0)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2558, device='cuda:0')"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float() * (condition==0).float()).sum()/(X * (1 - condition)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5456, device='cuda:0')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float() * (condition==0).float()).sum()/(X * (1 - condition)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2523, device='cuda:0')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float()).sum()/((condition)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2523, device='cuda:0')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float()).sum()/((condition)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4956, device='cuda:0')"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake_test > 0.5).float() * (condition==0).float() * X).sum()/(X * (1 - condition)).sum() # predicted accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9492, device='cuda:0')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake > 0.5).float() ).sum()/X.sum() # whole accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4893, device='cuda:0')"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fake_test > 0.5).float() ).sum()/X.sum() # whole accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((fake > 0.5).float() * (condition==0).float() * X).sum()/(X * (1 - fake)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses_tr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = torch.randn(train.shape[0], nz).to(device)\n",
    "# noisev = Variable(noise)\n",
    "# fake = netG_tr(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.around(fake.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = fake * (fake <= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == (tr + vr)[:fake.shape[0], :].round()).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there is a significant bias towards higher ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networks\n",
    "netD_augm = NetD().to(device)\n",
    "netG_augm = NetG().to(device)\n",
    "print(netD_augm)\n",
    "print(netG_augm)\n",
    "optimizerG = optim.RMSprop(netG_augm.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD_augm.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1]).to(device)\n",
    "mone = (-1 * one).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(train.shape[0], nz).to(device)\n",
    "noisev = Variable(noise)\n",
    "fake = netG_augm(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.around(fake.detach().cpu().numpy())\n",
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without train\n",
    "print(5, (5 == fake.round()).sum(), (5 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == (tr + vr)[:fake.shape[0], :].round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netD_augm.load_state_dict(torch.load('./netG_augm-1m'))\n",
    "# netD_augm.load_state_dict(torch.load('./netD_augm-1m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD_augm.train()\n",
    "netG_augm.train()\n",
    "eval_losses_aug = train_GAN(netD_augm, netG_augm, augmented_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses_aug)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netG_tr.eval()\n",
    "netG_augm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(train.shape[0], nz).to(device)\n",
    "noisev = Variable(noise)\n",
    "fake = netG_augm(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.around(fake.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake = fake * (fake <= 5).astype(int)\n",
    "\n",
    "fake = fake.clip(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == (tr + vr)[:fake.shape[0], :].round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(train.shape[0], nz).to(device)\n",
    "noisev = Variable(noise)\n",
    "\n",
    "fake_tr = netG_tr(noisev)\n",
    "fake_aug = netG_augm(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(fake_tr.round()), torch.unique(fake_aug.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tr = fake_tr.clamp(0,5).detach().cpu().numpy().round()\n",
    "fake_aug = fake_aug.clamp(0,5).detach().cpu().numpy().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5, (5 == fake_tr).sum(), (5 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(4, (4 == fake_tr).sum(), (4 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(3, (3 == fake_tr).sum(), (3 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(2, (2 == fake_tr).sum(), (2 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(1, (1 == fake_tr).sum(), (1 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(0, (0 == fake_tr).sum(), (0 == (tr + vr)[:fake.shape[0], :]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5, (5 == fake_aug).sum(), (5 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(4, (4 == fake_aug).sum(), (4 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(3, (3 == fake_aug).sum(), (3 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(2, (2 == fake_aug).sum(), (2 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(1, (1 == fake_aug).sum(), (1 == (tr + vr)[:fake.shape[0], :]).sum())\n",
    "print(0, (0 == fake_aug).sum(), (0 == (tr + vr)[:fake.shape[0], :]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(tr), get_sparsity(fake_tr), get_sparsity(fake_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_orig, vr_1 = loadData('./ml-1m/ratings.dat', delimiter='::', seed=seed,  transpose=False, valfrac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter \n",
    "import matrix_factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ix = np.random.randint(0, fake.shape[0], 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding_fake_autoenc = fake_tr[rand_ix,:]\n",
    "adding_fake_autoenc_lus_gan = fake_aug[rand_ix,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fake_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(adding_fake_autoenc_lus_gan[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adding_fake_autoenc == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adding_fake_autoenc_lus_gan == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(adding_fake_autoenc_lus_gan[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_fake[0,0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_fake_autoenc_lus_gan[0,0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_auto_enc = np.append(tr, adding_fake_autoenc, axis=0)\n",
    "tr_auto_enc_plus_gan = np.append(tr, adding_fake_autoenc_lus_gan, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD = matrix_factorization.ExplicitMF(tr, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(augmented_train.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD = matrix_factorization.ExplicitMF(augmented_train.cpu().numpy(), 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD = matrix_factorization.ExplicitMF(tr, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([50], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD = matrix_factorization.ExplicitMF(augmented_train.cpu().numpy(), 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([50], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.shape, augmented_train.cpu().numpy().shape, tr_auto_enc.shape, tr_auto_enc_plus_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(tr_auto_enc), get_sparsity(tr_auto_enc_plus_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25, 40]\n",
    "\n",
    "MF_SGD = matrix_factorization.ExplicitMF(tr_auto_enc, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_array = [1, 2, 5, 10, 25, 40]\n",
    "\n",
    "MF_SGD = matrix_factorization.ExplicitMF(tr_auto_enc_plus_gan, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity(tr_auto_enc_plus_gan), tr_auto_enc_plus_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(tr_auto_enc_plus_gan, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(tr_auto_enc_plus_gan, 40, learning='sgd', verbose=True)\n",
    "# iter_array = [1, 2, 5, 10, 25, 50, 100, 200]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve([60], vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(fake_aug, 40, learning='sgd', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_tr = augmented_train.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(augmented_tr, 40, learning='sgd', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(tr, 40, learning='sgd', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(tr, 40, learning='als', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_SGD = matrix_factorization.ExplicitMF(augmented_tr, 40, learning='als', verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 60]\n",
    "\n",
    "# iter_array = [10]\n",
    "# iter_array = [1, 2, 5, 10, 25]\n",
    "MF_SGD.calculate_learning_curve(iter_array, vr, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
