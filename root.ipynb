{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import sys\n",
    "from dataLoader import loadData\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading Movielens-1m\n",
    "# !curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "# #     http://www.grouplens.org/system/files/ml-1m.zip\n",
    "# !unzip ml-1m.zip\n",
    "# !cd ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data...\n",
      "data read in 5.703738212585449 seconds\n",
      "loaded dense data matrix\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "tr, vr = loadData('./ml-1m/ratings.dat', delimiter='::', seed=seed, transpose=False, valfrac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./tr_movielens_1m', tr)\n",
    "np.save('./vr_movielens_1m', vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [3., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(mat):\n",
    "    sparsity = float(len(mat.nonzero()[0]))\n",
    "    sparsity /= (mat.shape[0] * mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.021525859265269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44683670296601535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from os.path import isfile, isdir, join\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrD = 5e-4\n",
    "lrG = 5e-4\n",
    "batch_size = 64\n",
    "cuda = True\n",
    "epochs = 0 #change\n",
    "nz = 10\n",
    "d_iter = 5\n",
    "g_iter = 1\n",
    "lamba = 1e-3 # constant for L2 penalty (diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available()==True:\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device =\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Dropout(p=0.5)\n",
      "    (5): Linear(in_features=1024, out_features=3706, bias=True)\n",
      "    (6): Sigmoid()\n",
      "    (7): Dropout(p=0.6)\n",
      "  )\n",
      ")\n",
      "NetD(\n",
      "  (t1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (b1): Linear(in_features=3706, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=3706, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "features_length = train.shape[1]\n",
    "class NetD(torch.nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(NetD, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        # top\n",
    "        self.t1 = torch.nn.Linear(features_length, 1024)\n",
    "        # bottom\n",
    "        self.b1 = torch.nn.Linear(features_length, 1024)\n",
    "        # combined\n",
    "        self.fc = torch.nn.Linear(2 * 1024, features_length)\n",
    "    def forward(self, xr, xf):\n",
    "        # get filt\n",
    "#         filt = (torch.abs((real > 0.3).float() * fake - real))/real.shape[0]\n",
    "        filt = torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda())/(fake == 0).sum()\n",
    "#         filt = torch.abs((real != 0).float().cuda() * fake.cuda() - real.cuda())\n",
    "\n",
    "#         filt = torch.abs((xr != 0).int() * xf - xr)\n",
    "#         filt = 1 - (xr * (xf >= 0.5).float()) - ((1-xr) * (xf < 0.5).float())\n",
    "        # random swap\n",
    "        idr = torch.multinomial(torch.Tensor([0.5,0.5]), xr.size(0), replacement=True)\n",
    "        idrx = idr.float().unsqueeze(1).expand_as(xr)\n",
    "        if self.use_cuda: \n",
    "            idrx = idrx.cuda()\n",
    "        idrx = Variable(idrx)\n",
    "        xt = xr * idrx + xf * (1 - idrx)\n",
    "        xb = xr * (1 - idrx) + xf * idrx\n",
    "        # top : real\n",
    "        xt = F.relu(self.t1(xt))\n",
    "        # bottom : fake\n",
    "        xb = F.relu(self.b1(xb))\n",
    "        # combined\n",
    "        x = torch.cat((xt, xb), 1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        # apply filter, aggregate\n",
    "#         print(filt.type(), x.type())\n",
    "        x = filt * x\n",
    "\n",
    "        x = x.mean(dim = 1).squeeze()\n",
    "        # use sign, because of swapping\n",
    "        sgn = idr * 2 - 1\n",
    "        if self.use_cuda: \n",
    "            sgn = sgn.cuda()\n",
    "        sgn = Variable(sgn.float())\n",
    "        x = sgn * x\n",
    "        return x\n",
    "        \n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(nz, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(1024, features_length),\n",
    "#     torch.nn.Sigmoid()*5\n",
    "#     )\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(NetG, self).__init__()\n",
    "\n",
    "        self.net = torch.nn.Sequential( \n",
    "                                torch.nn.Linear(nz, 1024), \n",
    "                                torch.nn.ReLU(), \n",
    "                                torch.nn.Linear(1024, 1024), \n",
    "                                torch.nn.Sigmoid(), \n",
    "                                nn.Dropout(0.5),\n",
    "                                torch.nn.Linear(1024, features_length), \n",
    "                                torch.nn.Sigmoid(), \n",
    "                                nn.Dropout(0.6)\n",
    "                                )\n",
    "\n",
    "#         self.net = nn.Sequential(\n",
    "#                                  nn.Linear(nz,1024),\n",
    "# #                                  nn.Dropout(0.3)\n",
    "#                                  nn.ReLU(),\n",
    "#                                  nn.Linear(1024,2048),\n",
    "#                                  nn.Sigmoid(),\n",
    "#                                  nn.Dropout(0.3),\n",
    "#                                  nn.Linear(2048,features_length),\n",
    "# #                                  nn.Sigmoid()\n",
    "#                                  nn.Dropout(0.5)\n",
    "#                                     )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "#         return x\n",
    "        return x*5 # to get values in range [0,5]\n",
    "    \n",
    "# networks\n",
    "netD = NetD().to(device)\n",
    "netG = NetG().to(device)\n",
    "print(netG)\n",
    "print(netD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.FloatTensor([1]).to(device)\n",
    "mone = (one * -1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in netD.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #\n",
    "    \n",
    "for p in netG.parameters(): # reset requires_grad\n",
    "    p.requires_grad = True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch(mat, batch_size=16):\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(mat.shape, rand_rows)\n",
    "#     print(mat[rand_rows].shape)\n",
    "    return mat[rand_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3706)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_batch(train, batch_size=batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.autograd.Variable(torch.Tensor(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_my(x_r, x_g): # custom loss -todo\n",
    "    return torch.sum(torch.abs((x_r != 0).float() * x_g - x_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 300\n",
    "gen_iterations = 0\n",
    "eval_losses = []\n",
    "for epoch in range(0):\n",
    "#     data_iter = iter(data_loader)\n",
    "    i = 0\n",
    "    while i < steps_per_epoch:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "        d_iter = d_iter\n",
    "        j = 0\n",
    "        while j < d_iter*5:\n",
    "            j += 1\n",
    "            # load real data\n",
    "            i += 1\n",
    "#             X, _ = data_iter.next()\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X += torch.Tensor(np.random.normal(0, 0.2, X.shape))\n",
    "#             print(X >= 0.5)\n",
    "# #             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            # generate fake data\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            with torch.no_grad():\n",
    "                noisev = Variable(noise) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "#             print(real[0,:20], fake[0,:20])\n",
    "            real + fake * (real == 0).float()\n",
    "            fake = fake * Variable(real != 0).float().cuda()\n",
    "#             real + fake * (real == 0).float()\n",
    "#             print(real[0,:20], fake[0,:20])\n",
    "            fake.requires_grad = False\n",
    "#             print(real.shape, fake.shape)\n",
    "    \n",
    "            # compute gradient, take step\n",
    "            netD.zero_grad()\n",
    "#             print('real', real[:10, :20])\n",
    "#             print('fake', fake[:10, :20])\n",
    "#             print(real.type(), fake.type())\n",
    "#             print(fake)\n",
    "            out = netD(real, fake)\n",
    "            \n",
    "            outputD = torch.mean(out) + lamba * out.norm()\n",
    "            stdD = torch.std(out)\n",
    "            outputD.backward(mone)\n",
    "            optimizerD.step()\n",
    "#             print(out.shape)\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        g_iter = g_iter\n",
    "        j = 0\n",
    "        while j < g_iter*5:\n",
    "            j += 1\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            # load real data\n",
    "            i += 1\n",
    "            X = get_random_batch(train, batch_size=batch_size)\n",
    "#             X += torch.Tensor(np.random.normal(0, 0.2, X.shape))\n",
    "#             X = X.view(X.size(0), -1)\n",
    "#             X = (X >= 0.5).float()\n",
    "            if cuda: \n",
    "                X = X.cuda()\n",
    "            real = Variable(X)\n",
    "            \n",
    "            # update generator\n",
    "            noise = torch.randn(batch_size, nz)\n",
    "            if cuda: \n",
    "                noise = noise.cuda()\n",
    "            noisev = Variable(noise)\n",
    "            \n",
    "            fake = netG(noisev)\n",
    "            real + fake * (real == 0).float()\n",
    "            fake = fake * Variable(real != 0).float().cuda()\n",
    "#             fake = fake * Variable(real != 0).float().cuda()\n",
    "#             fake.requires_grad = False\n",
    "#             fake = Variable(netG(noisev)).data\n",
    "#             fake = fake * Variable(((real != 0) & (fake > 0.8))).float().cuda()\n",
    "#             fake.requires_grad = True\n",
    "            \n",
    "            out = netD(real, fake)\n",
    "            outputG = torch.mean(out) + lamba * out.norm()\n",
    "            stdG = torch.std(out)\n",
    "            outputG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "\n",
    "#             print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f '% (epoch, epochs, i, len(data_loader), gen_iterations, outputD.item(), outputG.item()))\n",
    "#             print('output_D', outputD.item(), gen_iterations)\n",
    "#             print('output_G', outputG.item(), gen_iterations)\n",
    "#             print('std_D', stdD.item(), gen_iterations)\n",
    "#             print('std_G', stdG.item(), gen_iterations)\n",
    "            torch.save(netG.state_dict(), './netG-1m')\n",
    "            torch.save(netD.state_dict(), './netD-1m')\n",
    "            # evaluation\n",
    "            if gen_iterations % 100 == 0: # todo- to change\n",
    "#                 gen.eval()\n",
    "#                 z_vector_eval = make_some_noise(128)\n",
    "#                 fake_rows_eval = gen(z_vector_eval)\n",
    "#                 real_rows_eval = get_random_batch(train, 128)\n",
    "        #         print(fake_rows[0][:10]) enable to see some results\n",
    "#                 fake = Variable(netG(noisev).data).round()\n",
    "#                 fake = ((real != 0) & (fake != 0))\n",
    "#                 print(fake)\n",
    "                eval_loss = F.mse_loss(fake, real, reduction='mean')\n",
    "                eval_losses.append(eval_loss)\n",
    "                print('Epoch number {}. my distance between random real and fake samples {}'.format(epoch, d_my(real, fake)))\n",
    "                print('Epoch number {}. MSE distance between random real and fake samples {}'.format(epoch, eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(netG.state_dict(), './netG-1m')\n",
    "# torch.save(netD.state_dict(), './netD-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(train.shape[0], nz).to(device)\n",
    "noisev = Variable(noise)\n",
    "fake = netG(noisev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6040, 3706])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.around(fake.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = fake * (fake <= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1751784 226310\n",
      "4 616209 348971\n",
      "3 91897 261197\n",
      "2 3749 107557\n",
      "1 17 56174\n",
      "0 19920584 21384031\n"
     ]
    }
   ],
   "source": [
    "print(5, (5 == fake.round()).sum(), (5 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(4, (4 == fake.round()).sum(), (4 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(3, (3 == fake.round()).sum(), (3 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(2, (2 == fake.round()).sum(), (2 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(1, (1 == fake.round()).sum(), (1 == (tr + vr)[:fake.shape[0], :].round()).sum())\n",
    "print(0, (0 == fake.round()).sum(), (0 == (tr + vr)[:fake.shape[0], :].round()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train > 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.934857739195076e-06"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[0,:] > 3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [3., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.Tensor(tr.copy()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.021525859265269"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mask = (train == 0).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_feedback_mask = (train > 3).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_feedback_mask = ((train < 4).to(device).float() * (1 - zero_mask)).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((positive_feedback_mask + negative_feedback_mask) != zero_mask).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7090908603553212"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(negative_feedback_mask.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING DENOISING AUTOENCODER ON NEGATIVE FEEDBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class denoising_autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, z=32):\n",
    "        super(denoising_autoencoder, self).__init__()\n",
    "        self.encoder=nn.Sequential(\n",
    "                      nn.Linear(input_size, 1024),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(1024,512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(512, z),\n",
    "#                       nn.Sigmoid()\n",
    "                      )\n",
    "\n",
    "        self.decoder=nn.Sequential(\n",
    "                      nn.Linear(z, 512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(512, 1024),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(1024, input_size),\n",
    "#                       nn.Sigmoid(),\n",
    "                      )\n",
    "    \n",
    " \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "#         print(z.shape)\n",
    "        x = self.decoder(z)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = denoising_autoencoder(input_size=train[0,:].shape[0]).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.RMSprop(model.parameters(),lr=0.0001, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_masked_batch(mat, batch_size = 32, p=0.5):\n",
    "    '''\n",
    "    This works as a trainloader for denoising autoencoder.\n",
    "    Randomly masks observed entries (replaces 1s with 0s) to add a noise\n",
    "    '''\n",
    "    rand_rows = np.random.randint(mat.shape[0], size=batch_size)\n",
    "#     print(rand_rows)\n",
    "#     return mat[rand_rows], mat[rand_rows]\n",
    "    orig = mat[rand_rows].clone()\n",
    "    corrupted = mat[rand_rows].clone()\n",
    "    mask_arr = torch.FloatTensor((np.random.rand(orig.shape[0], orig.shape[1]) > p)).to(device)\n",
    "\n",
    "    return orig, corrupted*mask_arr, rand_rows\n",
    "\n",
    "orig, masked, _ = get_random_masked_batch(negative_feedback_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3585064759848895"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(orig.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1822045331894226"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(masked.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1822045331894226"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(torch.nn.functional.dropout(masked, training=False).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.functional.dropout(orig, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Epoch:  0\n",
      "======> epoch: 0/120, Loss:0.19880089163780212\n",
      "======> epoch: 0/120, Loss:0.16642989218235016\n",
      "======> epoch: 0/120, Loss:0.13725459575653076\n",
      "======> epoch: 0/120, Loss:0.1530311554670334\n",
      "======> epoch: 0/120, Loss:0.1279515027999878\n",
      "======> epoch: 0/120, Loss:0.16339918971061707\n",
      "======> epoch: 0/120, Loss:0.13594625890254974\n",
      "======> epoch: 0/120, Loss:0.1364845633506775\n",
      "======> epoch: 0/120, Loss:0.1684131920337677\n",
      "======> epoch: 0/120, Loss:0.18973736464977264\n",
      "Entering Epoch:  1\n",
      "======> epoch: 1/120, Loss:0.1416318714618683\n",
      "======> epoch: 1/120, Loss:0.11005086451768875\n",
      "======> epoch: 1/120, Loss:0.1717134416103363\n",
      "======> epoch: 1/120, Loss:0.1609048992395401\n",
      "======> epoch: 1/120, Loss:0.1354023814201355\n",
      "======> epoch: 1/120, Loss:0.1453096866607666\n",
      "======> epoch: 1/120, Loss:0.16222523152828217\n",
      "======> epoch: 1/120, Loss:0.12530158460140228\n",
      "======> epoch: 1/120, Loss:0.1431865394115448\n",
      "======> epoch: 1/120, Loss:0.1512361615896225\n",
      "Entering Epoch:  2\n",
      "======> epoch: 2/120, Loss:0.14695627987384796\n",
      "======> epoch: 2/120, Loss:0.12176667153835297\n",
      "======> epoch: 2/120, Loss:0.1773013472557068\n",
      "======> epoch: 2/120, Loss:0.14754712581634521\n",
      "======> epoch: 2/120, Loss:0.15893146395683289\n",
      "======> epoch: 2/120, Loss:0.14212852716445923\n",
      "======> epoch: 2/120, Loss:0.12194572389125824\n",
      "======> epoch: 2/120, Loss:0.1638011932373047\n",
      "======> epoch: 2/120, Loss:0.15314128994941711\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-36b80ac85af1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"======> epoch: {}/{}, Loss:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mtrain_den_ae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_unsqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-36b80ac85af1>\u001b[0m in \u001b[0;36mtrain_den_ae\u001b[1;34m(mat, _unsqueeze)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Entering Epoch: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0morig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_random_masked_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m#-----------------Forward Pass----------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-d9791a25a3c0>\u001b[0m in \u001b[0;36mget_random_masked_batch\u001b[1;34m(mat, batch_size, p)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrand_rows\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcorrupted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrand_rows\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmask_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrupted\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmask_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrand_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losslist = []\n",
    "def train_den_ae(mat, _unsqueeze=True):\n",
    "    epochs = 120\n",
    "    # l = len(trainloader)\n",
    "    # l = 120\n",
    "#     losslist = []\n",
    "    epochloss = 0\n",
    "    running_loss = 0\n",
    "    steps_per_epoch = 100\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(\"Entering Epoch: \", epoch)\n",
    "        for i in range(steps_per_epoch):\n",
    "            orig, masked, _ = get_random_masked_batch(mat, batch_size=batch_size)\n",
    "\n",
    "            #-----------------Forward Pass----------------------\n",
    "            if _unsqueeze:\n",
    "                masked = masked.unsqueeze(2)\n",
    "            output = model(masked)\n",
    "    #         print(orig.shape, output.shape)\n",
    "            loss = criterion(output, orig)\n",
    "            #-----------------Backward Pass---------------------\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    #         running_loss += loss.item()\n",
    "    #         epochloss += loss.item()\n",
    "    #         #-----------------Log-------------------------------\n",
    "    #         losslist.append(running_loss/l)\n",
    "    #         running_loss=0\n",
    "    #     print(\"======> epoch: {}/{}, Loss:{}\".format(epoch,epochs,loss.item()))\n",
    "            if i%10 == 0:\n",
    "                running_loss += loss.item()\n",
    "                epochloss += loss.item()\n",
    "                #-----------------Log-------------------------------\n",
    "                losslist.append(running_loss/steps_per_epoch)\n",
    "                running_loss=0\n",
    "                print(\"======> epoch: {}/{}, Loss:{}\".format(epoch,epochs,loss.item()))\n",
    "                \n",
    "train_den_ae(train, _unsqueeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losslist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, masked, _ = get_random_masked_batch(train, batch_size=1, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(orig[0][:400] > 0).sum(), (masked[0][:400] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------Forward Pass----------------------\n",
    "output = model(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((5*output[0]).round() >1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5*output).round()[0][2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, masked, _ = get_random_masked_batch(negative_feedback_mask, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig[0][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked[0][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------Forward Pass----------------------\n",
    "output = model(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig[0][:400](orig.round() > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(masked.round() > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output.round() > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.round()[0,100:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig[0,100:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_denoising_autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, inSize,fSize = 32, nz=24):  #sigma is the corruption level\n",
    "        super(conv_denoising_autoencoder, self).__init__()\n",
    "        #define layers here\n",
    "\n",
    "        self.inp_size = inSize\n",
    "        self.nz = nz\n",
    "        self.fSize = 32\n",
    "#         self.imSize = imSize\n",
    "#         self.sigma = sigma\n",
    "#         self.multimodalZ = multimodalZ\n",
    "\n",
    "#         inSize = imSize / ( 2 ** 4)\n",
    "#         self.inSize = inSize\n",
    "    \n",
    "        self.enc1 = nn.Conv1d(self.inp_size, fSize, 5, stride=2, padding=2)\n",
    "        self.enc2 = nn.Conv1d(fSize, fSize * 2, 5, stride=2, padding=2)\n",
    "        self.enc3 = nn.Conv1d(fSize * 2, fSize * 4, 5, stride=2, padding=2)\n",
    "        self.enc4 = nn.Conv1d(fSize * 4, fSize * 8, 5, stride=2, padding=2)\n",
    "        self.enc5 = nn.Linear(fSize * 8, self.nz)\n",
    "\n",
    "        self.dec1 = nn.Linear(self.nz, fSize * 8)\n",
    "        self.dec2 = nn.ConvTranspose1d(fSize * 8, fSize * 4, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec3 = nn.ConvTranspose1d(fSize * 4, fSize * 2, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec4 = nn.ConvTranspose1d(fSize * 2, fSize, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec5 = nn.ConvTranspose1d(fSize, 32, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.last_dec = nn.Linear(32*16, self.inp_size)\n",
    "        \n",
    "        self.useCUDA = torch.cuda.is_available()\n",
    "\n",
    "#     def norm_prior(self, noSamples=25):\n",
    "#         z = torch.randn(noSamples, self.nz)\n",
    "#         return z\n",
    "\n",
    "#     def multi_prior(self, noSamples=25, mode=None):\n",
    "#         #make a 2D sqrt(nz)-by-sqrt(nz) grid of gaussians\n",
    "#         num = np.sqrt(self.nz) #no of modes in x and y\n",
    "#         STD = 1.0\n",
    "#         modes = np.arange(-num,num)\n",
    "#         p = np.random.uniform(0, num,(noSamples*2))\n",
    "\n",
    "#         if mode is None:\n",
    "#             mu = modes[np.floor(2 * p).astype(int)]\n",
    "#         else:\n",
    "#             mu = modes[np.ones((noSamples, 2), dtype=int) * int(mode)]\n",
    "\n",
    "#         z = torch.Tensor(mu).view(-1,2) + STD * torch.randn(noSamples, 2)\n",
    "#         return z\n",
    "\n",
    "    def encode(self, x):\n",
    "        self.batch_size = x.shape[0]\n",
    "        #define the encoder here return mu(x) and sigma(x)\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.enc5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#     def corrupt(self, x):\n",
    "#         noise = self.sigma * Variable(torch.randn(x.size())).type_as(x)\n",
    "#         return x + noise\n",
    "\n",
    "#     def sample_z(self, noSamples=25, mode=None):\n",
    "#         if not self.multimodalZ:\n",
    "#             z = self.norm_prior(noSamples=noSamples)\n",
    "#         else:\n",
    "#             z = self.multi_prior(noSamples=noSamples, mode=mode)\n",
    "#         if self.useCUDA:\n",
    "#             return Variable(z.cuda())\n",
    "#         else:\n",
    "#             return Variable(z)\n",
    "\n",
    "    def decode(self, z):\n",
    "        #define the decoder here\n",
    "        z = F.relu(self.dec1(z))\n",
    "        z = z.unsqueeze(2)\n",
    "#         print(z.shape)\n",
    "#         z = z.view(z.size(0), -1, self.inp_size)\n",
    "        z = F.relu(self.dec2(z))\n",
    "        z = F.relu(self.dec3(z))\n",
    "        z = F.relu(self.dec4(z))\n",
    "        z = F.sigmoid(self.dec5(z))\n",
    "#         print(z.shape)\n",
    "#         z = F.sigmoid(self.last_dec(z.view(self.batch_size, -1)))\n",
    "        z = F.sigmoid(self.last_dec(z.view(self.batch_size, -1)))\n",
    "    \n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the outputs needed for training\n",
    "#         x_corr = self.corrupt(x)\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_denoising_autoencoder(train[0,:].shape[0]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(),lr=0.00005, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> epoch: 0/120, Loss:0.2545390725135803\n",
      "======> epoch: 0/120, Loss:0.17399930953979492\n",
      "======> epoch: 0/120, Loss:0.15063545107841492\n",
      "======> epoch: 0/120, Loss:0.13435578346252441\n",
      "======> epoch: 0/120, Loss:0.1256829798221588\n",
      "======> epoch: 0/120, Loss:0.11841604858636856\n",
      "======> epoch: 0/120, Loss:0.11225336790084839\n",
      "======> epoch: 0/120, Loss:0.10787416994571686\n",
      "======> epoch: 0/120, Loss:0.10315914452075958\n",
      "======> epoch: 0/120, Loss:0.10181874781847\n",
      "Entering Epoch:  1\n",
      "======> epoch: 1/120, Loss:0.09674400836229324\n",
      "======> epoch: 1/120, Loss:0.09399295598268509\n",
      "======> epoch: 1/120, Loss:0.09185909479856491\n",
      "======> epoch: 1/120, Loss:0.08951041102409363\n",
      "======> epoch: 1/120, Loss:0.08559313416481018\n",
      "======> epoch: 1/120, Loss:0.08554727584123611\n",
      "======> epoch: 1/120, Loss:0.08353861421346664\n",
      "======> epoch: 1/120, Loss:0.08224904537200928\n",
      "======> epoch: 1/120, Loss:0.07849826663732529\n",
      "======> epoch: 1/120, Loss:0.0785520151257515\n",
      "Entering Epoch:  2\n",
      "======> epoch: 2/120, Loss:0.07790759950876236\n",
      "======> epoch: 2/120, Loss:0.0752132311463356\n",
      "======> epoch: 2/120, Loss:0.07438579201698303\n",
      "======> epoch: 2/120, Loss:0.07529383897781372\n",
      "======> epoch: 2/120, Loss:0.07354152947664261\n",
      "======> epoch: 2/120, Loss:0.0694330483675003\n",
      "======> epoch: 2/120, Loss:0.07066516578197479\n"
     ]
    }
   ],
   "source": [
    "train_den_ae(negative_feedback_mask, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losslist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, masked, _ = get_random_masked_batch(train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(orig[0][:400] > 0).sum(), (masked[0][:400] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig[0][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked[0][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------Forward Pass----------------------\n",
    "output = model(masked.unsqueeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((5*output[0]).round() >1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5*output).round()[0][2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/gtshs2/Collaborative-Denoising-Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((tr + vr) > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Collaborative-Denoising-Auto-Encoder/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
